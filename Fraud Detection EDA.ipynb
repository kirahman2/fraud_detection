{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_raw = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.info(); # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.info(); # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_null = df_train.isnull().any()\n",
    "# df_null = pd.DataFrame(list_null).reset_index()\n",
    "# df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.loc[:,df_train.isnull().any()]['id_34'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# train_transaction_sum = train_transaction.duplicated().sum()\n",
    "# train_identity_sum = train_identity.duplicated().sum()\n",
    "# columns = train_transaction.columns\n",
    "# print('Train transaction duplicates: {}\\nTrain identity duplicates: {} \\n'.format(train_transaction_sum, train_identity_sum))\n",
    "# # print('Train feature columns:\\n', list(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.dtypes # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many transactions are in the dataset?\n",
    "# df_train.shape # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the fraud rate of the data set?\n",
    "# fraud_rate = df_train.isFraud.value_counts() / 590540\n",
    "# fraud_rate  # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the statistical overview of the data set?\n",
    "# df_train.describe() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary = df_train.groupby('isFraud')\n",
    "# fraud_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_groupby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "# D = time elapsed between each transaction, card = card information, C = counting, ie how many addresses \n",
    "# associated with card, M=True/False, V created features on ranking, counting, etc. \n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# boolean columns. convert via dummy variable. We dont know if true/false is better than one or the other. \n",
    "# col_bool = col_m\n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))\n",
    "\n",
    "# columns removed dist1, dist2, R_emaildomain, DeviceInfo, DeviceType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train.copy()\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "    \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()\n",
    "# df_null_info\n",
    "# TEST: test imputing with missing instead of mode to see if we have improvements in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['addr1', 'addr2', 'ProductCD', 'P_emaildomain', 'card1', 'card2', 'card3', 'card4', \n",
    "#  'card5', 'card6', 'M1', 'M2', 'M3', 'M4', 'M6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>V40</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isFraud</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.221568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V40</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.213533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V44</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.515480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V45</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.608788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V51</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.196567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V52</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>0.207535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V86</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V87</td>\n",
       "      <td>0.221568</td>\n",
       "      <td>0.213533</td>\n",
       "      <td>0.515480</td>\n",
       "      <td>0.608788</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>0.207535</td>\n",
       "      <td>0.850021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          isFraud       V40       V44       V45       V51       V52       V86  \\\n",
       "isFraud  1.000000  0.174672  0.217870  0.235436  0.182007  0.195492  0.222343   \n",
       "V40      0.174672  1.000000  0.225232  0.271469  0.744831  0.745758  0.217055   \n",
       "V44      0.217870  0.225232  1.000000  0.905537  0.257145  0.251881  0.604776   \n",
       "V45      0.235436  0.271469  0.905537  1.000000  0.257400  0.296102  0.585396   \n",
       "V51      0.182007  0.744831  0.257145  0.257400  1.000000  0.954315  0.212453   \n",
       "V52      0.195492  0.745758  0.251881  0.296102  0.954315  1.000000  0.215183   \n",
       "V86      0.222343  0.217055  0.604776  0.585396  0.212453  0.215183  1.000000   \n",
       "V87      0.221568  0.213533  0.515480  0.608788  0.196567  0.207535  0.850021   \n",
       "\n",
       "              V87  \n",
       "isFraud  0.221568  \n",
       "V40      0.213533  \n",
       "V44      0.515480  \n",
       "V45      0.608788  \n",
       "V51      0.196567  \n",
       "V52      0.207535  \n",
       "V86      0.850021  \n",
       "V87      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_summary = df_features.groupby('isFraud')\n",
    "fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_summary.csv')\n",
    "\n",
    "corr = df_features.corr()\n",
    "corr.to_csv('/Users/krahman/work/fraud_detection/saved_files/corr_matrix.csv')\n",
    "corr2 = corr[corr['isFraud']>.17]\n",
    "corr2 = corr2.loc[:,corr2.index]\n",
    "\n",
    "sns.heatmap(corr2,\n",
    "           xticklabels=corr2.columns.values,\n",
    "           yticklabels=corr2.columns.values)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,4))\n",
    "# sns.barplot(x='V44', y='V44', hue='isFraud', data=df_train)\n",
    "# plt.show()\n",
    "\n",
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X.card1, y)\n",
    "# sns.regplot(x='card5_237.0', y='isFraud', data=pp.df_train, logistic=True, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dropping Features On Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###DELETE\n",
    "\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final\n",
    "\n",
    "# df_temp = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "# df_temp[0:20]\n",
    "# pd.DataFrame(pca.components_, columns=list(X_temp.columns), index=range(0,225))\n",
    "# pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA (2 components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardizing our data, which is required for PCA.\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # PCA instantiate and fit \n",
    "# pca = PCA(n_components=2)\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data = pcomponents, columns=['PC1','PC2'])\n",
    "# print(X_pca.shape)\n",
    "# X_pca.head()\n",
    "\n",
    "# # two principal components scatter plot\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.scatter(X_pca['PC1'], X_pca['PC2'], c=y['isFraud'])\n",
    "# plt.xlabel('First principal component')\n",
    "# plt.ylabel('Second principal component')\n",
    "\n",
    "# # explaining vaariance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to all features (all components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.title('addr1 versus addr2')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.title('Addr1 Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: less occurring email domains are more likely to have higher fraud_perc because they are \n",
    "# perhaps an email provider with less resources. The card that the holder has attached to certain email\n",
    "# addresses puts them at higher risk for fraud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After running final_features, run create_final_df.\n",
      "After running final_features, run create_final_df.\n",
      "Keeping original feature card5\n",
      "Keeping original feature V317\n",
      "Keeping original feature V69\n",
      "Keeping original feature D1\n",
      "Keeping original feature D3\n",
      "Keeping original feature D4\n",
      "Keeping original feature D11\n",
      "Dropping columns:  ['addr1', 'addr2', 'card2', 'card3', 'C1', 'V294', 'V279', 'C14', 'V306', 'D2', 'D10', 'C4']\n",
      "bool_apply_pca set to false.\n",
      "smote applied.\n",
      "tuning dataframe created.\n",
      "final dataframe created.\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineering():\n",
    "    '''create new features for columns without ordinal values'''\n",
    "    def __init__(self):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.df_raw = df_raw.copy()\n",
    "        \n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        \n",
    "        self.col = []\n",
    "        self.col_fe = []\n",
    "        self.df_new_feat = pd.DataFrame()\n",
    "        self.list_drop_col = []\n",
    "        self.str_list_col_fe = []\n",
    "        self.list_feat = []\n",
    "\n",
    "    def feature_testing(self, bool_drop_col, list_feat):\n",
    "        '''testing and scoring new potential features'''\n",
    "        print(\"While running feature_testing, do not run final_features.\")            \n",
    "        if list_feat:\n",
    "            for col in list_feat:\n",
    "                self.col_fe = col\n",
    "                bool_predict_proba = False\n",
    "                if col in df_features.columns:\n",
    "                    df_feat = self.create_test_feature(bool_drop_col, col)\n",
    "                    if df_feat_1000:\n",
    "                        df_feat = df_feat[0:1000] ### delete\n",
    "                    df_feat = df_feat.drop(self.list_drop_col[-1], axis=1)\n",
    "                    self._apply_df_transform(df_feat)\n",
    "                    model_lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "                    self._convert_list_to_string(list_feat)\n",
    "                    mod.create_df_score_model(model_lr)\n",
    "                else:\n",
    "                    print(\"\\nColumn\", col, \"does not exist in dataframe.\\n\")\n",
    "            self.col_fe = []\n",
    "        self.list_drop_col = []\n",
    "            \n",
    "    def final_features(self, bool_drop_col, list_feat):\n",
    "        '''creates final new features'''\n",
    "        print('After running final_features, run create_final_df.')\n",
    "        self.list_feat = list_feat\n",
    "        df_feat = self.create_feature(bool_drop_col, list_feat)  \n",
    "        if df_feat_1000:\n",
    "            df_feat = df_feat[0:1000] ### delete\n",
    "        for col in list_feat:\n",
    "            col_fe = self._append_col_lists(col)\n",
    "            df_feat[col] = self._fill_na(df_feat, col_fe)\n",
    "            self._concat_df_new_feat(df_feat, col_fe)\n",
    "        self._convert_list_to_string(list_feat)\n",
    "        return df_feat ### delete?\n",
    "    \n",
    "    def _append_col_lists(self, col):\n",
    "        '''appending columns and new feature column names'''\n",
    "        col_fe = col + '_fe'\n",
    "        self.col.append(col)\n",
    "        self.col_fe.append(col_fe)\n",
    "        return col_fe\n",
    "    \n",
    "    def _fill_na(self, df_feat, col_fe):\n",
    "        '''fill na values for new features'''\n",
    "        col_mode = df_feat[col_fe].mode()[0]\n",
    "        return df_feat[col_fe].fillna(col_mode)\n",
    "        \n",
    "    def _concat_df_new_feat(self, df_feat, col_fe):\n",
    "        '''adding new feauture columns to one dataframe'''  \n",
    "        df_temp = df_feat[col_fe]\n",
    "        self.df_new_feat = pd.concat([self.df_new_feat, df_temp], axis=1)\n",
    "    \n",
    "    def _convert_list_to_string(self, list_feat):\n",
    "        '''convert list to string to print later'''\n",
    "        str_temp = ''\n",
    "        for val in list_feat:\n",
    "            str_temp = str_temp + val + ' '\n",
    "        self.str_list_col_fe = str_temp\n",
    "\n",
    "    def create_final_df(self):\n",
    "        '''creates final dataframe after creating final_features'''\n",
    "        df_feat = pd.concat([df_features, self.df_new_feat], axis=1) # comment out when 0:1000\n",
    "        if df_feat_1000:\n",
    "            df_feat = pd.concat([df_features[0:1000], self.df_new_feat], axis=1) ### delete\n",
    "        print('Dropping columns: ', self.list_drop_col)\n",
    "        df_feat = df_feat.drop(self.list_drop_col, axis=1)\n",
    "        self._apply_df_transform(df_feat)\n",
    "        self._create_tuning_df(df_feat)\n",
    "        self.list_drop_col = [] ### testing\n",
    "        print(\"final dataframe created.\")\n",
    "        \n",
    "    def _apply_df_transform(self, df_feat):\n",
    "        '''create dataframe, apply pca, apply smote'''\n",
    "        self.df_feat = df_feat\n",
    "        X, y = self._drop_col_id_target(df_feat)\n",
    "        self._apply_pca(X, y)\n",
    "        self._apply_smote()\n",
    "\n",
    "    def _create_tuning_df(self, df_feat):\n",
    "        '''whole dataframe used for model tuning'''\n",
    "        if bool_create_tuning_df:\n",
    "            X, y = self._drop_col_id_target(df_feat)\n",
    "            X = self._pca(X)\n",
    "            sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "            mod.X_features, mod.y_target = sm.fit_sample(X, y)\n",
    "            print('tuning dataframe created.')\n",
    "        else:\n",
    "            print('bool_create_tuning_df set to false.')\n",
    "\n",
    "    def _drop_col_id_target(self, df_feat):\n",
    "        '''dropping col id and target from features and creating target dataframe'''\n",
    "        X = df_feat.drop(col_target, axis=1)\n",
    "        X = X.drop(col_id, axis=1)\n",
    "        y = df_feat[col_target]\n",
    "        return X, y\n",
    "    \n",
    "    def _apply_pca(self, X, y):\n",
    "        '''applying PCA and creating train and test set'''\n",
    "        if bool_apply_pca:\n",
    "            X_pca = self._pca(X)\n",
    "            self._split_dataframe(X_pca, y)\n",
    "            print('PCA applied.')\n",
    "        else:\n",
    "            print(\"bool_apply_pca set to false.\")\n",
    "            self._split_dataframe(X, y)\n",
    "            \n",
    "    def _pca(self, X):\n",
    "        '''applying pca features dataframe'''\n",
    "        scaled_X = StandardScaler().fit_transform(X)\n",
    "        pca = PCA(n_components=250) #set value\n",
    "        pcomponents = pca.fit_transform(scaled_X)\n",
    "        X_pca = pd.DataFrame(data=pcomponents)\n",
    "        return X_pca\n",
    "\n",
    "    def _split_dataframe(self, X, y):\n",
    "        '''splitting dataframe into training and test set'''\n",
    "        mod.X_train, mod.X_test, mod.y_train, mod.y_test = train_test_split(X, \n",
    "                                                                            y, \n",
    "                                                                            test_size=0.1, \n",
    "                                                                            random_state=42)\n",
    "\n",
    "    def _apply_smote(self):\n",
    "        '''applying smote to split training set'''\n",
    "        if bool_apply_smote:\n",
    "            sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "            mod.X_train, mod.y_train = sm.fit_sample(mod.X_train, \n",
    "                                                     mod.y_train)\n",
    "            print(\"smote applied.\")\n",
    "        else:\n",
    "            print(\"bool_apply_smote set to false.\")\n",
    "        \n",
    "    def create_test_feature(self, bool_drop_col, col):\n",
    "        '''creates correllated ratio to target column'''\n",
    "        df_feat = df_features.copy()        \n",
    "        df_feat = self._calculate_target_perc(col, df_feat) \n",
    "        df_feat = self._map_col(col, df_feat)\n",
    "        df_feat = self._create_ratio(df_feat)\n",
    "        df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def create_feature(self, bool_drop_col, list_col):\n",
    "        '''creating new feature'''\n",
    "        df_feat = self.df_feat       \n",
    "        for col in list_col:\n",
    "            df_feat = self._check_col_exist(col, df_feat)\n",
    "            df_feat = self._calculate_target_perc(col, df_feat) \n",
    "            df_feat = self._map_col(col, df_feat)\n",
    "            df_feat = self._create_ratio(df_feat)\n",
    "            df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat \n",
    "    \n",
    "    def _check_col_exist(self, col, df_feat):\n",
    "        '''recreates original column from original dataframe'''\n",
    "        if col not in df_feat.columns:\n",
    "            df_feat[col] = df_raw[col]\n",
    "            df_feat[col] = self._fill_na(df_feat, col)\n",
    "            df_feat[col] = self._label_encode(df_feat, col)\n",
    "        return df_feat\n",
    "    \n",
    "    def _label_encode(self, df_feat, col):\n",
    "        '''label encoding columns pulled from original df_raw'''\n",
    "        le = LabelEncoder()\n",
    "        df_feat[col] = le.fit_transform(df_feat[col])\n",
    "        return df_feat[col]\n",
    "    \n",
    "    def _drop_column(self, bool_drop_col, col, df_feat):\n",
    "        '''dropping or keeping columns'''\n",
    "        if bool_drop_col:\n",
    "            if (col in df_features.columns):    \n",
    "                self.list_drop_col.append(col) \n",
    "        else:\n",
    "            print(\"Keeping original feature\", col)\n",
    "        return df_feat\n",
    "\n",
    "    def aggregate_features(self, list_col, val_aggreg):\n",
    "        for col in list_col:\n",
    "            df_groupby = self.df_raw.groupby(col).mean()\n",
    "            dict_aggreg_col = df_groupby[[val_aggreg]].to_dict()\n",
    "            self.df_feat[col + '_fe'] = self.df_raw[col].map(dict_aggreg_col['TransactionAmt'])\n",
    "            col_mode = self.df_feat[col + '_fe'].mode()[0]\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col + '_fe'].fillna(col_mode)\n",
    "\n",
    "    def _calculate_target_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage for each column'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            list_perc = self._append_fraud_percentage(df_feat, col_val, val, list_perc)    \n",
    "        self._create_dict(col_val, list_perc, unique_col_values) # call _create_dict \n",
    "        return df_feat\n",
    "    \n",
    "    def _append_fraud_percentage(self, df_feat, col_val, val, list_perc):\n",
    "        '''calculating fraud percentage and adding to list'''\n",
    "        fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                            & (df_feat[col_target]==1)].shape[0]\n",
    "        non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "        if (non_fraud_total==0):\n",
    "            list_perc.append(0)\n",
    "        else: \n",
    "            list_perc.append(fraud_total/non_fraud_total)\n",
    "        return list_perc\n",
    "\n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self, col, df_feat):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for val in dict_keys:\n",
    "            df_feat[col + '_fe'] = df_feat[col].map(self.dict_all_feat[val])\n",
    "            self.new_col.append(col + '_fe')\n",
    "        return df_feat\n",
    "            \n",
    "    def _create_ratio(self, df_feat):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "            col_min_val = df_feat[df_feat[val] > 0][val].min()\n",
    "            df_feat[val] = df_feat[val]/col_min_val\n",
    "        self.new_col = []\n",
    "        return df_feat\n",
    "\n",
    "fe = FeatureEngineering()\n",
    "\n",
    "bool_apply_pca = False\n",
    "bool_apply_smote = True\n",
    "df_feat_1000 = False\n",
    "bool_create_tuning_df = True\n",
    "bool_drop_col = True\n",
    "fe.final_features(bool_drop_col, list_feat=['addr1','addr2','card2','card3','C1','P_emaildomain', \n",
    "                                            'card6', 'V294','V279','C14','V306','D2','D10'])\n",
    "bool_drop_col = False\n",
    "fe.final_features(bool_drop_col, list_feat=['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "fe.list_drop_col.append('C4')\n",
    "\n",
    "fe.create_final_df()\n",
    "\n",
    "# fe.feature_testing(bool_drop_col, list_feat=['addr1'])\n",
    "\n",
    "# NEXT, fix bugs in fe, then check to see that mod.X_features works, then check mod.y_target. check\n",
    "# model scores right, then clean up code, then test the new def we created. then go back to \n",
    "# model tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "roc score: 0.7163359236144149\n",
      "\n",
      "The following new features have been created: ['addr1_fe', 'addr2_fe', 'card2_fe', 'card3_fe', 'C1_fe', 'P_emaildomain_fe', 'card6_fe', 'V294_fe', 'V279_fe', 'C14_fe', 'V306_fe', 'D2_fe', 'D10_fe', 'card5_fe', 'V317_fe', 'V69_fe', 'D1_fe', 'D3_fe', 'D4_fe', 'D11_fe'] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81     56945\n",
      "           1       0.08      0.75      0.15      2109\n",
      "\n",
      "    accuracy                           0.69     59054\n",
      "   macro avg       0.53      0.72      0.48     59054\n",
      "weighted avg       0.95      0.69      0.78     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "338          NaN  958.0    860.0   0.572352  0.545756            4.155328   \n",
      "339  model score  508.0   8724.0   0.155061  0.759128            9.844820   \n",
      "340  model score  508.0   8724.0   0.155061  0.759128           11.113225   \n",
      "341     addr1_fe  360.0  30387.0   0.054425  0.829303            5.777150   \n",
      "0    model score  529.0  18023.0   0.080600  0.749170            5.136140   \n",
      "\n",
      "         tn       tp  \n",
      "338  1151.0  56085.0  \n",
      "339  1601.0  48221.0  \n",
      "340  1601.0  48221.0  \n",
      "341  1749.0  26558.0  \n",
      "0    1580.0  38922.0  \n",
      "\n",
      "model does not have _feature_importance attribute.\n"
     ]
    }
   ],
   "source": [
    "bool_predict_proba = False\n",
    "model_current = LogisticRegression(random_state=42)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139754"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod.X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139754"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod.y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.679144</td>\n",
       "      <td>-0.349748</td>\n",
       "      <td>2.802287</td>\n",
       "      <td>-0.910563</td>\n",
       "      <td>-1.207496</td>\n",
       "      <td>-0.823423</td>\n",
       "      <td>0.064612</td>\n",
       "      <td>-0.973015</td>\n",
       "      <td>-0.169964</td>\n",
       "      <td>0.439863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039477</td>\n",
       "      <td>0.027419</td>\n",
       "      <td>-0.022020</td>\n",
       "      <td>-0.034622</td>\n",
       "      <td>-0.013778</td>\n",
       "      <td>-0.047151</td>\n",
       "      <td>0.032487</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.015699</td>\n",
       "      <td>0.009081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.484195</td>\n",
       "      <td>-0.519751</td>\n",
       "      <td>1.520535</td>\n",
       "      <td>-1.255726</td>\n",
       "      <td>-1.446283</td>\n",
       "      <td>-0.625314</td>\n",
       "      <td>0.096616</td>\n",
       "      <td>1.226491</td>\n",
       "      <td>0.411590</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001498</td>\n",
       "      <td>-0.006161</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>-0.018336</td>\n",
       "      <td>-0.002907</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>-0.005224</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.005139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.971773</td>\n",
       "      <td>-0.558737</td>\n",
       "      <td>2.231490</td>\n",
       "      <td>-0.829415</td>\n",
       "      <td>-0.788181</td>\n",
       "      <td>-0.562928</td>\n",
       "      <td>-0.153909</td>\n",
       "      <td>0.528396</td>\n",
       "      <td>-0.599256</td>\n",
       "      <td>-0.231679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>0.030081</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>-0.002601</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>-0.013559</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>-0.008645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.269332</td>\n",
       "      <td>2.874889</td>\n",
       "      <td>1.927759</td>\n",
       "      <td>0.254433</td>\n",
       "      <td>0.975446</td>\n",
       "      <td>0.468235</td>\n",
       "      <td>3.082074</td>\n",
       "      <td>2.616242</td>\n",
       "      <td>-0.787795</td>\n",
       "      <td>-0.057923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109701</td>\n",
       "      <td>0.320159</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>-0.004809</td>\n",
       "      <td>-0.069659</td>\n",
       "      <td>-0.055047</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.002729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.720992</td>\n",
       "      <td>-0.154942</td>\n",
       "      <td>4.493407</td>\n",
       "      <td>-1.478024</td>\n",
       "      <td>-1.433028</td>\n",
       "      <td>-1.421843</td>\n",
       "      <td>-1.694828</td>\n",
       "      <td>-0.255056</td>\n",
       "      <td>1.079694</td>\n",
       "      <td>1.349497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>-0.007863</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>-0.010845</td>\n",
       "      <td>-0.007048</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.002750</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>-0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>-4.212123</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>-1.266686</td>\n",
       "      <td>-0.482762</td>\n",
       "      <td>-0.334057</td>\n",
       "      <td>0.086208</td>\n",
       "      <td>1.267565</td>\n",
       "      <td>-6.218330</td>\n",
       "      <td>-1.117837</td>\n",
       "      <td>-0.936203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>-0.006782</td>\n",
       "      <td>0.056734</td>\n",
       "      <td>-0.008682</td>\n",
       "      <td>-0.017213</td>\n",
       "      <td>-0.015694</td>\n",
       "      <td>-0.037610</td>\n",
       "      <td>-0.030081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590536</td>\n",
       "      <td>-2.278867</td>\n",
       "      <td>-0.404907</td>\n",
       "      <td>2.593187</td>\n",
       "      <td>-0.680588</td>\n",
       "      <td>-0.567999</td>\n",
       "      <td>-0.305401</td>\n",
       "      <td>-0.665731</td>\n",
       "      <td>0.349376</td>\n",
       "      <td>-0.810003</td>\n",
       "      <td>-1.252163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002034</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>-0.001707</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>-0.004080</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590537</td>\n",
       "      <td>-3.486385</td>\n",
       "      <td>-0.516122</td>\n",
       "      <td>-2.024323</td>\n",
       "      <td>0.196702</td>\n",
       "      <td>0.906089</td>\n",
       "      <td>0.639536</td>\n",
       "      <td>-3.415815</td>\n",
       "      <td>-1.415500</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>-0.973828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002390</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>-0.016099</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>-0.010130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590538</td>\n",
       "      <td>-0.464533</td>\n",
       "      <td>0.828484</td>\n",
       "      <td>5.268476</td>\n",
       "      <td>2.831623</td>\n",
       "      <td>6.269637</td>\n",
       "      <td>3.023542</td>\n",
       "      <td>-0.821574</td>\n",
       "      <td>4.769562</td>\n",
       "      <td>1.859054</td>\n",
       "      <td>-0.735273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094414</td>\n",
       "      <td>0.149153</td>\n",
       "      <td>0.029822</td>\n",
       "      <td>0.316190</td>\n",
       "      <td>-0.078859</td>\n",
       "      <td>0.096156</td>\n",
       "      <td>-0.124994</td>\n",
       "      <td>-0.003841</td>\n",
       "      <td>-0.300051</td>\n",
       "      <td>-0.321546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590539</td>\n",
       "      <td>-3.024885</td>\n",
       "      <td>1.139103</td>\n",
       "      <td>1.611969</td>\n",
       "      <td>3.143895</td>\n",
       "      <td>1.356622</td>\n",
       "      <td>0.582964</td>\n",
       "      <td>-6.542847</td>\n",
       "      <td>-4.554875</td>\n",
       "      <td>-0.126119</td>\n",
       "      <td>2.277745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029809</td>\n",
       "      <td>0.031711</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>-0.008590</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.030626</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0      -1.679144 -0.349748  2.802287 -0.910563 -1.207496 -0.823423  0.064612   \n",
       "1      -0.484195 -0.519751  1.520535 -1.255726 -1.446283 -0.625314  0.096616   \n",
       "2      -1.971773 -0.558737  2.231490 -0.829415 -0.788181 -0.562928 -0.153909   \n",
       "3      -2.269332  2.874889  1.927759  0.254433  0.975446  0.468235  3.082074   \n",
       "4      -0.720992 -0.154942  4.493407 -1.478024 -1.433028 -1.421843 -1.694828   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "590535 -4.212123  0.011435 -1.266686 -0.482762 -0.334057  0.086208  1.267565   \n",
       "590536 -2.278867 -0.404907  2.593187 -0.680588 -0.567999 -0.305401 -0.665731   \n",
       "590537 -3.486385 -0.516122 -2.024323  0.196702  0.906089  0.639536 -3.415815   \n",
       "590538 -0.464533  0.828484  5.268476  2.831623  6.269637  3.023542 -0.821574   \n",
       "590539 -3.024885  1.139103  1.611969  3.143895  1.356622  0.582964 -6.542847   \n",
       "\n",
       "             7         8         9    ...       240       241       242  \\\n",
       "0      -0.973015 -0.169964  0.439863  ... -0.039477  0.027419 -0.022020   \n",
       "1       1.226491  0.411590  0.507778  ... -0.001498 -0.006161  0.011493   \n",
       "2       0.528396 -0.599256 -0.231679  ...  0.006192 -0.002288 -0.005354   \n",
       "3       2.616242 -0.787795 -0.057923  ... -0.109701  0.320159  0.045039   \n",
       "4      -0.255056  1.079694  1.349497  ... -0.004530 -0.007863 -0.002951   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "590535 -6.218330 -1.117837 -0.936203  ...  0.031624  0.018982  0.021076   \n",
       "590536  0.349376 -0.810003 -1.252163  ... -0.002034  0.002215 -0.001707   \n",
       "590537 -1.415500  0.808632 -0.973828  ... -0.002390  0.000487 -0.007667   \n",
       "590538  4.769562  1.859054 -0.735273  ...  0.094414  0.149153  0.029822   \n",
       "590539 -4.554875 -0.126119  2.277745  ... -0.029809  0.031711 -0.012426   \n",
       "\n",
       "             243       244       245       246       247       248       249  \n",
       "0      -0.034622 -0.013778 -0.047151  0.032487  0.001580 -0.015699  0.009081  \n",
       "1      -0.001804 -0.018336 -0.002907  0.001749 -0.005224  0.002790  0.005139  \n",
       "2       0.030081  0.007492 -0.002601 -0.052287 -0.013559  0.010516 -0.008645  \n",
       "3       0.060854 -0.004809 -0.069659 -0.055047  0.008236  0.008185  0.002729  \n",
       "4      -0.010845 -0.007048 -0.000085 -0.002750  0.005891 -0.005743 -0.002140  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "590535 -0.006782  0.056734 -0.008682 -0.017213 -0.015694 -0.037610 -0.030081  \n",
       "590536  0.002329  0.009871  0.005409  0.014123 -0.004080 -0.004296  0.004941  \n",
       "590537  0.008861 -0.016099  0.004767  0.014420  0.016204  0.011329 -0.010130  \n",
       "590538  0.316190 -0.078859  0.096156 -0.124994 -0.003841 -0.300051 -0.321546  \n",
       "590539  0.011426 -0.008590  0.015707  0.030626  0.000807  0.030009 -0.023038  \n",
       "\n",
       "[590540 rows x 250 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_current = DecisionTreeClassifier(random_state=42)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "roc score: 0.7653269954567143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     56945\n",
      "           1       0.57      0.55      0.56      2109\n",
      "\n",
      "    accuracy                           0.97     59054\n",
      "   macro avg       0.78      0.77      0.77     59054\n",
      "weighted avg       0.97      0.97      0.97     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "332     addr1_fe  682.0  19343.0   0.068705  0.676624            4.681482   \n",
      "333     addr1_fe  682.0  19343.0   0.068705  0.676624            3.852398   \n",
      "334     addr1_fe  360.0  30387.0   0.054425  0.829303            4.896017   \n",
      "335  model score  958.0    860.0   0.572352  0.545756            4.096957   \n",
      "0            NaN  958.0    860.0   0.572352  0.545756            3.928485   \n",
      "\n",
      "         tn       tp  \n",
      "332  1427.0  37602.0  \n",
      "333  1427.0  37602.0  \n",
      "334  1749.0  26558.0  \n",
      "335  1151.0  56085.0  \n",
      "0    1151.0  56085.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              col  feat_rank\n",
      "0   TransactionDT   0.036505\n",
      "1   TransactionID   0.032122\n",
      "2         isFraud   0.030023\n",
      "3              V1   0.019718\n",
      "4             V69   0.017775\n",
      "5             V14   0.017476\n",
      "6  TransactionAmt   0.016972\n",
      "7             V12   0.014583\n",
      "8           card5   0.011881\n",
      "9           card1   0.011186\n"
     ]
    }
   ],
   "source": [
    "bool_predict_proba = False\n",
    "model_current = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = False\n",
    "# model_current = LogisticRegression(random_state=42)\n",
    "# mod.create_df_score_model(model_current) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, bool_smote):\n",
    "        self.X_train = pd.DataFrame()\n",
    "        self.y_train = pd.DataFrame()\n",
    "        self.X_test = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.X_features = pd.DataFrame()\n",
    "        self.y_target = pd.DataFrame()\n",
    "        \n",
    "    def create_df_score_model(self, model_current):\n",
    "        '''scores model'''\n",
    "        print(\"Fitting model:\\n\", model_current)\n",
    "        y_pred, elapsed_time = self.add_model(model_current) \n",
    "        df_scores, df_temp, y_pred = self._score_model(y_pred, \n",
    "                                                       elapsed_time)\n",
    "        self._save_results(df_scores, df_temp, y_pred)\n",
    "        self._feature_importance(model_current)\n",
    "        fe.col_fe = []\n",
    "        \n",
    "    def add_model(self, model):        \n",
    "        '''fitting model and calculating time elapsed'''\n",
    "        start_time = time.time()\n",
    "        model.fit(mod.X_train, mod.y_train)\n",
    "        y_pred = self._predict(model)\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        return y_pred, elapsed_time\n",
    "    \n",
    "    def _predict(self, model):\n",
    "        '''make prediction'''\n",
    "        if bool_predict_proba:\n",
    "            y_pred = self._predict_proba(model)\n",
    "            return y_pred \n",
    "        else:\n",
    "            y_pred = model.predict(mod.X_test)\n",
    "            return y_pred\n",
    "        \n",
    "    def _predict_proba(self, model):\n",
    "        try:\n",
    "            y_pred_prob = model.predict_proba(mod.X_test)\n",
    "            y_pred_class = self._predict_proba_threshold(y_pred_prob)\n",
    "            return y_pred_class\n",
    "        except:\n",
    "            print(\"Model does not have predict_proba attribute.\")\n",
    "            \n",
    "    def _predict_proba_threshold(self, y_pred_prob):\n",
    "        for threshold in [.1, .15, .2, .25, .3, .35, .4, .45, .5]:\n",
    "            print('threshold: ', threshold)\n",
    "            y_pred_class = binarize(y_pred_prob, threshold)[:,1]\n",
    "            print('roc auc score:', roc_auc_score(mod.y_test, y_pred_class))\n",
    "            print('confusion matrix:\\n', confusion_matrix(mod.y_test, y_pred_class))\n",
    "        return y_pred_class\n",
    "            \n",
    "#     def _create_roc_curve(self, y_pred_class):\n",
    "#         fpr, tpr, thresholds = roc_curve(mod.y_test, y_pred_class)\n",
    "#         plt.plot(fpr, tpr)\n",
    "#         plt.xlim([0.0, 1.0])\n",
    "#         plt.ylim([0.0, 1.0])\n",
    "#         plt.title(\"ROC curve for classifier\")\n",
    "#         plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "#         plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "#         plt.grid(True)\n",
    "#         plt.show()\n",
    "        \n",
    "    def _score_model(self, y_pred, elapsed_time):      \n",
    "        '''creating dataframe with score results'''\n",
    "        col_recall, col_precision, col_time = self._calc_scores(y_pred, \n",
    "                                                                  elapsed_time)        \n",
    "        df_conf_matrix = self._confusion_matrix(y_pred)\n",
    "        df_temp = pd.concat([col_recall, col_precision, df_conf_matrix, col_time], axis=1)\n",
    "        if fe.col_fe:\n",
    "            df_temp = self._concat_new_feat(df_temp)\n",
    "        df_scores = self._read_create_score_file(df_temp)\n",
    "        return df_scores, df_temp, y_pred\n",
    "\n",
    "    def _calc_scores(self, y_pred, elapsed_time):\n",
    "        '''calculating recall, precision and elapsed time'''\n",
    "        col_recall = pd.Series(recall_score(mod.y_test, y_pred), name='recall')\n",
    "        col_precision = pd.Series(precision_score(mod.y_test, y_pred), name='precision')\n",
    "        col_time = pd.Series(elapsed_time, name='time_elapsed (min)')\n",
    "        print(\"roc score:\", roc_auc_score(mod.y_test, y_pred))\n",
    "        return col_recall, col_precision, col_time\n",
    "    \n",
    "    def _confusion_matrix(self, y_pred):\n",
    "        '''creating confusion matrix dataframe'''\n",
    "        df_conf_matrix = pd.DataFrame(confusion_matrix(mod.y_test, y_pred))\n",
    "        val_tp = pd.Series(df_conf_matrix[0][0], name='tp')\n",
    "        val_fn = pd.Series(df_conf_matrix[0][1], name='fn')\n",
    "        val_fp = pd.Series(df_conf_matrix[1][0], name='fp')\n",
    "        val_tn = pd.Series(df_conf_matrix[1][1], name='tn')\n",
    "        return pd.concat([val_fn, val_fp, val_tp, val_tn], axis=1)\n",
    "\n",
    "    def _concat_new_feat(self, df_temp):\n",
    "        '''concatenate scoring results'''        \n",
    "        print(\"\\nThe following new features have been created:\", fe.col_fe, '\\n')\n",
    "        if len(fe.col_fe) > 1: \n",
    "            fe.col_fe = \"model score\"\n",
    "        col_fe = pd.Series(fe.col_fe, name='feat_tested')\n",
    "        return pd.concat([col_fe, df_temp], axis=1)\n",
    "    \n",
    "    def _read_create_score_file(self, df_temp):\n",
    "        '''reading or creating df_scores file'''\n",
    "        try: \n",
    "            df_scores = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "            df_scores = df_scores.drop('Unnamed: 0', axis=1)\n",
    "        except:\n",
    "            print(\"\\nCreating df_scores.csv file.\") \n",
    "            df_scores = df_temp\n",
    "        return df_scores\n",
    "            \n",
    "    def _save_results(self, df_scores, df_temp, y_pred):\n",
    "        '''printing scores for new features'''            \n",
    "        df_scores = pd.concat([df_scores, df_temp], axis=0)\n",
    "        df_scores.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "        classif_report = classification_report(mod.y_test, y_pred)\n",
    "        self._print_summary(classif_report, df_scores)\n",
    "        self._save_summary(classif_report)\n",
    "\n",
    "    def _print_summary(self, classif_report, df_scores):\n",
    "        '''print last 5 rows of previous score results'''\n",
    "        print(classif_report)\n",
    "        print('\\nPrinting df_scores...\\n\\n', df_scores.tail(5))\n",
    "    \n",
    "    def _save_summary(self, classif_report):\n",
    "        '''save score result summary to text file'''\n",
    "        file_summary = open('/Users/krahman/work/fraud_detection/saved_files/df_scores_summary.txt', \"a\")\n",
    "        file_summary.write('New features created from: ' \n",
    "                           + fe.str_list_col_fe \n",
    "                           + '\\n')\n",
    "        file_summary.write(classif_report)\n",
    "        file_summary.close()\n",
    "        \n",
    "    def _feature_importance(self, model):\n",
    "        '''create feature importance dataframe and bar plot'''\n",
    "        try:\n",
    "            df_feat_rank = self._feat_import_create_df(model)\n",
    "            self._feat_import_create_plot(df_feat_rank)\n",
    "            print(df_feat_rank[0:10].reset_index(drop=True))\n",
    "        except:\n",
    "            print(\"\\nmodel does not have _feature_importance attribute.\")\n",
    "        \n",
    "    def _feat_import_create_df(self, model):\n",
    "        '''creating dataframe of important features'''\n",
    "        col_name = pd.Series(fe.df_feat.columns, name='col')\n",
    "        col_feat_rank = pd.Series(model.feature_importances_, \n",
    "                                  name='feat_rank')\n",
    "        df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1)\n",
    "        df_feat_rank = df_feat_rank.sort_values('feat_rank', ascending=False)\n",
    "        return df_feat_rank\n",
    "    \n",
    "    def _feat_import_create_plot(self, df_feat_rank):\n",
    "        '''create feature importance bar plot'''\n",
    "        plt.figure(figsize=(5,6))\n",
    "        sns.barplot(df_feat_rank.feat_rank[0:10],\n",
    "                    df_feat_rank.col[0:10],\n",
    "                    palette='Blues_d')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "        \n",
    "mod = Model(bool_smote=True)      \n",
    "\n",
    "# then Consider creating fe from TransactionAmt\n",
    "# NEXT, do more EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgbc = XGBClassifier()\n",
    "model_xgbc.fit(mod.X_train, mod.y_train)\n",
    "y_pred_xgbc = model_xgbc.predict(mod.X_test)\n",
    "print(classification_report(mod.y_test, y_pred_xgbc))\n",
    "print(confusion_matrix(mod.y_test, y_pred_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc = CatBoostClassifier()\n",
    "model_cbc.fit(mod.X_train, mod.y_train)\n",
    "y_pred_cbc = model_cbc.predict(mod.y_test)\n",
    "print(classification_report(mod.y_test, y_pred_cbc))\n",
    "print(confusion_matrix(mod.y_test, y_pred_cbc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT, before we keep tuning, we need to score on whole dataframe, so fix and test our method...\n",
    "# then we. need to add roc_score to tuning method... or once we get rfc results we can test to see if\n",
    "# it makes a difference or see if there is some kind of built in method we can use. \n",
    "\n",
    "# NEXT, we need to set up tuning for LogisticRegression, then XGBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-bd18bb047abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### Tuning RandomForestClassifier ####\n",
    "rfc = RandomForestClassifier(oob_score=False, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "n_estimators = [50,75,100,125,150,200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [3,5,7,9,11,13,15, None]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8,10]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_leaf_nodes = [2,3,5,7,9,None]\n",
    "min_impurity_decrease = [0,.1,.3,.5,.7,.9]\n",
    "\n",
    "# n_estimators = [50,75,100,125]\n",
    "# criterion = ['gini']\n",
    "# max_depth = [2,3,4,5,6,7,None]\n",
    "# min_samples_split = [6,7,8,9]\n",
    "# min_samples_leaf = [1,2]\n",
    "# min_weight_fraction_leaf = [0]\n",
    "# max_features = ['auto', 'sqrt', 'log2', None]\n",
    "# max_leaf_nodes = [None]\n",
    "# min_impurity_decrease = [0]\n",
    "\n",
    "hyperparameters = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split,\n",
    "                       min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, max_leaf_nodes=max_leaf_nodes,\n",
    "                       min_impurity_decrease=min_impurity_decrease\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(rfc, hyperparameters, random_state=42, cv=5, verbose=5, n_jobs=-1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best max_leaf_nodes:', best_model.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print('Best min_impurity_decrease:', best_model.best_estimator_.get_params()['min_impurity_decrease'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-646818bfd66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### LR Tuning ####\n",
    "lr = LogisticRegression(n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "tol = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "C = [1e-1,.2,.3,.5,.7,1]\n",
    "fit_intercept = [True,False]\n",
    "intercept_scaling = [1,.1,.01,.001]\n",
    "class_weight = ['balanced', None]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "max_iter = [50,75,100,150,200]\n",
    "multi_class = ['auto', 'ovr', 'multinomial']\n",
    "l1_ratio = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "\n",
    "\n",
    "hyperparameters = dict(penalty=penalty, tol=tol, C=C, \n",
    "                       fit_intercept=fit_intercept,\n",
    "                       intercept_scaling=intercept_scaling, class_weight=class_weight,\n",
    "                       solver=solver, max_iter=max_iter,\n",
    "                       multi_class=multi_class, l1_ratio=l1_ratio\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(lr, hyperparameters, random_state=42, cv=5, verbose=1, n_jobs=-1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best tol:', best_model.best_estimator_.get_params()['tol'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best fit_intercept:', best_model.best_estimator_.get_params()['fit_intercept'])\n",
    "print('Best intercept_scaling:', best_model.best_estimator_.get_params()['intercept_scaling'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best solver:', best_model.best_estimator_.get_params()['solver'])\n",
    "print('Best max_iter:', best_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best multi_class:', best_model.best_estimator_.get_params()['multi_class'])\n",
    "print('Best l1_ratio:', best_model.best_estimator_.get_params()['l1_ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-da51637b2234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### Tuning DTC ####\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [3,5,7,9,11, None]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,3,5,7,9]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "class_weight = ['balanced', None]\n",
    "\n",
    "hyperparameters = dict(criterion=criterion, splitter=splitter, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                       min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, class_weight=class_weight\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(dt, hyperparameters, random_state=42, cv=5, verbose=1, n_jobs=-1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best splitter:', best_model.best_estimator_.get_params()['splitter'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Tuning DecisionTreeClassifier #### \n",
    "# dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# criterion = ['gini', 'entropy']\n",
    "# splitter = ['best', 'random']\n",
    "# max_depth = [3,5,7,9,11, None]\n",
    "# min_samples_split = [2,3,5,7,9]\n",
    "# min_samples_leaf = [1,3,5,7,9]\n",
    "# min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "# max_features = ['auto', 'sqrt', 'log2', None]\n",
    "# class_weight = ['balanced', None]\n",
    "\n",
    "# hyperparameters = dict(criterion=criterion, splitter=splitter, max_depth=max_depth, \n",
    "#                        min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "#                        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "#                        max_features=max_features, class_weight=class_weight\n",
    "#                       )\n",
    "\n",
    "# clf = RandomizedSearchCV(dt, hyperparameters, random_state=42, cv=5, verbose=1, n_jobs=-1, scoring='roc_auc')\n",
    "# best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# # best hyper parameters\n",
    "# print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "# print('Best splitter:', best_model.best_estimator_.get_params()['splitter'])\n",
    "# print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "# print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "# print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "# print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "# print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "# print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-e357f2ba0026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Tuning XGBClassifier ###\n",
    "\n",
    "xgbc = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "learning_rate = [0,.1,.3,.5,.7,.9]\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "subsample = [1,3,5,7]\n",
    "colsample_bytree = [1,3,5,7]\n",
    "colsample_bylevel = [1,3,5,7]\n",
    "colsample_bynode = [1,3,5,7]\n",
    "reg_alpha = [0,1,3,5,7]\n",
    "reg_lambda = [1,3,5,7]\n",
    "scale_pos_weight = [1,3,5,7]\n",
    "base_score = [.1,.2,.3,.4,.5]\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, learning_rate=learning_rate, booster=booster, \n",
    "                       subsample=subsample, colsample_bytree=colsample_bytree, \n",
    "                       colsample_bylevel=colsample_bylevel, colsample_bynode=colsample_bynode,\n",
    "                       reg_alpha=reg_alpha, reg_lambda=reg_lambda, scale_pos_weight=scale_pos_weight,\n",
    "                       base_score=base_score\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(xgbc, hyperparameters, random_state=42, cv=5, verbose=1, n_jobs=-1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best booster:', best_model.best_estimator_.get_params()['booster'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print('Best colsample_bytree:', best_model.best_estimator_.get_params()['colsample_bytree'])\n",
    "print('Best colsample_bylevel:', best_model.best_estimator_.get_params()['colsample_bylevel'])\n",
    "print('Best colsample_bynode:', best_model.best_estimator_.get_params()['colsample_bynode'])\n",
    "print('Best reg_alpha:', best_model.best_estimator_.get_params()['reg_alpha'])\n",
    "print('Best reg_lambda:', best_model.best_estimator_.get_params()['reg_lambda'])\n",
    "print('Best scale_pos_weight:', best_model.best_estimator_.get_params()['scale_pos_weight'])\n",
    "print('Best base_score:', best_model.best_estimator_.get_params()['base_score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-2f36b7d03f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Tuning XGBClassifier ###\n",
    "\n",
    "cbc = CatBoostClassifier(random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "learning_rate = [0,.1,.3,.5,.7,.9]\n",
    "bagging_temperature = []\n",
    "subsample = [1,3,5,7]\n",
    "n_estimators = [50,75,100,150]\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, \n",
    "                       subsample=subsample\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(cbc, hyperparameters, random_state=42, cv=5, verbose=1, n_jobs=-1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "                       oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "roc score: 0.7653269954567143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     56945\n",
      "           1       0.57      0.55      0.56      2109\n",
      "\n",
      "    accuracy                           0.97     59054\n",
      "   macro avg       0.78      0.77      0.77     59054\n",
      "weighted avg       0.97      0.97      0.97     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "333     addr1_fe  682.0  19343.0   0.068705  0.676624            3.852398   \n",
      "334     addr1_fe  360.0  30387.0   0.054425  0.829303            4.896017   \n",
      "335  model score  958.0    860.0   0.572352  0.545756            4.096957   \n",
      "336          NaN  958.0    860.0   0.572352  0.545756            3.928485   \n",
      "0            NaN  958.0    860.0   0.572352  0.545756            4.159219   \n",
      "\n",
      "         tn       tp  \n",
      "333  1427.0  37602.0  \n",
      "334  1749.0  26558.0  \n",
      "335  1151.0  56085.0  \n",
      "336  1151.0  56085.0  \n",
      "0    1151.0  56085.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              col  feat_rank\n",
      "0   TransactionDT   0.036505\n",
      "1   TransactionID   0.032122\n",
      "2         isFraud   0.030023\n",
      "3              V1   0.019718\n",
      "4             V69   0.017775\n",
      "5             V14   0.017476\n",
      "6  TransactionAmt   0.016972\n",
      "7             V12   0.014583\n",
      "8           card5   0.011881\n",
      "9           card1   0.011186\n",
      "Fitting model:\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "                       oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "roc score: 0.7653269954567143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     56945\n",
      "           1       0.57      0.55      0.56      2109\n",
      "\n",
      "    accuracy                           0.97     59054\n",
      "   macro avg       0.78      0.77      0.77     59054\n",
      "weighted avg       0.97      0.97      0.97     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "334     addr1_fe  360.0  30387.0   0.054425  0.829303            4.896017   \n",
      "335  model score  958.0    860.0   0.572352  0.545756            4.096957   \n",
      "336          NaN  958.0    860.0   0.572352  0.545756            3.928485   \n",
      "337          NaN  958.0    860.0   0.572352  0.545756            4.159219   \n",
      "0            NaN  958.0    860.0   0.572352  0.545756            4.155328   \n",
      "\n",
      "         tn       tp  \n",
      "334  1749.0  26558.0  \n",
      "335  1151.0  56085.0  \n",
      "336  1151.0  56085.0  \n",
      "337  1151.0  56085.0  \n",
      "0    1151.0  56085.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              col  feat_rank\n",
      "0   TransactionDT   0.036505\n",
      "1   TransactionID   0.032122\n",
      "2         isFraud   0.030023\n",
      "3              V1   0.019718\n",
      "4             V69   0.017775\n",
      "5             V14   0.017476\n",
      "6  TransactionAmt   0.016972\n",
      "7             V12   0.014583\n",
      "8           card5   0.011881\n",
      "9           card1   0.011186\n"
     ]
    }
   ],
   "source": [
    "bool_predict_proba = False\n",
    "# tuned model\n",
    "current_model = RandomForestClassifier(\n",
    "                       max_depth=3, max_features='log2',\n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_samples_leaf=1, min_samples_split=7,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
    "                       n_jobs=-1, oob_score=False, random_state=42,\n",
    "                       verbose=0, warm_start=False)\n",
    "mod.create_df_score_model(model_current)\n",
    "\n",
    "# base model\n",
    "current_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.create_df_score_model(df_feat)\n",
    "# 369.0 all col\n",
    "# 398.0 remove P_emaildomain\n",
    "# 410.0 remove card6\n",
    "# 395.0 drop C4\n",
    "# 415.0 add all back in\n",
    "# 368.0 test again with C14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create feature from TransactionAmt. Add more EDA information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Tuning\n",
    "# 2. Finished - Features\n",
    "# 3. more EDA\n",
    "# 4. Finished - move pca and smote into fe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_read = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "df_temp_read[len(df_temp_read)-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it reads the csv, creates a dataframe, then appends the results, then saves over the old version and keeps\n",
    "# # a record of all columns in the tested dataframe.\n",
    "\n",
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# # we want to test a feature for feature engineering... we must \n",
    "\n",
    "# for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "#     print(col_original, col_new)\n",
    "#     X[col_new] = fe.df_feat[col_new]\n",
    "#     X = X.drop(col_original, axis=1)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    \n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "# #     X = X.drop(col, axis=1)\n",
    "#     print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['time_delta'] = df_temp['time_delta']\n",
    "# fe.df_feat['time_delta_week'] = df_temp['time_delta']/7\n",
    "# fe.df_feat['time_delta_month'] = df_temp['time_delta']/30\n",
    "# fe.df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe','time_delta_fe_week'],axis=1)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['TransactionAmt'] = df_features['TransactionAmt']\n",
    "# list(fe.df_feat)\n",
    "# fe.list_new_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe','addr1_fe'],axis=1)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# val_aggreg = 'TransactionAmt'\n",
    "# list_col = ['card2', 'C4', 'C1', 'V317', 'ProductCD', 'V294', 'V279', 'C14', 'card6', 'V306', 'V69']\n",
    "# fe.aggregate_features(list_col, val_aggreg)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### implement into feature engineering class. days lapsed\n",
    "df_temp = fe.df_feat[['TransactionDT']]\n",
    "df_temp['time_delta'] = 0\n",
    "len_df_temp = df_temp.shape[0]\n",
    "for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "    val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "    val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "    val_time_delta = val_time_2 - val_time_1\n",
    "    df_temp.loc[i, 'time_delta'] = val_time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NEXT, get our score working properly again... What did we do to score \n",
    "# LogisticRegression Base\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "# fit logistic regression\n",
    "model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# predict\n",
    "y_pred = model_lr_pca_sm.predict(X_test)\n",
    "# time\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# BASE SCORE\n",
    "# Time elapsed: 4.251827295621236\n",
    "# [[33985 22960]\n",
    "#  [  601  1508]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.60      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# RESULT: addr1_fe only\n",
    "\n",
    "# RESULT: time_delta_fe, addr1\n",
    "# Time elapsed: 5.163579479853312\n",
    "# [[26551 30394]\n",
    "#  [  363  1746]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.47      0.63     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.48     59054\n",
    "#    macro avg       0.52      0.65      0.37     59054\n",
    "# weighted avg       0.95      0.48      0.61     59054\n",
    "\n",
    "# RESULT: time_delta_fe, time_delta_week_fe\n",
    "# Time elapsed: 3.142271514733632\n",
    "# [[32540 24405]\n",
    "#  [  560  1549]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.57      0.72     56945\n",
    "#            1       0.06      0.73      0.11      2109\n",
    "\n",
    "#     accuracy                           0.58     59054\n",
    "#    macro avg       0.52      0.65      0.42     59054\n",
    "# weighted avg       0.95      0.58      0.70     59054\n",
    "\n",
    "\n",
    "# RESULT: created time_delta_fe\n",
    "# Time elapsed: 3.1532896359761557\n",
    "# [[26260 30685]\n",
    "#  [  359  1750]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.46      0.63     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.47     59054\n",
    "#    macro avg       0.52      0.65      0.36     59054\n",
    "# weighted avg       0.95      0.47      0.61     59054\n",
    "\n",
    "# RESULT: time_delta_fe only. dropping addr1_fe\n",
    "# Time elapsed: 6.11533077955246\n",
    "# [[26893 30052]\n",
    "#  [  365  1744]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.47      0.64     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.48     59054\n",
    "#    macro avg       0.52      0.65      0.37     59054\n",
    "# weighted avg       0.95      0.48      0.62     59054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.list_new_feat\n",
    "'TransactionAmt_fe', 'card1_fe', 'card2_fe','card3_fe', 'card5_fe', 'addr1_fe', 'addr2_fe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression feature testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.drop(col_target, axis=1)\n",
    "X = X.drop(col_id, axis=1)\n",
    "y = df_features[col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 'TransactionAmt_fe', 'card1_fe', 'card2_fe','card3_fe', 'card5_fe', 'addr1_fe', 'addr2_fe'\n",
    "# Good: addr2_fe, \n",
    "# Bad: TransactionAmt_fe, card1_fe, card2_fe, card3_fe, card5_fe\n",
    "# build a function that after a feature is created, you then have it test the feature and provide you results.. \n",
    "\n",
    "for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "    print(col_original, col_new)\n",
    "    X[col_new] = fe.df_feat[col_new]\n",
    "    X = X.drop(col_original, axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "    model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "#     X = X.drop(col, axis=1)\n",
    "    print(list(X.columns))\n",
    "# RESULTS: Base: 601\n",
    "\n",
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # good fe: C2_fe, card2_fe, V294_fe, V317_fe, V279_fe, V306_fe\n",
    "# # bad fe: C1_fe, ProductCD_fe, V294_fe, C14_fe, card6_fe, V69_fe\n",
    "# for col in list_col_fe:\n",
    "#     X[col] = fe.df_feat[col]    \n",
    "#     print(col)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     X = X.drop(col, axis=1)\n",
    "    \n",
    "# # good: C2_fe, \n",
    "# # not good: card2_fe, C4_fe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree smote only (pca commented out)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # applying PCA\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "# # pca = PCA(n_components=250)\n",
    "# pca = PCA()\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.1, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "\n",
    "model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "\n",
    "# Feature importance\n",
    "col_name = pd.Series(X.columns, name='col')\n",
    "col_feat_rank = pd.Series(model_dt_pca_smote.feature_importances_, name='feat_rank')\n",
    "df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1).sort_values('feat_rank', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "sns.barplot(df_feat_rank.feat_rank[0:10], df_feat_rank.col[0:10], palette='Blues_d')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "df_feat_rank[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EDA on C4 and TransactionAmt\n",
    "# df_temp = fe.df_feat\n",
    "\n",
    "# sns.lineplot(x='C4', y='TransactionAmt', data=df_temp)\n",
    "# plt.title('C4 versus Transaction Amount')\n",
    "# plt.show()\n",
    "\n",
    "# sns.scatterplot(x='C4', y='TransactionAmt', hue='isFraud', data=df_temp)\n",
    "# plt.title('C4 versus Transaction Amount')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the type of card is highly correllated with debit, credit, etc. figure out which feature to create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_lr_pca_sm.predict(X_pca)\n",
    "\n",
    "# cross validation\n",
    "# result = cross_val_score(model_lr_pca_sm, X_train2, y_train2, cv=10, n_jobs=-1, scoring='recall_score')\n",
    "# result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes, do we need to visualize our results?? We need to look at our confusion matrix\n",
    "# and decide how to improve our results from here... Test and see what happens if we \n",
    "# increase our principal components... test removing columns, adding columns, imputing\n",
    "# certain columns all together. \n",
    "\n",
    "# test imputing 500 or less for ohe. Then test dropping card1 due to its number\n",
    "# of unique values that would make our data very high dimensional. We can try only ohe for\n",
    "# the entire dataset to see how our model performs over all... Though.. it will likely run \n",
    "# out of memory and crash. \n",
    "\n",
    "# ALSO test probabilities on logisticregression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# plt.hist(y_pred_prob[:,1], bins=8)\n",
    "# plt.xlim(0,1)\n",
    "# plt.title(\"Histogram of Probability of Fraud\")\n",
    "# plt.xlabel(\"Predicted probability of Fraud\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "e\n",
    "\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.title(\"ROC curve for fraud detection classifier\")\n",
    "# plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "# plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_threshold(threshold):\n",
    "#     print(\"Sensitivity:\", tpr[thresholds > threshold][-1])\n",
    "#     print(\"Specificity:\", 1 - fpr[thresholds > threshold][-1],'\\n')\n",
    "    \n",
    "# evaluate_threshold(.5)\n",
    "# evaluate_threshold(.2)\n",
    "# evaluate_threshold(.1)\n",
    "\n",
    "# print(roc_auc_score(y, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_test2) # actual prediction test data set\n",
    "# print('y_pred_actual on test set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_actual))\n",
    "# print(classification_report(y_test2, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_test2)\n",
    "# y_pred_class = binarize(y_pred_proba, 0.5)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_class))\n",
    "# print(classification_report(y_test2, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_pca) # actual full data set\n",
    "# print('Logistic Regression')\n",
    "# print('y_pred_actual full data set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y, y_pred_actual))\n",
    "# print(classification_report(y, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba full data set\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_pca)#[:,1]#[0:10]\n",
    "# y_pred_class = binarize(y_pred_proba, 0.2)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using Logistic Regression, PCA, SMOTE\\n\")\n",
    "# y_pred_pca_sm = model_lr_pca.predict(X_test2)\n",
    "# # y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_lr_pca.score(X_test2, y_test2))\n",
    "# print(recall_score(y_test2, y_pred_pca_sm))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test2, y_pred_pca_sm))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test2, y_pred_pca_sm))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred_pca_sm_whole = model_lr_pca.predict(X_pca)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_lr_pca.score(X_pca, y))\n",
    "# print(recall_score(y, y_pred_pca_sm_whole))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred_pca_sm_whole))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred_pca_sm_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('dataframe length: ' + str(df_features.shape[0]))\n",
    "# print('TransactionDT unique: ' + str(len(df_features.TransactionDT.unique())))\n",
    "# print('is not fraud: ' + str(df_features[df_features.isFraud==0].shape[0]))\n",
    "# print('is fraud: ' + str(df_features[df_features.isFraud==1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # KEEP\n",
    "# fig = plt.figure(figsize=(15,4))\n",
    "# df_temp = df_features\n",
    "# sns.kdeplot(df_temp.loc[(df_temp.isFraud==0), 'TransactionDT'], color='b', shade=True, label='Not Fraud')\n",
    "# sns.kdeplot(df_temp.loc[(df_temp.isFraud==1), 'TransactionDT'], color='r', shade=True, label='Fraud')\n",
    "# plt.title('Transaction Date Versus Fraud')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='TransactionDT', y='TransactionDT', hue='isFraud', data=df_features)\n",
    "# plt.title(\"Transaction Date Versus Fraud\")\n",
    "# plt.show()\n",
    "\n",
    "# we want to figure out how to create more features from TransactionDT.. \n",
    "# are certain transactions more likely. in general, to be fraudualant around a certain day? \n",
    "# we have transactionID yet we dont have the specific card of who it belongs to.. \n",
    "# if card1 is the unique identifier... and we did a groupby on fraud.. \n",
    "# we have average spent per day as an option... \n",
    "# create a feature that is average spent per day for non fraud versus average spent per day for fraud.. \n",
    "# what would the describe method reveal for us? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using PCA\\n\")\n",
    "# y_pred_pca = model_dt_pca_smote.predict(X_test2)\n",
    "# # y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_dt_pca_smote.score(X_test2, y_test2))\n",
    "# print(recall_score(y_test2, y_pred_pca))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test2, y_pred_pca))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test2, y_pred_pca))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred_pca = model_dt_pca_smote.predict(X_pca)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_dt_pca_smote.score(X_pca, y))\n",
    "# print(recall_score(y, y_pred_pca))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred_pca))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Variance ratio:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(\"\\nPrincipal components explained:\")\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # explaining variance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))\n",
    "\n",
    "# # # predicting on original dataset\n",
    "# # y_pred = clf_lr.predict(X)\n",
    "# # print(\"\\nTest Results\")\n",
    "# # print(clf_lr.score(X, y))\n",
    "# # print(recall_score(y, y_pred))\n",
    "# # print(\"\\nConfusion Matrix\")\n",
    "# # print(confusion_matrix(y, y_pred))\n",
    "# # print('\\nClassification Report:\\n')\n",
    "# # print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X2 = StandardScaler().fit_transform(X)\n",
    "# pca3 = PCA(n_components=275)\n",
    "# pcomponents = pca3.fit_transform(scaled_X2)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # applying SMOTE to train set to correct class imbalance\n",
    "# sm = SMOTE(random_state=42, ratio = 1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# # fitting to residuals created by SMOTE\n",
    "# clf_lr = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "# clf_lr.fit(X_train_res, y_train_res);\n",
    "\n",
    "# # predicting on test set\n",
    "# y_test_pred = clf_lr.predict(X_test)\n",
    "# print(\"Validation results\")\n",
    "# print(clf_lr.score(X_test, y_test))\n",
    "# print(recall_score(y_test, y_test_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test, y_test_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# y_pred = clf_lr.predict(X)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(clf_lr.score(X, y))\n",
    "# print(recall_score(y, y_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
