{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_raw = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.info(); # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.info(); # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_null = df_train.isnull().any()\n",
    "# df_null = pd.DataFrame(list_null).reset_index()\n",
    "# df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.loc[:,df_train.isnull().any()]['id_34'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# train_transaction_sum = train_transaction.duplicated().sum()\n",
    "# train_identity_sum = train_identity.duplicated().sum()\n",
    "# columns = train_transaction.columns\n",
    "# print('Train transaction duplicates: {}\\nTrain identity duplicates: {} \\n'.format(train_transaction_sum, train_identity_sum))\n",
    "# # print('Train feature columns:\\n', list(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.dtypes # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many transactions are in the dataset?\n",
    "# df_train.shape # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the fraud rate of the data set?\n",
    "# fraud_rate = df_train.isFraud.value_counts() / 590540\n",
    "# fraud_rate  # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the statistical overview of the data set?\n",
    "# df_train.describe() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary = df_train.groupby('isFraud')\n",
    "# fraud_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_groupby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "# D = time elapsed between each transaction, card = card information, C = counting, ie how many addresses \n",
    "# associated with card, M=True/False, V created features on ranking, counting, etc. \n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# boolean columns. convert via dummy variable. We dont know if true/false is better than one or the other. \n",
    "# col_bool = col_m\n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))\n",
    "\n",
    "# columns removed dist1, dist2, R_emaildomain, DeviceInfo, DeviceType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train.copy()\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "    \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()\n",
    "# df_null_info\n",
    "# TEST: test imputing with missing instead of mode to see if we have improvements in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['addr1', 'addr2', 'ProductCD', 'P_emaildomain', 'card1', 'card2', 'card3', 'card4', \n",
    "#  'card5', 'card6', 'M1', 'M2', 'M3', 'M4', 'M6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>V40</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isFraud</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.221568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V40</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.213533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V44</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.515480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V45</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.608788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V51</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.196567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V52</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>0.207535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V86</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V87</td>\n",
       "      <td>0.221568</td>\n",
       "      <td>0.213533</td>\n",
       "      <td>0.515480</td>\n",
       "      <td>0.608788</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>0.207535</td>\n",
       "      <td>0.850021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          isFraud       V40       V44       V45       V51       V52       V86  \\\n",
       "isFraud  1.000000  0.174672  0.217870  0.235436  0.182007  0.195492  0.222343   \n",
       "V40      0.174672  1.000000  0.225232  0.271469  0.744831  0.745758  0.217055   \n",
       "V44      0.217870  0.225232  1.000000  0.905537  0.257145  0.251881  0.604776   \n",
       "V45      0.235436  0.271469  0.905537  1.000000  0.257400  0.296102  0.585396   \n",
       "V51      0.182007  0.744831  0.257145  0.257400  1.000000  0.954315  0.212453   \n",
       "V52      0.195492  0.745758  0.251881  0.296102  0.954315  1.000000  0.215183   \n",
       "V86      0.222343  0.217055  0.604776  0.585396  0.212453  0.215183  1.000000   \n",
       "V87      0.221568  0.213533  0.515480  0.608788  0.196567  0.207535  0.850021   \n",
       "\n",
       "              V87  \n",
       "isFraud  0.221568  \n",
       "V40      0.213533  \n",
       "V44      0.515480  \n",
       "V45      0.608788  \n",
       "V51      0.196567  \n",
       "V52      0.207535  \n",
       "V86      0.850021  \n",
       "V87      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_summary = df_features.groupby('isFraud')\n",
    "fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_summary.csv')\n",
    "\n",
    "corr = df_features.corr()\n",
    "corr.to_csv('/Users/krahman/work/fraud_detection/saved_files/corr_matrix.csv')\n",
    "corr2 = corr[corr['isFraud']>.17]\n",
    "corr2 = corr2.loc[:,corr2.index]\n",
    "\n",
    "sns.heatmap(corr2,\n",
    "           xticklabels=corr2.columns.values,\n",
    "           yticklabels=corr2.columns.values)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,4))\n",
    "# sns.barplot(x='V44', y='V44', hue='isFraud', data=df_train)\n",
    "# plt.show()\n",
    "\n",
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X.card1, y)\n",
    "# sns.regplot(x='card5_237.0', y='isFraud', data=pp.df_train, logistic=True, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dropping Features On Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###DELETE\n",
    "\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final\n",
    "\n",
    "# df_temp = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "# df_temp[0:20]\n",
    "# pd.DataFrame(pca.components_, columns=list(X_temp.columns), index=range(0,225))\n",
    "# pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA (2 components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardizing our data, which is required for PCA.\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # PCA instantiate and fit \n",
    "# pca = PCA(n_components=2)\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data = pcomponents, columns=['PC1','PC2'])\n",
    "# print(X_pca.shape)\n",
    "# X_pca.head()\n",
    "\n",
    "# # two principal components scatter plot\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.scatter(X_pca['PC1'], X_pca['PC2'], c=y['isFraud'])\n",
    "# plt.xlabel('First principal component')\n",
    "# plt.ylabel('Second principal component')\n",
    "\n",
    "# # explaining vaariance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to all features (all components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.title('addr1 versus addr2')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.title('Addr1 Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: less occurring email domains are more likely to have higher fraud_perc because they are \n",
    "# perhaps an email provider with less resources. The card that the holder has attached to certain email\n",
    "# addresses puts them at higher risk for fraud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After running final_features, run create_final_df.\n",
      "After running final_features, run create_final_df.\n",
      "Keeping original feature card5\n",
      "Keeping original feature V317\n",
      "Keeping original feature V69\n",
      "Keeping original feature D1\n",
      "Keeping original feature D3\n",
      "Keeping original feature D4\n",
      "Keeping original feature D11\n",
      "Dropping columns:  ['addr1', 'addr2', 'card2', 'card3', 'C1', 'V294', 'V279', 'C14', 'V306', 'D2', 'D10', 'C4']\n",
      "PCA applied.\n",
      "smote applied.\n",
      "tuning dataframe created.\n",
      "final dataframe created.\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineering():\n",
    "    '''create new features for columns without ordinal values'''\n",
    "    def __init__(self):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.df_raw = df_raw.copy()\n",
    "        \n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        \n",
    "        self.col = []\n",
    "        self.col_fe = []\n",
    "        self.df_new_feat = pd.DataFrame()\n",
    "        self.list_drop_col = []\n",
    "        self.str_list_col_fe = []\n",
    "        self.list_feat = []\n",
    "\n",
    "    def feature_testing(self, bool_drop_col, list_feat):\n",
    "        '''testing and scoring new potential features'''\n",
    "        print(\"While running feature_testing, do not run final_features.\")            \n",
    "        if list_feat:\n",
    "            for col in list_feat:\n",
    "                self.col_fe = col\n",
    "                bool_predict_proba = False\n",
    "                if col in df_features.columns:\n",
    "                    df_feat = self.create_test_feature(bool_drop_col, col)\n",
    "                    if df_feat_1000:\n",
    "                        df_feat = df_feat[0:1000] ### delete\n",
    "                    df_feat = df_feat.drop(self.list_drop_col[-1], axis=1)\n",
    "                    self._apply_df_transform(df_feat)\n",
    "                    model_lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "                    self._convert_list_to_string(list_feat)\n",
    "                    mod.create_df_score_model(model_lr)\n",
    "                else:\n",
    "                    print(\"\\nColumn\", col, \"does not exist in dataframe.\\n\")\n",
    "            self.col_fe = []\n",
    "        self.list_drop_col = []\n",
    "            \n",
    "    def final_features(self, bool_drop_col, list_feat):\n",
    "        '''creates final new features'''\n",
    "        print('After running final_features, run create_final_df.')\n",
    "        self.list_feat = list_feat\n",
    "        df_feat = self.create_feature(bool_drop_col, list_feat)  \n",
    "        if df_feat_1000:\n",
    "            df_feat = df_feat[0:1000] ### delete\n",
    "        for col in list_feat:\n",
    "            col_fe = self._append_col_lists(col)\n",
    "            df_feat[col] = self._fill_na(df_feat, col_fe)\n",
    "            self._concat_df_new_feat(df_feat, col_fe)\n",
    "        self._convert_list_to_string(list_feat)\n",
    "        return df_feat ### delete?\n",
    "    \n",
    "    def _append_col_lists(self, col):\n",
    "        '''appending columns and new feature column names'''\n",
    "        col_fe = col + '_fe'\n",
    "        self.col.append(col)\n",
    "        self.col_fe.append(col_fe)\n",
    "        return col_fe\n",
    "    \n",
    "    def _fill_na(self, df_feat, col_fe):\n",
    "        '''fill na values for new features'''\n",
    "        col_mode = df_feat[col_fe].mode()[0]\n",
    "        return df_feat[col_fe].fillna(col_mode)\n",
    "        \n",
    "    def _concat_df_new_feat(self, df_feat, col_fe):\n",
    "        '''adding new feauture columns to one dataframe'''  \n",
    "        df_temp = df_feat[col_fe]\n",
    "        self.df_new_feat = pd.concat([self.df_new_feat, df_temp], axis=1)\n",
    "    \n",
    "    def _convert_list_to_string(self, list_feat):\n",
    "        '''convert list to string to print later'''\n",
    "        str_temp = ''\n",
    "        for val in list_feat:\n",
    "            str_temp = str_temp + val + ' '\n",
    "        self.str_list_col_fe = str_temp\n",
    "\n",
    "    def create_final_df(self):\n",
    "        '''creates final dataframe after creating final_features'''\n",
    "        df_feat = pd.concat([df_features, self.df_new_feat], axis=1) # comment out when 0:1000\n",
    "        if df_feat_1000:\n",
    "            df_feat = pd.concat([df_features[0:1000], self.df_new_feat], axis=1) ### delete\n",
    "        print('Dropping columns: ', self.list_drop_col)\n",
    "        df_feat = df_feat.drop(self.list_drop_col, axis=1)\n",
    "        self._apply_df_transform(df_feat)\n",
    "        self._create_tuning_df(df_feat)\n",
    "        self.list_drop_col = [] ### testing\n",
    "        print(\"final dataframe created.\")\n",
    "        \n",
    "    def _apply_df_transform(self, df_feat):\n",
    "        '''create dataframe, apply pca, apply smote'''\n",
    "        self.df_feat = df_feat\n",
    "        X, y = self._drop_col_id_target(df_feat)\n",
    "        self._apply_pca(X, y)\n",
    "        self._apply_smote()\n",
    "\n",
    "    def _create_tuning_df(self, df_feat):\n",
    "        '''whole dataframe used for model tuning'''\n",
    "        if bool_create_tuning_df:\n",
    "            X, y = self._drop_col_id_target(df_feat)\n",
    "            X = self._pca(X)\n",
    "            sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "            mod.X_features, mod.y_target = sm.fit_sample(X, y)\n",
    "            print('tuning dataframe created.')\n",
    "        else:\n",
    "            print('bool_create_tuning_df set to false.')\n",
    "\n",
    "    def _drop_col_id_target(self, df_feat):\n",
    "        '''dropping col id and target from features and creating target dataframe'''\n",
    "        X = df_feat.drop(col_target, axis=1)\n",
    "        X = X.drop(col_id, axis=1)\n",
    "        y = df_feat[col_target]\n",
    "        return X, y\n",
    "    \n",
    "    def _apply_pca(self, X, y):\n",
    "        '''applying PCA and creating train and test set'''\n",
    "        if bool_apply_pca:\n",
    "            X_pca = self._pca(X)\n",
    "            self._split_dataframe(X_pca, y)\n",
    "            print('PCA applied.')\n",
    "        else:\n",
    "            print(\"bool_apply_pca set to false.\")\n",
    "            self._split_dataframe(X, y)\n",
    "            \n",
    "    def _pca(self, X):\n",
    "        '''applying pca features dataframe'''\n",
    "        scaled_X = StandardScaler().fit_transform(X)\n",
    "        pca = PCA(n_components=250) #set value\n",
    "        pcomponents = pca.fit_transform(scaled_X)\n",
    "        X_pca = pd.DataFrame(data=pcomponents)\n",
    "        return X_pca\n",
    "\n",
    "    def _split_dataframe(self, X, y):\n",
    "        '''splitting dataframe into training and test set'''\n",
    "        mod.X_train, mod.X_test, mod.y_train, mod.y_test = train_test_split(X, \n",
    "                                                                            y, \n",
    "                                                                            test_size=0.1, \n",
    "                                                                            random_state=42)\n",
    "\n",
    "    def _apply_smote(self):\n",
    "        '''applying smote to split training set'''\n",
    "        if bool_apply_smote:\n",
    "            sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "            mod.X_train, mod.y_train = sm.fit_sample(mod.X_train, \n",
    "                                                     mod.y_train)\n",
    "            print(\"smote applied.\")\n",
    "        else:\n",
    "            print(\"bool_apply_smote set to false.\")\n",
    "        \n",
    "    def create_test_feature(self, bool_drop_col, col):\n",
    "        '''creates correllated ratio to target column'''\n",
    "        df_feat = df_features.copy()        \n",
    "        df_feat = self._calculate_target_perc(col, df_feat) \n",
    "        df_feat = self._map_col(col, df_feat)\n",
    "        df_feat = self._create_ratio(df_feat)\n",
    "        df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def create_feature(self, bool_drop_col, list_col):\n",
    "        '''creating new feature'''\n",
    "        df_feat = self.df_feat       \n",
    "        for col in list_col:\n",
    "            df_feat = self._check_col_exist(col, df_feat)\n",
    "            df_feat = self._calculate_target_perc(col, df_feat) \n",
    "            df_feat = self._map_col(col, df_feat)\n",
    "            df_feat = self._create_ratio(df_feat)\n",
    "            df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat \n",
    "    \n",
    "    def _check_col_exist(self, col, df_feat):\n",
    "        '''recreates original column from original dataframe'''\n",
    "        if col not in df_feat.columns:\n",
    "            df_feat[col] = df_raw[col]\n",
    "            df_feat[col] = self._fill_na(df_feat, col)\n",
    "            df_feat[col] = self._label_encode(df_feat, col)\n",
    "        return df_feat\n",
    "    \n",
    "    def _label_encode(self, df_feat, col):\n",
    "        '''label encoding columns pulled from original df_raw'''\n",
    "        le = LabelEncoder()\n",
    "        df_feat[col] = le.fit_transform(df_feat[col])\n",
    "        return df_feat[col]\n",
    "    \n",
    "    def _drop_column(self, bool_drop_col, col, df_feat):\n",
    "        '''dropping or keeping columns'''\n",
    "        if bool_drop_col:\n",
    "            if (col in df_features.columns):    \n",
    "                self.list_drop_col.append(col) \n",
    "        else:\n",
    "            print(\"Keeping original feature\", col)\n",
    "        return df_feat\n",
    "\n",
    "    def aggregate_features(self, list_col, val_aggreg):\n",
    "        for col in list_col:\n",
    "            df_groupby = self.df_raw.groupby(col).mean()\n",
    "            dict_aggreg_col = df_groupby[[val_aggreg]].to_dict()\n",
    "            self.df_feat[col + '_fe'] = self.df_raw[col].map(dict_aggreg_col['TransactionAmt'])\n",
    "            col_mode = self.df_feat[col + '_fe'].mode()[0]\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col + '_fe'].fillna(col_mode)\n",
    "\n",
    "    def _calculate_target_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage for each column'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            list_perc = self._append_fraud_percentage(df_feat, col_val, val, list_perc)    \n",
    "        self._create_dict(col_val, list_perc, unique_col_values) # call _create_dict \n",
    "        return df_feat\n",
    "    \n",
    "    def _append_fraud_percentage(self, df_feat, col_val, val, list_perc):\n",
    "        '''calculating fraud percentage and adding to list'''\n",
    "        fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                            & (df_feat[col_target]==1)].shape[0]\n",
    "        non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "        if (non_fraud_total==0):\n",
    "            list_perc.append(0)\n",
    "        else: \n",
    "            list_perc.append(fraud_total/non_fraud_total)\n",
    "        return list_perc\n",
    "\n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self, col, df_feat):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for val in dict_keys:\n",
    "            df_feat[col + '_fe'] = df_feat[col].map(self.dict_all_feat[val])\n",
    "            self.new_col.append(col + '_fe')\n",
    "        return df_feat\n",
    "            \n",
    "    def _create_ratio(self, df_feat):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "            col_min_val = df_feat[df_feat[val] > 0][val].min()\n",
    "            df_feat[val] = df_feat[val]/col_min_val\n",
    "        self.new_col = []\n",
    "        return df_feat\n",
    "\n",
    "fe = FeatureEngineering()\n",
    "\n",
    "bool_apply_pca = True\n",
    "bool_apply_smote = True\n",
    "df_feat_1000 = False\n",
    "bool_create_tuning_df = True\n",
    "bool_drop_col = True\n",
    "fe.final_features(bool_drop_col, list_feat=['addr1','addr2','card2','card3','C1','P_emaildomain', \n",
    "                                            'card6', 'V294','V279','C14','V306','D2','D10'])\n",
    "bool_drop_col = False\n",
    "fe.final_features(bool_drop_col, list_feat=['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "fe.list_drop_col.append('C4')\n",
    "\n",
    "fe.create_final_df()\n",
    "\n",
    "# fe.feature_testing(bool_drop_col, list_feat=['addr1'])\n",
    "\n",
    "# NEXT, fix bugs in fe, then check to see that mod.X_features works, then check mod.y_target. check\n",
    "# model scores right, then clean up code, then test the new def we created. then go back to \n",
    "# model tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.67914422e+00, -3.49748207e-01,  2.80228703e+00, ...,\n",
       "         1.57956336e-03, -1.56985656e-02,  9.08141843e-03],\n",
       "       [-4.84194542e-01, -5.19750838e-01,  1.52053537e+00, ...,\n",
       "        -5.22400203e-03,  2.79034648e-03,  5.13881253e-03],\n",
       "       [-1.97177288e+00, -5.58737441e-01,  2.23148967e+00, ...,\n",
       "        -1.35586758e-02,  1.05160373e-02, -8.64544766e-03],\n",
       "       ...,\n",
       "       [-1.64099167e+00,  8.89749116e-01,  1.17072521e+00, ...,\n",
       "        -7.15880176e-02, -8.44372948e-02, -1.05563052e-01],\n",
       "       [-1.17677409e+00,  6.76745308e-01,  3.62591540e+00, ...,\n",
       "        -2.51628523e-02,  7.98621556e-03,  4.89218013e-03],\n",
       "       [ 1.58819852e+01, -1.94379551e+00, -1.01577876e+00, ...,\n",
       "         1.45069948e-01,  1.93907058e-01,  2.66702324e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add delete functions to our created dataframes potentially..\n",
    "mod.X_features = pd.DataFrame(mod.X_features)\n",
    "mod.y_target = pd.DataFrame(mod.y_target)\n",
    "\n",
    "mod.X_features.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv')\n",
    "mod.y_target.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv')\n",
    "mod.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv')\n",
    "mod.X_features = mod.X_features.drop('Unnamed: 0', axis=1)\n",
    "mod.y_target = mod.y_target.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod.X_features.info(memory_usage='deep')\n",
    "# mod.y_target.info(memory_usage='deep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bool_predict_proba = False\n",
    "# model_current = LogisticRegression(random_state=42)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_current = DecisionTreeClassifier(random_state=42)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = False\n",
    "# model_current = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = False\n",
    "# model_current = LogisticRegression(random_state=42)\n",
    "# mod.create_df_score_model(model_current) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, bool_smote):\n",
    "        self.X_train = pd.DataFrame()\n",
    "        self.y_train = pd.DataFrame()\n",
    "        self.X_test = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.X_features = pd.DataFrame()\n",
    "        self.y_target = pd.DataFrame()\n",
    "        \n",
    "    def create_df_score_model(self, model_current):\n",
    "        '''scores model'''\n",
    "        print(\"Fitting model:\\n\", model_current)\n",
    "        y_pred, elapsed_time = self.add_model(model_current) \n",
    "        df_scores, df_temp, y_pred = self._score_model(y_pred, \n",
    "                                                       elapsed_time)\n",
    "        self._save_results(df_scores, df_temp, y_pred)\n",
    "        self._feature_importance(model_current)\n",
    "        fe.col_fe = []\n",
    "        \n",
    "    def add_model(self, model):        \n",
    "        '''fitting model and calculating time elapsed'''\n",
    "        start_time = time.time()\n",
    "        model.fit(mod.X_train, mod.y_train)\n",
    "        y_pred = self._predict(model)\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        return y_pred, elapsed_time\n",
    "    \n",
    "    def _predict(self, model):\n",
    "        '''make prediction'''\n",
    "        if bool_predict_proba:\n",
    "            y_pred = self._predict_proba(model)\n",
    "            return y_pred \n",
    "        else:\n",
    "            y_pred = model.predict(mod.X_test)\n",
    "            return y_pred\n",
    "        \n",
    "    def _predict_proba(self, model):\n",
    "        try:\n",
    "            y_pred_prob = model.predict_proba(mod.X_test)\n",
    "            y_pred_class = self._predict_proba_threshold(y_pred_prob)\n",
    "            return y_pred_class\n",
    "        except:\n",
    "            print(\"Model does not have predict_proba attribute.\")\n",
    "            \n",
    "    def _predict_proba_threshold(self, y_pred_prob):\n",
    "        for threshold in [.1, .15, .2, .25, .3, .35, .4, .45, .5]:\n",
    "            print('threshold: ', threshold)\n",
    "            y_pred_class = binarize(y_pred_prob, threshold)[:,1]\n",
    "            print('roc auc score:', roc_auc_score(mod.y_test, y_pred_class))\n",
    "            print('confusion matrix:\\n', confusion_matrix(mod.y_test, y_pred_class))\n",
    "        return y_pred_class\n",
    "            \n",
    "#     def _create_roc_curve(self, y_pred_class):\n",
    "#         fpr, tpr, thresholds = roc_curve(mod.y_test, y_pred_class)\n",
    "#         plt.plot(fpr, tpr)\n",
    "#         plt.xlim([0.0, 1.0])\n",
    "#         plt.ylim([0.0, 1.0])\n",
    "#         plt.title(\"ROC curve for classifier\")\n",
    "#         plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "#         plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "#         plt.grid(True)\n",
    "#         plt.show()\n",
    "        \n",
    "    def _score_model(self, y_pred, elapsed_time):      \n",
    "        '''creating dataframe with score results'''\n",
    "        col_recall, col_precision, col_time = self._calc_scores(y_pred, \n",
    "                                                                  elapsed_time)        \n",
    "        df_conf_matrix = self._confusion_matrix(y_pred)\n",
    "        df_temp = pd.concat([col_recall, col_precision, df_conf_matrix, col_time], axis=1)\n",
    "        if fe.col_fe:\n",
    "            df_temp = self._concat_new_feat(df_temp)\n",
    "        df_scores = self._read_create_score_file(df_temp)\n",
    "        return df_scores, df_temp, y_pred\n",
    "\n",
    "    def _calc_scores(self, y_pred, elapsed_time):\n",
    "        '''calculating recall, precision and elapsed time'''\n",
    "        col_recall = pd.Series(recall_score(mod.y_test, y_pred), name='recall')\n",
    "        col_precision = pd.Series(precision_score(mod.y_test, y_pred), name='precision')\n",
    "        col_time = pd.Series(elapsed_time, name='time_elapsed (min)')\n",
    "        print(\"roc score:\", roc_auc_score(mod.y_test, y_pred))\n",
    "        return col_recall, col_precision, col_time\n",
    "    \n",
    "    def _confusion_matrix(self, y_pred):\n",
    "        '''creating confusion matrix dataframe'''\n",
    "        df_conf_matrix = pd.DataFrame(confusion_matrix(mod.y_test, y_pred))\n",
    "        val_tp = pd.Series(df_conf_matrix[0][0], name='tp')\n",
    "        val_fn = pd.Series(df_conf_matrix[0][1], name='fn')\n",
    "        val_fp = pd.Series(df_conf_matrix[1][0], name='fp')\n",
    "        val_tn = pd.Series(df_conf_matrix[1][1], name='tn')\n",
    "        return pd.concat([val_fn, val_fp, val_tp, val_tn], axis=1)\n",
    "\n",
    "    def _concat_new_feat(self, df_temp):\n",
    "        '''concatenate scoring results'''        \n",
    "        print(\"\\nThe following new features have been created:\", fe.col_fe, '\\n')\n",
    "        if len(fe.col_fe) > 1: \n",
    "            fe.col_fe = \"model score\"\n",
    "        col_fe = pd.Series(fe.col_fe, name='feat_tested')\n",
    "        return pd.concat([col_fe, df_temp], axis=1)\n",
    "    \n",
    "    def _read_create_score_file(self, df_temp):\n",
    "        '''reading or creating df_scores file'''\n",
    "        try: \n",
    "            df_scores = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "            df_scores = df_scores.drop('Unnamed: 0', axis=1)\n",
    "        except:\n",
    "            print(\"\\nCreating df_scores.csv file.\") \n",
    "            df_scores = df_temp\n",
    "        return df_scores\n",
    "            \n",
    "    def _save_results(self, df_scores, df_temp, y_pred):\n",
    "        '''printing scores for new features'''            \n",
    "        df_scores = pd.concat([df_scores, df_temp], axis=0)\n",
    "        df_scores.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "        classif_report = classification_report(mod.y_test, y_pred)\n",
    "        self._print_summary(classif_report, df_scores)\n",
    "        self._save_summary(classif_report)\n",
    "\n",
    "    def _print_summary(self, classif_report, df_scores):\n",
    "        '''print last 5 rows of previous score results'''\n",
    "        print(classif_report)\n",
    "        print('\\nPrinting df_scores...\\n\\n', df_scores.tail(5))\n",
    "    \n",
    "    def _save_summary(self, classif_report):\n",
    "        '''save score result summary to text file'''\n",
    "        file_summary = open('/Users/krahman/work/fraud_detection/saved_files/df_scores_summary.txt', \"a\")\n",
    "        file_summary.write('New features created from: ' \n",
    "                           + fe.str_list_col_fe \n",
    "                           + '\\n')\n",
    "        file_summary.write(classif_report)\n",
    "        file_summary.close()\n",
    "        \n",
    "    def _feature_importance(self, model):\n",
    "        '''create feature importance dataframe and bar plot'''\n",
    "        try:\n",
    "            df_feat_rank = self._feat_import_create_df(model)\n",
    "            self._feat_import_create_plot(df_feat_rank)\n",
    "            print(df_feat_rank[0:10].reset_index(drop=True))\n",
    "        except:\n",
    "            print(\"\\nmodel does not have _feature_importance attribute.\")\n",
    "        \n",
    "    def _feat_import_create_df(self, model):\n",
    "        '''creating dataframe of important features'''\n",
    "        col_name = pd.Series(fe.df_feat.columns, name='col')\n",
    "        col_feat_rank = pd.Series(model.feature_importances_, \n",
    "                                  name='feat_rank')\n",
    "        df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1)\n",
    "        df_feat_rank = df_feat_rank.sort_values('feat_rank', ascending=False)\n",
    "        return df_feat_rank\n",
    "    \n",
    "    def _feat_import_create_plot(self, df_feat_rank):\n",
    "        '''create feature importance bar plot'''\n",
    "        plt.figure(figsize=(5,6))\n",
    "        sns.barplot(df_feat_rank.feat_rank[0:10],\n",
    "                    df_feat_rank.col[0:10],\n",
    "                    palette='Blues_d')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "        \n",
    "mod = Model(bool_smote=True)      \n",
    "\n",
    "# then Consider creating fe from TransactionAmt\n",
    "# NEXT, do more EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgbc = XGBClassifier()\n",
    "# model_xgbc.fit(mod.X_train, mod.y_train)\n",
    "# y_pred_xgbc = model_xgbc.predict(mod.X_test)\n",
    "# print(classification_report(mod.y_test, y_pred_xgbc))\n",
    "# print(confusion_matrix(mod.y_test, y_pred_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cbc = CatBoostClassifier()\n",
    "# model_cbc.fit(mod.X_train, mod.y_train)\n",
    "# y_pred_cbc = model_cbc.predict(mod.y_test)\n",
    "# print(classification_report(mod.y_test, y_pred_cbc))\n",
    "# print(confusion_matrix(mod.y_test, y_pred_cbc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT, before we keep tuning, we need to score on whole dataframe, so fix and test our method...\n",
    "# then we. need to add roc_score to tuning method... or once we get rfc results we can test to see if\n",
    "# it makes a difference or see if there is some kind of built in method we can use. \n",
    "\n",
    "# NEXT, we need to set up tuning for LogisticRegression, then XGBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a6a980f0f196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Tuning XGBClassifier READY ###\n",
    "print('tuning xgbc')\n",
    "xgbc = XGBClassifier(n_jobs=7, random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "learning_rate = [0,.1,.3,.5,.7,.9]\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "subsample = [1,3,5,7]\n",
    "colsample_bytree = [1,3,5,7]\n",
    "colsample_bylevel = [0,.1,.3,.5,.7,.9,1]\n",
    "colsample_bynode = [1,3,5,7]\n",
    "reg_alpha = [0,1,3,5,7]\n",
    "reg_lambda = [1,3,5,7]\n",
    "scale_pos_weight = [1,3,5,7]\n",
    "base_score = [.1,.2,.3,.4,.5]\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, learning_rate=learning_rate, booster=booster, \n",
    "                       subsample=subsample, colsample_bytree=colsample_bytree, \n",
    "                       colsample_bylevel=colsample_bylevel, colsample_bynode=colsample_bynode,\n",
    "                       reg_alpha=reg_alpha, reg_lambda=reg_lambda, scale_pos_weight=scale_pos_weight,\n",
    "                       base_score=base_score\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(xgbc, hyperparameters, random_state=42, cv=5, verbose=1, n_jobs=7, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best booster:', best_model.best_estimator_.get_params()['booster'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print('Best colsample_bytree:', best_model.best_estimator_.get_params()['colsample_bytree'])\n",
    "print('Best colsample_bylevel:', best_model.best_estimator_.get_params()['colsample_bylevel'])\n",
    "print('Best colsample_bynode:', best_model.best_estimator_.get_params()['colsample_bynode'])\n",
    "print('Best reg_alpha:', best_model.best_estimator_.get_params()['reg_alpha'])\n",
    "print('Best reg_lambda:', best_model.best_estimator_.get_params()['reg_lambda'])\n",
    "print('Best scale_pos_weight:', best_model.best_estimator_.get_params()['scale_pos_weight'])\n",
    "print('Best base_score:', best_model.best_estimator_.get_params()['base_score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Tuning RandomForestClassifier READY ####\n",
    "rfc = RandomForestClassifier(oob_score=False, n_jobs=7, random_state=42, verbose=1)\n",
    "\n",
    "n_estimators = [50,75,100,125,150,200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [3,5,7,9,11,13,15, None]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8,10]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_leaf_nodes = [2,3,5,7,9,None]\n",
    "min_impurity_decrease = [0,.1,.3,.5,.7,.9]\n",
    "\n",
    "# n_estimators = [50,75,100,125]\n",
    "# criterion = ['gini']\n",
    "# max_depth = [2,3,4,5,6,7,None]\n",
    "# min_samples_split = [6,7,8,9]\n",
    "# min_samples_leaf = [1,2]\n",
    "# min_weight_fraction_leaf = [0]\n",
    "# max_features = ['auto', 'sqrt', 'log2', None]\n",
    "# max_leaf_nodes = [None]\n",
    "# min_impurity_decrease = [0]\n",
    "\n",
    "hyperparameters = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split,\n",
    "                       min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, max_leaf_nodes=max_leaf_nodes,\n",
    "                       min_impurity_decrease=min_impurity_decrease\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(rfc, hyperparameters, random_state=42, cv=5, verbose=5, n_jobs=7, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best max_leaf_nodes:', best_model.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print('Best min_impurity_decrease:', best_model.best_estimator_.get_params()['min_impurity_decrease'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed: 32.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-59164be529d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### LR Tuning ####\n",
    "lr = LogisticRegression(n_jobs=7, random_state=42, verbose=1)\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "tol = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "C = [1e-1,.2,.3,.5,.7,1]\n",
    "fit_intercept = [True,False]\n",
    "intercept_scaling = [1,.1,.01,.001]\n",
    "class_weight = ['balanced', None]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "max_iter = [50,75,100,150,200]\n",
    "multi_class = ['auto', 'ovr', 'multinomial']\n",
    "l1_ratio = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "\n",
    "\n",
    "hyperparameters = dict(penalty=penalty, tol=tol, C=C, \n",
    "                       fit_intercept=fit_intercept,\n",
    "                       intercept_scaling=intercept_scaling, class_weight=class_weight,\n",
    "                       solver=solver, max_iter=max_iter,\n",
    "                       multi_class=multi_class, l1_ratio=l1_ratio\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(lr, hyperparameters, random_state=42, cv=5, verbose=10, n_jobs=7, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best tol:', best_model.best_estimator_.get_params()['tol'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best fit_intercept:', best_model.best_estimator_.get_params()['fit_intercept'])\n",
    "print('Best intercept_scaling:', best_model.best_estimator_.get_params()['intercept_scaling'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best solver:', best_model.best_estimator_.get_params()['solver'])\n",
    "print('Best max_iter:', best_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best multi_class:', best_model.best_estimator_.get_params()['multi_class'])\n",
    "print('Best l1_ratio:', best_model.best_estimator_.get_params()['l1_ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 36.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d6ef713a829c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### Tuning DTC READY ####\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [3,5,7,9,11, None]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,3,5,7,9]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "class_weight = ['balanced', None]\n",
    "\n",
    "hyperparameters = dict(criterion=criterion, splitter=splitter, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                       min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, class_weight=class_weight\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(dt, hyperparameters, random_state=42, cv=5, verbose=10, n_jobs=7, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best splitter:', best_model.best_estimator_.get_params()['splitter'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6544898\ttotal: 929ms\tremaining: 15m 27s\n",
      "1:\tlearn: 0.6249446\ttotal: 1.84s\tremaining: 15m 16s\n",
      "2:\tlearn: 0.6016028\ttotal: 3.28s\tremaining: 18m 10s\n",
      "3:\tlearn: 0.5816481\ttotal: 4.46s\tremaining: 18m 31s\n",
      "4:\tlearn: 0.5655440\ttotal: 6.06s\tremaining: 20m 5s\n",
      "5:\tlearn: 0.5526336\ttotal: 7s\tremaining: 19m 18s\n",
      "6:\tlearn: 0.5399379\ttotal: 7.87s\tremaining: 18m 36s\n",
      "7:\tlearn: 0.5300839\ttotal: 8.72s\tremaining: 18m 1s\n",
      "8:\tlearn: 0.5214796\ttotal: 9.47s\tremaining: 17m 23s\n",
      "9:\tlearn: 0.5139839\ttotal: 10.2s\tremaining: 16m 50s\n",
      "10:\tlearn: 0.5073609\ttotal: 11.2s\tremaining: 16m 43s\n",
      "11:\tlearn: 0.5022986\ttotal: 12.4s\tremaining: 17m 1s\n",
      "12:\tlearn: 0.4973163\ttotal: 13.7s\tremaining: 17m 23s\n",
      "13:\tlearn: 0.4925372\ttotal: 14.8s\tremaining: 17m 20s\n",
      "14:\tlearn: 0.4885491\ttotal: 16s\tremaining: 17m 28s\n",
      "15:\tlearn: 0.4846308\ttotal: 16.8s\tremaining: 17m 12s\n",
      "16:\tlearn: 0.4813124\ttotal: 17.7s\tremaining: 17m 2s\n",
      "17:\tlearn: 0.4783247\ttotal: 19.5s\tremaining: 17m 41s\n",
      "18:\tlearn: 0.4754238\ttotal: 20.3s\tremaining: 17m 28s\n",
      "19:\tlearn: 0.4724263\ttotal: 21s\tremaining: 17m 9s\n",
      "20:\tlearn: 0.4699991\ttotal: 22s\tremaining: 17m 5s\n",
      "21:\tlearn: 0.4677904\ttotal: 23s\tremaining: 17m 1s\n",
      "22:\tlearn: 0.4655596\ttotal: 23.9s\tremaining: 16m 55s\n",
      "23:\tlearn: 0.4634476\ttotal: 24.9s\tremaining: 16m 53s\n",
      "24:\tlearn: 0.4615865\ttotal: 29s\tremaining: 18m 49s\n",
      "25:\tlearn: 0.4598072\ttotal: 30s\tremaining: 18m 43s\n",
      "26:\tlearn: 0.4582196\ttotal: 31s\tremaining: 18m 37s\n",
      "27:\tlearn: 0.4566503\ttotal: 31.8s\tremaining: 18m 23s\n",
      "28:\tlearn: 0.4546688\ttotal: 33.9s\tremaining: 18m 53s\n",
      "29:\tlearn: 0.4532058\ttotal: 36.1s\tremaining: 19m 28s\n",
      "30:\tlearn: 0.4517481\ttotal: 39.8s\tremaining: 20m 42s\n",
      "31:\tlearn: 0.4499908\ttotal: 41.2s\tremaining: 20m 45s\n",
      "32:\tlearn: 0.4486334\ttotal: 43.2s\tremaining: 21m 4s\n",
      "33:\tlearn: 0.4472402\ttotal: 48s\tremaining: 22m 43s\n",
      "34:\tlearn: 0.4458378\ttotal: 50.3s\tremaining: 23m 6s\n",
      "35:\tlearn: 0.4446040\ttotal: 52s\tremaining: 23m 11s\n",
      "36:\tlearn: 0.4433656\ttotal: 53s\tremaining: 22m 59s\n",
      "37:\tlearn: 0.4421346\ttotal: 53.9s\tremaining: 22m 43s\n",
      "38:\tlearn: 0.4406306\ttotal: 54.7s\tremaining: 22m 27s\n",
      "39:\tlearn: 0.4394255\ttotal: 55.4s\tremaining: 22m 10s\n",
      "40:\tlearn: 0.4382351\ttotal: 56.7s\tremaining: 22m 5s\n",
      "41:\tlearn: 0.4370122\ttotal: 58s\tremaining: 22m 2s\n",
      "42:\tlearn: 0.4360455\ttotal: 59.1s\tremaining: 21m 55s\n",
      "43:\tlearn: 0.4349355\ttotal: 1m\tremaining: 21m 46s\n",
      "44:\tlearn: 0.4337023\ttotal: 1m 1s\tremaining: 21m 40s\n",
      "45:\tlearn: 0.4325752\ttotal: 1m 2s\tremaining: 21m 31s\n",
      "46:\tlearn: 0.4315775\ttotal: 1m 3s\tremaining: 21m 26s\n",
      "47:\tlearn: 0.4306593\ttotal: 1m 4s\tremaining: 21m 15s\n",
      "48:\tlearn: 0.4295987\ttotal: 1m 5s\tremaining: 21m 3s\n",
      "49:\tlearn: 0.4285603\ttotal: 1m 5s\tremaining: 20m 52s\n",
      "50:\tlearn: 0.4274367\ttotal: 1m 6s\tremaining: 20m 39s\n",
      "51:\tlearn: 0.4264201\ttotal: 1m 7s\tremaining: 20m 33s\n",
      "52:\tlearn: 0.4254559\ttotal: 1m 8s\tremaining: 20m 27s\n",
      "53:\tlearn: 0.4246262\ttotal: 1m 9s\tremaining: 20m 22s\n",
      "54:\tlearn: 0.4237910\ttotal: 1m 10s\tremaining: 20m 10s\n",
      "55:\tlearn: 0.4227272\ttotal: 1m 11s\tremaining: 19m 59s\n",
      "56:\tlearn: 0.4218597\ttotal: 1m 11s\tremaining: 19m 49s\n",
      "57:\tlearn: 0.4209131\ttotal: 1m 12s\tremaining: 19m 40s\n",
      "58:\tlearn: 0.4198247\ttotal: 1m 13s\tremaining: 19m 38s\n",
      "59:\tlearn: 0.4189717\ttotal: 1m 14s\tremaining: 19m 29s\n",
      "60:\tlearn: 0.4181890\ttotal: 1m 15s\tremaining: 19m 23s\n",
      "61:\tlearn: 0.4172957\ttotal: 1m 16s\tremaining: 19m 18s\n",
      "62:\tlearn: 0.4164701\ttotal: 1m 17s\tremaining: 19m 9s\n",
      "63:\tlearn: 0.4157742\ttotal: 1m 18s\tremaining: 19m 2s\n",
      "64:\tlearn: 0.4149257\ttotal: 1m 18s\tremaining: 18m 55s\n",
      "65:\tlearn: 0.4141992\ttotal: 1m 19s\tremaining: 18m 49s\n",
      "66:\tlearn: 0.4133184\ttotal: 1m 21s\tremaining: 18m 51s\n",
      "67:\tlearn: 0.4126194\ttotal: 1m 21s\tremaining: 18m 43s\n",
      "68:\tlearn: 0.4117358\ttotal: 1m 22s\tremaining: 18m 37s\n",
      "69:\tlearn: 0.4110941\ttotal: 1m 23s\tremaining: 18m 34s\n",
      "70:\tlearn: 0.4103729\ttotal: 1m 25s\tremaining: 18m 36s\n",
      "71:\tlearn: 0.4096460\ttotal: 1m 26s\tremaining: 18m 29s\n",
      "72:\tlearn: 0.4090022\ttotal: 1m 27s\tremaining: 18m 24s\n",
      "73:\tlearn: 0.4083597\ttotal: 1m 28s\tremaining: 18m 28s\n",
      "74:\tlearn: 0.4076587\ttotal: 1m 29s\tremaining: 18m 28s\n",
      "75:\tlearn: 0.4069607\ttotal: 1m 31s\tremaining: 18m 30s\n",
      "76:\tlearn: 0.4063452\ttotal: 1m 32s\tremaining: 18m 29s\n",
      "77:\tlearn: 0.4055970\ttotal: 1m 34s\tremaining: 18m 41s\n",
      "78:\tlearn: 0.4049149\ttotal: 1m 35s\tremaining: 18m 35s\n",
      "79:\tlearn: 0.4042575\ttotal: 1m 36s\tremaining: 18m 34s\n",
      "80:\tlearn: 0.4036332\ttotal: 1m 37s\tremaining: 18m 31s\n",
      "81:\tlearn: 0.4029529\ttotal: 1m 38s\tremaining: 18m 28s\n",
      "82:\tlearn: 0.4022831\ttotal: 1m 41s\tremaining: 18m 41s\n",
      "83:\tlearn: 0.4016826\ttotal: 1m 42s\tremaining: 18m 39s\n",
      "84:\tlearn: 0.4010603\ttotal: 1m 43s\tremaining: 18m 34s\n",
      "85:\tlearn: 0.4003440\ttotal: 1m 44s\tremaining: 18m 35s\n",
      "86:\tlearn: 0.3996621\ttotal: 1m 46s\tremaining: 18m 38s\n",
      "87:\tlearn: 0.3989743\ttotal: 1m 47s\tremaining: 18m 31s\n",
      "88:\tlearn: 0.3982979\ttotal: 1m 47s\tremaining: 18m 24s\n",
      "89:\tlearn: 0.3976863\ttotal: 1m 48s\tremaining: 18m 19s\n",
      "90:\tlearn: 0.3970910\ttotal: 1m 49s\tremaining: 18m 11s\n",
      "91:\tlearn: 0.3965277\ttotal: 1m 50s\tremaining: 18m 7s\n",
      "92:\tlearn: 0.3959545\ttotal: 1m 51s\tremaining: 18m 4s\n",
      "93:\tlearn: 0.3954749\ttotal: 1m 52s\tremaining: 18m\n",
      "94:\tlearn: 0.3949477\ttotal: 1m 53s\tremaining: 17m 56s\n",
      "95:\tlearn: 0.3943123\ttotal: 1m 53s\tremaining: 17m 51s\n",
      "96:\tlearn: 0.3936910\ttotal: 1m 54s\tremaining: 17m 46s\n",
      "97:\tlearn: 0.3931564\ttotal: 1m 56s\tremaining: 17m 50s\n",
      "98:\tlearn: 0.3925184\ttotal: 1m 57s\tremaining: 17m 47s\n",
      "99:\tlearn: 0.3920963\ttotal: 1m 58s\tremaining: 17m 42s\n",
      "100:\tlearn: 0.3914603\ttotal: 1m 59s\tremaining: 17m 41s\n",
      "101:\tlearn: 0.3908172\ttotal: 1m 59s\tremaining: 17m 36s\n",
      "102:\tlearn: 0.3901793\ttotal: 2m\tremaining: 17m 32s\n",
      "103:\tlearn: 0.3896633\ttotal: 2m 1s\tremaining: 17m 27s\n",
      "104:\tlearn: 0.3891509\ttotal: 2m 2s\tremaining: 17m 26s\n",
      "105:\tlearn: 0.3885342\ttotal: 2m 3s\tremaining: 17m 21s\n",
      "106:\tlearn: 0.3879950\ttotal: 2m 4s\tremaining: 17m 17s\n",
      "107:\tlearn: 0.3875249\ttotal: 2m 5s\tremaining: 17m 14s\n",
      "108:\tlearn: 0.3870410\ttotal: 2m 6s\tremaining: 17m 10s\n",
      "109:\tlearn: 0.3865044\ttotal: 2m 6s\tremaining: 17m 6s\n",
      "110:\tlearn: 0.3860675\ttotal: 2m 7s\tremaining: 17m 2s\n",
      "111:\tlearn: 0.3855363\ttotal: 2m 8s\tremaining: 17m 1s\n",
      "112:\tlearn: 0.3847900\ttotal: 2m 9s\tremaining: 16m 58s\n",
      "113:\tlearn: 0.3843631\ttotal: 2m 10s\tremaining: 16m 54s\n",
      "114:\tlearn: 0.3836895\ttotal: 2m 11s\tremaining: 16m 50s\n",
      "115:\tlearn: 0.3832519\ttotal: 2m 12s\tremaining: 16m 46s\n",
      "116:\tlearn: 0.3827539\ttotal: 2m 12s\tremaining: 16m 42s\n",
      "117:\tlearn: 0.3822310\ttotal: 2m 13s\tremaining: 16m 40s\n",
      "118:\tlearn: 0.3817794\ttotal: 2m 14s\tremaining: 16m 37s\n",
      "119:\tlearn: 0.3812554\ttotal: 2m 15s\tremaining: 16m 35s\n",
      "120:\tlearn: 0.3807018\ttotal: 2m 16s\tremaining: 16m 31s\n",
      "121:\tlearn: 0.3802297\ttotal: 2m 17s\tremaining: 16m 29s\n",
      "122:\tlearn: 0.3797872\ttotal: 2m 18s\tremaining: 16m 25s\n",
      "123:\tlearn: 0.3791538\ttotal: 2m 19s\tremaining: 16m 23s\n",
      "124:\tlearn: 0.3788130\ttotal: 2m 20s\tremaining: 16m 20s\n",
      "125:\tlearn: 0.3782852\ttotal: 2m 22s\tremaining: 16m 25s\n",
      "126:\tlearn: 0.3778452\ttotal: 2m 22s\tremaining: 16m 21s\n",
      "127:\tlearn: 0.3774106\ttotal: 2m 23s\tremaining: 16m 19s\n",
      "128:\tlearn: 0.3768847\ttotal: 2m 25s\tremaining: 16m 21s\n",
      "129:\tlearn: 0.3763915\ttotal: 2m 27s\tremaining: 16m 25s\n",
      "130:\tlearn: 0.3759411\ttotal: 2m 28s\tremaining: 16m 23s\n",
      "131:\tlearn: 0.3753790\ttotal: 2m 30s\tremaining: 16m 32s\n",
      "132:\tlearn: 0.3748694\ttotal: 2m 35s\tremaining: 16m 50s\n",
      "133:\tlearn: 0.3743144\ttotal: 2m 35s\tremaining: 16m 47s\n",
      "134:\tlearn: 0.3738697\ttotal: 2m 36s\tremaining: 16m 44s\n",
      "135:\tlearn: 0.3734295\ttotal: 2m 37s\tremaining: 16m 40s\n",
      "136:\tlearn: 0.3730334\ttotal: 2m 38s\tremaining: 16m 35s\n",
      "137:\tlearn: 0.3726366\ttotal: 2m 39s\tremaining: 16m 33s\n",
      "138:\tlearn: 0.3721977\ttotal: 2m 41s\tremaining: 16m 38s\n",
      "139:\tlearn: 0.3716295\ttotal: 2m 42s\tremaining: 16m 37s\n",
      "140:\tlearn: 0.3711727\ttotal: 2m 50s\tremaining: 17m 20s\n",
      "141:\tlearn: 0.3706175\ttotal: 2m 52s\tremaining: 17m 19s\n",
      "142:\tlearn: 0.3701167\ttotal: 2m 53s\tremaining: 17m 19s\n",
      "143:\tlearn: 0.3695305\ttotal: 2m 54s\tremaining: 17m 15s\n",
      "144:\tlearn: 0.3691208\ttotal: 2m 55s\tremaining: 17m 14s\n",
      "145:\tlearn: 0.3686021\ttotal: 2m 56s\tremaining: 17m 13s\n",
      "146:\tlearn: 0.3681912\ttotal: 2m 57s\tremaining: 17m 10s\n",
      "147:\tlearn: 0.3678040\ttotal: 2m 58s\tremaining: 17m 6s\n",
      "148:\tlearn: 0.3674129\ttotal: 2m 59s\tremaining: 17m 3s\n",
      "149:\tlearn: 0.3669816\ttotal: 2m 59s\tremaining: 16m 59s\n",
      "150:\tlearn: 0.3665906\ttotal: 3m\tremaining: 16m 55s\n",
      "151:\tlearn: 0.3661955\ttotal: 3m 1s\tremaining: 16m 52s\n",
      "152:\tlearn: 0.3657406\ttotal: 3m 2s\tremaining: 16m 49s\n",
      "153:\tlearn: 0.3652479\ttotal: 3m 4s\tremaining: 16m 50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154:\tlearn: 0.3647690\ttotal: 3m 5s\tremaining: 16m 49s\n",
      "155:\tlearn: 0.3643453\ttotal: 3m 6s\tremaining: 16m 48s\n",
      "156:\tlearn: 0.3639767\ttotal: 3m 7s\tremaining: 16m 48s\n",
      "157:\tlearn: 0.3635476\ttotal: 3m 8s\tremaining: 16m 46s\n",
      "158:\tlearn: 0.3632361\ttotal: 3m 9s\tremaining: 16m 43s\n",
      "159:\tlearn: 0.3627946\ttotal: 3m 11s\tremaining: 16m 42s\n",
      "160:\tlearn: 0.3622907\ttotal: 3m 11s\tremaining: 16m 40s\n",
      "161:\tlearn: 0.3618861\ttotal: 3m 12s\tremaining: 16m 36s\n",
      "162:\tlearn: 0.3615091\ttotal: 3m 13s\tremaining: 16m 32s\n",
      "163:\tlearn: 0.3611054\ttotal: 3m 14s\tremaining: 16m 29s\n",
      "164:\tlearn: 0.3607151\ttotal: 3m 15s\tremaining: 16m 26s\n",
      "165:\tlearn: 0.3602508\ttotal: 3m 17s\tremaining: 16m 30s\n",
      "166:\tlearn: 0.3598519\ttotal: 3m 17s\tremaining: 16m 26s\n",
      "167:\tlearn: 0.3595129\ttotal: 3m 19s\tremaining: 16m 26s\n",
      "168:\tlearn: 0.3591616\ttotal: 3m 20s\tremaining: 16m 26s\n",
      "169:\tlearn: 0.3587460\ttotal: 3m 23s\tremaining: 16m 31s\n",
      "170:\tlearn: 0.3583586\ttotal: 3m 25s\tremaining: 16m 35s\n",
      "171:\tlearn: 0.3579535\ttotal: 3m 27s\tremaining: 16m 37s\n",
      "172:\tlearn: 0.3575351\ttotal: 3m 29s\tremaining: 16m 40s\n",
      "173:\tlearn: 0.3571961\ttotal: 3m 30s\tremaining: 16m 41s\n",
      "174:\tlearn: 0.3567913\ttotal: 3m 32s\tremaining: 16m 40s\n",
      "175:\tlearn: 0.3563737\ttotal: 3m 33s\tremaining: 16m 39s\n",
      "176:\tlearn: 0.3558938\ttotal: 3m 34s\tremaining: 16m 38s\n",
      "177:\tlearn: 0.3555299\ttotal: 3m 35s\tremaining: 16m 36s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7312bd78e607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_cbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_cbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   3842\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   3843\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3844\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   3845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m             )\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_cbc = CatBoostClassifier(learning_rate=.1, random_state=42, thread_count=-1)\n",
    "model_cbc.fit(mod.X_features, mod.y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cbc = model_cbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(mod.y_test, pred_cbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed: 11.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-292af29b995b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Tuning CatBoost READY ###\n",
    "# Tune learning rate manually.\n",
    "cbc = CatBoostClassifier(random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "# learning_rate = [.1,.3,.5,.7,.9]\n",
    "# bagging_temperature = []\n",
    "subsample = [1,3,5,7]\n",
    "n_estimators = [50,75,100,150]\n",
    "depth = [2,4,6,8,10]\n",
    "grow_policy = ['SymmetricTree', 'Depthwise', 'Lossguide']\n",
    "\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, \n",
    "#                        learning_rate=learning_rate, \n",
    "                       n_estimators=n_estimators,\n",
    "                       subsample=subsample,\n",
    "                       depth=depth,\n",
    "                       grow_policy=grow_policy\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(cbc, hyperparameters, random_state=42, cv=5, verbose=10, n_jobs=7, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbc.fit(x)\n",
    "mod.X_train, mod.X_test, mod.y_train, mod.y_test = train_test_split(mod.X_features, \n",
    "                                                                    mod.y_target, \n",
    "                                                                            test_size=0.1, \n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.198909\n",
      "0:\tlearn: 0.6219019\ttotal: 1.15s\tremaining: 19m 8s\n",
      "1:\tlearn: 0.5770163\ttotal: 2.99s\tremaining: 24m 51s\n",
      "2:\tlearn: 0.5487995\ttotal: 4.41s\tremaining: 24m 25s\n",
      "3:\tlearn: 0.5278432\ttotal: 5.62s\tremaining: 23m 19s\n",
      "4:\tlearn: 0.5132952\ttotal: 7.21s\tremaining: 23m 54s\n",
      "5:\tlearn: 0.5014962\ttotal: 8.52s\tremaining: 23m 31s\n",
      "6:\tlearn: 0.4926963\ttotal: 9.61s\tremaining: 22m 43s\n",
      "7:\tlearn: 0.4847921\ttotal: 10.6s\tremaining: 21m 59s\n",
      "8:\tlearn: 0.4778748\ttotal: 11.7s\tremaining: 21m 33s\n",
      "9:\tlearn: 0.4731304\ttotal: 13s\tremaining: 21m 28s\n",
      "10:\tlearn: 0.4687837\ttotal: 14s\tremaining: 20m 57s\n",
      "11:\tlearn: 0.4648911\ttotal: 15s\tremaining: 20m 32s\n",
      "12:\tlearn: 0.4612255\ttotal: 15.9s\tremaining: 20m 10s\n",
      "13:\tlearn: 0.4581508\ttotal: 16.9s\tremaining: 19m 49s\n",
      "14:\tlearn: 0.4548853\ttotal: 18.8s\tremaining: 20m 37s\n",
      "15:\tlearn: 0.4513931\ttotal: 20.5s\tremaining: 21m 1s\n",
      "16:\tlearn: 0.4485468\ttotal: 22s\tremaining: 21m 12s\n",
      "17:\tlearn: 0.4457924\ttotal: 23.6s\tremaining: 21m 29s\n",
      "18:\tlearn: 0.4435485\ttotal: 24.8s\tremaining: 21m 20s\n",
      "19:\tlearn: 0.4408056\ttotal: 26.2s\tremaining: 21m 21s\n",
      "20:\tlearn: 0.4386588\ttotal: 27.2s\tremaining: 21m 7s\n",
      "21:\tlearn: 0.4360782\ttotal: 29s\tremaining: 21m 27s\n",
      "22:\tlearn: 0.4341444\ttotal: 30.4s\tremaining: 21m 29s\n",
      "23:\tlearn: 0.4324119\ttotal: 31.7s\tremaining: 21m 30s\n",
      "24:\tlearn: 0.4304954\ttotal: 32.8s\tremaining: 21m 19s\n",
      "25:\tlearn: 0.4286690\ttotal: 35.1s\tremaining: 21m 53s\n",
      "26:\tlearn: 0.4266650\ttotal: 36.3s\tremaining: 21m 49s\n",
      "27:\tlearn: 0.4245514\ttotal: 37.6s\tremaining: 21m 46s\n",
      "28:\tlearn: 0.4225834\ttotal: 39.4s\tremaining: 22m\n",
      "29:\tlearn: 0.4206739\ttotal: 40.9s\tremaining: 22m 3s\n",
      "30:\tlearn: 0.4192401\ttotal: 51.6s\tremaining: 26m 52s\n",
      "31:\tlearn: 0.4175912\ttotal: 55.9s\tremaining: 28m 10s\n",
      "32:\tlearn: 0.4159407\ttotal: 58.7s\tremaining: 28m 39s\n",
      "33:\tlearn: 0.4142996\ttotal: 59.9s\tremaining: 28m 20s\n",
      "34:\tlearn: 0.4129588\ttotal: 1m 1s\tremaining: 28m 6s\n",
      "35:\tlearn: 0.4116308\ttotal: 1m 2s\tremaining: 27m 42s\n",
      "36:\tlearn: 0.4101913\ttotal: 1m 3s\tremaining: 27m 26s\n",
      "37:\tlearn: 0.4087311\ttotal: 1m 5s\tremaining: 27m 28s\n",
      "38:\tlearn: 0.4074890\ttotal: 1m 7s\tremaining: 27m 47s\n",
      "39:\tlearn: 0.4061440\ttotal: 1m 10s\tremaining: 28m 15s\n",
      "40:\tlearn: 0.4046624\ttotal: 1m 12s\tremaining: 28m 8s\n",
      "41:\tlearn: 0.4033471\ttotal: 1m 13s\tremaining: 27m 52s\n",
      "42:\tlearn: 0.4022624\ttotal: 1m 15s\tremaining: 27m 56s\n",
      "43:\tlearn: 0.4010182\ttotal: 1m 16s\tremaining: 27m 35s\n",
      "44:\tlearn: 0.4000519\ttotal: 1m 17s\tremaining: 27m 14s\n",
      "45:\tlearn: 0.3986671\ttotal: 1m 18s\tremaining: 26m 58s\n",
      "46:\tlearn: 0.3976661\ttotal: 1m 18s\tremaining: 26m 36s\n",
      "47:\tlearn: 0.3965950\ttotal: 1m 19s\tremaining: 26m 17s\n",
      "48:\tlearn: 0.3953500\ttotal: 1m 20s\tremaining: 26m\n",
      "49:\tlearn: 0.3945444\ttotal: 1m 21s\tremaining: 25m 57s\n",
      "50:\tlearn: 0.3934454\ttotal: 1m 22s\tremaining: 25m 41s\n",
      "51:\tlearn: 0.3925008\ttotal: 1m 23s\tremaining: 25m 25s\n",
      "52:\tlearn: 0.3914799\ttotal: 1m 24s\tremaining: 25m 11s\n",
      "53:\tlearn: 0.3903989\ttotal: 1m 25s\tremaining: 25m\n",
      "54:\tlearn: 0.3893911\ttotal: 1m 26s\tremaining: 24m 46s\n",
      "55:\tlearn: 0.3880870\ttotal: 1m 27s\tremaining: 24m 34s\n",
      "56:\tlearn: 0.3870868\ttotal: 1m 28s\tremaining: 24m 29s\n",
      "57:\tlearn: 0.3859613\ttotal: 1m 29s\tremaining: 24m 15s\n",
      "58:\tlearn: 0.3851009\ttotal: 1m 30s\tremaining: 24m 3s\n",
      "59:\tlearn: 0.3841726\ttotal: 1m 31s\tremaining: 23m 54s\n",
      "60:\tlearn: 0.3830669\ttotal: 1m 32s\tremaining: 23m 43s\n",
      "61:\tlearn: 0.3821886\ttotal: 1m 33s\tremaining: 23m 32s\n",
      "62:\tlearn: 0.3812590\ttotal: 1m 34s\tremaining: 23m 21s\n",
      "63:\tlearn: 0.3802570\ttotal: 1m 35s\tremaining: 23m 11s\n",
      "64:\tlearn: 0.3795124\ttotal: 1m 36s\tremaining: 23m 1s\n",
      "65:\tlearn: 0.3784728\ttotal: 1m 36s\tremaining: 22m 49s\n",
      "66:\tlearn: 0.3775095\ttotal: 1m 37s\tremaining: 22m 40s\n",
      "67:\tlearn: 0.3762324\ttotal: 1m 38s\tremaining: 22m 30s\n",
      "68:\tlearn: 0.3752329\ttotal: 1m 39s\tremaining: 22m 23s\n",
      "69:\tlearn: 0.3744043\ttotal: 1m 41s\tremaining: 22m 23s\n",
      "70:\tlearn: 0.3733506\ttotal: 1m 42s\tremaining: 22m 14s\n",
      "71:\tlearn: 0.3725059\ttotal: 1m 42s\tremaining: 22m 6s\n",
      "72:\tlearn: 0.3715987\ttotal: 1m 44s\tremaining: 22m 3s\n",
      "73:\tlearn: 0.3705243\ttotal: 1m 45s\tremaining: 21m 57s\n",
      "74:\tlearn: 0.3697112\ttotal: 1m 46s\tremaining: 21m 50s\n",
      "75:\tlearn: 0.3688739\ttotal: 1m 47s\tremaining: 21m 42s\n",
      "76:\tlearn: 0.3680698\ttotal: 1m 48s\tremaining: 21m 46s\n",
      "77:\tlearn: 0.3672675\ttotal: 1m 50s\tremaining: 21m 47s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-526be3d2b023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# cbc.predict(mod.X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   3842\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   3843\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3844\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   3845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m             )\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cbc.fit(mod.X_train, mod.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cbc = cbc.predict(mod.X_test)\n",
    "confusion_matrix(y_test, pred_cbc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "                       oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "roc score: 0.7653269954567143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     56945\n",
      "           1       0.57      0.55      0.56      2109\n",
      "\n",
      "    accuracy                           0.97     59054\n",
      "   macro avg       0.78      0.77      0.77     59054\n",
      "weighted avg       0.97      0.97      0.97     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "333     addr1_fe  682.0  19343.0   0.068705  0.676624            3.852398   \n",
      "334     addr1_fe  360.0  30387.0   0.054425  0.829303            4.896017   \n",
      "335  model score  958.0    860.0   0.572352  0.545756            4.096957   \n",
      "336          NaN  958.0    860.0   0.572352  0.545756            3.928485   \n",
      "0            NaN  958.0    860.0   0.572352  0.545756            4.159219   \n",
      "\n",
      "         tn       tp  \n",
      "333  1427.0  37602.0  \n",
      "334  1749.0  26558.0  \n",
      "335  1151.0  56085.0  \n",
      "336  1151.0  56085.0  \n",
      "0    1151.0  56085.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              col  feat_rank\n",
      "0   TransactionDT   0.036505\n",
      "1   TransactionID   0.032122\n",
      "2         isFraud   0.030023\n",
      "3              V1   0.019718\n",
      "4             V69   0.017775\n",
      "5             V14   0.017476\n",
      "6  TransactionAmt   0.016972\n",
      "7             V12   0.014583\n",
      "8           card5   0.011881\n",
      "9           card1   0.011186\n",
      "Fitting model:\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "                       oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "roc score: 0.7653269954567143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     56945\n",
      "           1       0.57      0.55      0.56      2109\n",
      "\n",
      "    accuracy                           0.97     59054\n",
      "   macro avg       0.78      0.77      0.77     59054\n",
      "weighted avg       0.97      0.97      0.97     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "334     addr1_fe  360.0  30387.0   0.054425  0.829303            4.896017   \n",
      "335  model score  958.0    860.0   0.572352  0.545756            4.096957   \n",
      "336          NaN  958.0    860.0   0.572352  0.545756            3.928485   \n",
      "337          NaN  958.0    860.0   0.572352  0.545756            4.159219   \n",
      "0            NaN  958.0    860.0   0.572352  0.545756            4.155328   \n",
      "\n",
      "         tn       tp  \n",
      "334  1749.0  26558.0  \n",
      "335  1151.0  56085.0  \n",
      "336  1151.0  56085.0  \n",
      "337  1151.0  56085.0  \n",
      "0    1151.0  56085.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              col  feat_rank\n",
      "0   TransactionDT   0.036505\n",
      "1   TransactionID   0.032122\n",
      "2         isFraud   0.030023\n",
      "3              V1   0.019718\n",
      "4             V69   0.017775\n",
      "5             V14   0.017476\n",
      "6  TransactionAmt   0.016972\n",
      "7             V12   0.014583\n",
      "8           card5   0.011881\n",
      "9           card1   0.011186\n"
     ]
    }
   ],
   "source": [
    "# bool_predict_proba = False\n",
    "# # tuned model\n",
    "# current_model = RandomForestClassifier(\n",
    "#                        max_depth=3, max_features='log2',\n",
    "#                        min_impurity_decrease=0.0, \n",
    "#                        min_samples_leaf=1, min_samples_split=7,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=50,\n",
    "#                        n_jobs=-1, oob_score=False, random_state=42,\n",
    "#                        verbose=0, warm_start=False)\n",
    "# mod.create_df_score_model(model_current)\n",
    "\n",
    "# # base model\n",
    "# current_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.create_df_score_model(df_feat)\n",
    "# 369.0 all col\n",
    "# 398.0 remove P_emaildomain\n",
    "# 410.0 remove card6\n",
    "# 395.0 drop C4\n",
    "# 415.0 add all back in\n",
    "# 368.0 test again with C14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create feature from TransactionAmt. Add more EDA information. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Tuning\n",
    "# 2. Finished - Features\n",
    "# 3. more EDA\n",
    "# 4. Finished - move pca and smote into fe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_read = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "df_temp_read[len(df_temp_read)-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it reads the csv, creates a dataframe, then appends the results, then saves over the old version and keeps\n",
    "# # a record of all columns in the tested dataframe.\n",
    "\n",
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# # we want to test a feature for feature engineering... we must \n",
    "\n",
    "# for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "#     print(col_original, col_new)\n",
    "#     X[col_new] = fe.df_feat[col_new]\n",
    "#     X = X.drop(col_original, axis=1)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    \n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "# #     X = X.drop(col, axis=1)\n",
    "#     print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['time_delta'] = df_temp['time_delta']\n",
    "# fe.df_feat['time_delta_week'] = df_temp['time_delta']/7\n",
    "# fe.df_feat['time_delta_month'] = df_temp['time_delta']/30\n",
    "# fe.df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### implement into feature engineering class. days lapsed\n",
    "df_temp = fe.df_feat[['TransactionDT']]\n",
    "df_temp['time_delta'] = 0\n",
    "len_df_temp = df_temp.shape[0]\n",
    "for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "    val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "    val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "    val_time_delta = val_time_2 - val_time_1\n",
    "    df_temp.loc[i, 'time_delta'] = val_time_delta\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes, do we need to visualize our results?? We need to look at our confusion matrix\n",
    "# and decide how to improve our results from here... Test and see what happens if we \n",
    "# increase our principal components... test removing columns, adding columns, imputing\n",
    "# certain columns all together. \n",
    "\n",
    "# test imputing 500 or less for ohe. Then test dropping card1 due to its number\n",
    "# of unique values that would make our data very high dimensional. We can try only ohe for\n",
    "# the entire dataset to see how our model performs over all... Though.. it will likely run \n",
    "# out of memory and crash. \n",
    "\n",
    "# ALSO test probabilities on logisticregression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# plt.hist(y_pred_prob[:,1], bins=8)\n",
    "# plt.xlim(0,1)\n",
    "# plt.title(\"Histogram of Probability of Fraud\")\n",
    "# plt.xlabel(\"Predicted probability of Fraud\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "e\n",
    "\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.title(\"ROC curve for fraud detection classifier\")\n",
    "# plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "# plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_threshold(threshold):\n",
    "#     print(\"Sensitivity:\", tpr[thresholds > threshold][-1])\n",
    "#     print(\"Specificity:\", 1 - fpr[thresholds > threshold][-1],'\\n')\n",
    "    \n",
    "# evaluate_threshold(.5)\n",
    "# evaluate_threshold(.2)\n",
    "# evaluate_threshold(.1)\n",
    "\n",
    "# print(roc_auc_score(y, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_test2) # actual prediction test data set\n",
    "# print('y_pred_actual on test set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_actual))\n",
    "# print(classification_report(y_test2, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_test2)\n",
    "# y_pred_class = binarize(y_pred_proba, 0.5)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_class))\n",
    "# print(classification_report(y_test2, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_pca) # actual full data set\n",
    "# print('Logistic Regression')\n",
    "# print('y_pred_actual full data set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y, y_pred_actual))\n",
    "# print(classification_report(y, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba full data set\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_pca)#[:,1]#[0:10]\n",
    "# y_pred_class = binarize(y_pred_proba, 0.2)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='TransactionDT', y='TransactionDT', hue='isFraud', data=df_features)\n",
    "# plt.title(\"Transaction Date Versus Fraud\")\n",
    "# plt.show()\n",
    "\n",
    "# we want to figure out how to create more features from TransactionDT.. \n",
    "# are certain transactions more likely. in general, to be fraudualant around a certain day? \n",
    "# we have transactionID yet we dont have the specific card of who it belongs to.. \n",
    "# if card1 is the unique identifier... and we did a groupby on fraud.. \n",
    "# we have average spent per day as an option... \n",
    "# create a feature that is average spent per day for non fraud versus average spent per day for fraud.. \n",
    "# what would the describe method reveal for us? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
