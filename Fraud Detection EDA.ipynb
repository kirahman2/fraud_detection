{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_raw = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.info(); # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.info(); # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_null = df_train.isnull().any()\n",
    "# df_null = pd.DataFrame(list_null).reset_index()\n",
    "# df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.loc[:,df_train.isnull().any()]['id_34'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# train_transaction_sum = train_transaction.duplicated().sum()\n",
    "# train_identity_sum = train_identity.duplicated().sum()\n",
    "# columns = train_transaction.columns\n",
    "# print('Train transaction duplicates: {}\\nTrain identity duplicates: {} \\n'.format(train_transaction_sum, train_identity_sum))\n",
    "# # print('Train feature columns:\\n', list(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.dtypes # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many transactions are in the dataset?\n",
    "# df_train.shape # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the fraud rate of the data set?\n",
    "# fraud_rate = df_train.isFraud.value_counts() / 590540\n",
    "# fraud_rate  # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the statistical overview of the data set?\n",
    "# df_train.describe() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary = df_train.groupby('isFraud')\n",
    "# fraud_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_groupby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "# D = time elapsed between each transaction, card = card information, C = counting, ie how many addresses \n",
    "# associated with card, M=True/False, V created features on ranking, counting, etc. \n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# boolean columns. convert via dummy variable. We dont know if true/false is better than one or the other. \n",
    "# col_bool = col_m\n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))\n",
    "\n",
    "# columns removed dist1, dist2, R_emaildomain, DeviceInfo, DeviceType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 195 columns with null values.\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train.copy()\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "#                 self.list_mode_value.append('MISSING')\n",
    "\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "#                 print(\"fillna,\" + str(val))\n",
    "\n",
    "#                 self.df_train[val] = self.df_train[val].fillna('MISSING')\n",
    "    \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()\n",
    "# df_null_info\n",
    "\n",
    "# determine what to do with columns that have too many unique values... obviously.. types of solutions\n",
    "# would be to put \"MISSING\" for those that dont have an email address... but you will need to evaluate \n",
    "# and make instead a counter of unique values, then append that and look at the CSV via google sheets. use \n",
    "# something like the code below \n",
    "\n",
    "# TEST: test imputing with missing instead of mode to see if we have improvements in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoded: addr1 unique 333\n",
      "label encoded: addr2 unique 75\n",
      "dummies encoded: ProductCD unique 5\n",
      "dummies encoded: P_emaildomain unique 59\n",
      "label encoded: card1 unique 13553\n",
      "label encoded: card2 unique 501\n",
      "label encoded: card3 unique 115\n",
      "dummies encoded: card4 unique 4\n",
      "label encoded: card5 unique 120\n",
      "dummies encoded: card6 unique 4\n",
      "dummies encoded: M1 unique 2\n",
      "dummies encoded: M2 unique 2\n",
      "dummies encoded: M3 unique 2\n",
      "dummies encoded: M4 unique 3\n",
      "dummies encoded: M6 unique 2\n",
      "new dataframe shape:(590540, 285)\n"
     ]
    }
   ],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['addr1', 'addr2', 'ProductCD', 'P_emaildomain', 'card1', 'card2', 'card3', 'card4', \n",
    "#  'card5', 'card6', 'M1', 'M2', 'M3', 'M4', 'M6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>V40</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isFraud</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.221568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V40</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.213533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V44</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.515480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V45</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.608788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V51</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.196567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V52</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>0.207535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V86</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V87</td>\n",
       "      <td>0.221568</td>\n",
       "      <td>0.213533</td>\n",
       "      <td>0.515480</td>\n",
       "      <td>0.608788</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>0.207535</td>\n",
       "      <td>0.850021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          isFraud       V40       V44       V45       V51       V52       V86  \\\n",
       "isFraud  1.000000  0.174672  0.217870  0.235436  0.182007  0.195492  0.222343   \n",
       "V40      0.174672  1.000000  0.225232  0.271469  0.744831  0.745758  0.217055   \n",
       "V44      0.217870  0.225232  1.000000  0.905537  0.257145  0.251881  0.604776   \n",
       "V45      0.235436  0.271469  0.905537  1.000000  0.257400  0.296102  0.585396   \n",
       "V51      0.182007  0.744831  0.257145  0.257400  1.000000  0.954315  0.212453   \n",
       "V52      0.195492  0.745758  0.251881  0.296102  0.954315  1.000000  0.215183   \n",
       "V86      0.222343  0.217055  0.604776  0.585396  0.212453  0.215183  1.000000   \n",
       "V87      0.221568  0.213533  0.515480  0.608788  0.196567  0.207535  0.850021   \n",
       "\n",
       "              V87  \n",
       "isFraud  0.221568  \n",
       "V40      0.213533  \n",
       "V44      0.515480  \n",
       "V45      0.608788  \n",
       "V51      0.196567  \n",
       "V52      0.207535  \n",
       "V86      0.850021  \n",
       "V87      1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_summary = df_features.groupby('isFraud')\n",
    "fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_summary.csv')\n",
    "\n",
    "corr = df_features.corr()\n",
    "corr.to_csv('/Users/krahman/work/fraud_detection/saved_files/corr_matrix.csv')\n",
    "corr2 = corr[corr['isFraud']>.17]\n",
    "corr2 = corr2.loc[:,corr2.index]\n",
    "\n",
    "sns.heatmap(corr2,\n",
    "           xticklabels=corr2.columns.values,\n",
    "           yticklabels=corr2.columns.values)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,4))\n",
    "# sns.barplot(x='V44', y='V44', hue='isFraud', data=df_train)\n",
    "# plt.show()\n",
    "\n",
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X.card1, y)\n",
    "# sns.regplot(x='card5_237.0', y='isFraud', data=pp.df_train, logistic=True, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dropping Features On Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# y_test = pp.df_train[col_target] #.rename(columns=['isFraud'])\n",
    "# y_test = pd.Series(y_test)\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing dropping columns\n",
    "# model_lr_results = pd.DataFrame()\n",
    "# model_recall = []\n",
    "# model_precision = []\n",
    "# model_auc_score = []\n",
    "\n",
    "# for col in ['addr1', 'addr2', 'P_emaildomain', 'card1', 'card2', 'card3', 'card5']:\n",
    "#     print('Dropping: ', col)\n",
    "#     X_drop = X.drop(col, axis=1)\n",
    "# #     X_drop = X_drop.loc[:10000,:]\n",
    "#     y_drop = y#[:10001]\n",
    "    \n",
    "#     scaled_X = StandardScaler().fit_transform(X_drop)\n",
    "#     # pca\n",
    "#     pca = PCA()\n",
    "#     pcomponents = pca.fit_transform(scaled_X)\n",
    "#     X_pca = pd.DataFrame(data=pcomponents)\n",
    "#     # split\n",
    "#     X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y_drop, test_size=0.1, random_state=42)\n",
    "#     # smote\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "#     # model fit\n",
    "#     model_lr_pca = LogisticRegression(random_state=42)\n",
    "#     model_lr_pca.fit(X_train_res, y_train_res)\n",
    "#     # predict\n",
    "#     y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "#     y_pred_class = binarize(y_pred_prob, 0.5)[:,1]\n",
    "#     # scoring\n",
    "#     model_recall.append(recall_score(y_drop, y_pred_class))\n",
    "#     model_precision.append(precision_score(y_drop, y_pred_class))\n",
    "#     model_auc_score.append(roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "#     print(confusion_matrix(y_drop, y_pred_class))\n",
    "#     print(classification_report(y_drop, y_pred_class))\n",
    "#     print('AUC: ', roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "\n",
    "# model_recall = pd.Series(model_recall, name='recall')\n",
    "# model_precision = pd.Series(model_precision, name='precision')\n",
    "# model_auc_score = pd.Series(model_auc_score, name='auc_score')\n",
    "# model_results_final = pd.concat([model_auc_score, model_recall, model_precision],axis=1)\n",
    "# model_results_final\n",
    "\n",
    "# # it's apparent that label encoding on some of these don't really matter and if we drop them.. it doesn't really\n",
    "# # matter.. \n",
    "# # dropping these columns has little impact with logistic regression.. \n",
    "\n",
    "# # tune logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DELETE\n",
    "\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final\n",
    "\n",
    "# df_temp = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "# df_temp[0:20]\n",
    "# pd.DataFrame(pca.components_, columns=list(X_temp.columns), index=range(0,225))\n",
    "# pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA (2 components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardizing our data, which is required for PCA.\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # PCA instantiate and fit \n",
    "# pca = PCA(n_components=2)\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data = pcomponents, columns=['PC1','PC2'])\n",
    "# print(X_pca.shape)\n",
    "# X_pca.head()\n",
    "\n",
    "# # two principal components scatter plot\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.scatter(X_pca['PC1'], X_pca['PC2'], c=y['isFraud'])\n",
    "# plt.xlabel('First principal component')\n",
    "# plt.ylabel('Second principal component')\n",
    "\n",
    "# # explaining vaariance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to all features (all components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca2 = PCA().fit(scaled_X)\n",
    "# plt.plot(np.cumsum(pca2.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Variance (%)')\n",
    "# plt.title('Credit Card Fraud Explained Variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model w/ SMOTE only - base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # Apply SMOTE\n",
    "# sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train1, y_train1)\n",
    "\n",
    "# model_lr = LogisticRegression(random_state=42)\n",
    "# model_lr.fit(X_train_res, y_train_res) \n",
    "\n",
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using only SMOTE (and w/o PCA)\\n\")\n",
    "# y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_lr.score(X_test1, y_test1))\n",
    "# print(recall_score(y_test1, y_pred_test1))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test1, y_pred_test1))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test1, y_pred_test1))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred = model_lr.predict(X)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_lr.score(X, y))\n",
    "# print(recall_score(y, y_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression w/PCA  w/SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.title('addr1 versus addr2')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.title('Addr1 Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EDA Email Class\n",
    "# # P_emaildomain\n",
    "# # list(df_train.columns)\n",
    "# # df_train.P_emaildomain.unique()\n",
    "# list_perc = []\n",
    "# list_fraud_count = []\n",
    "# list_non_fraud_count = []\n",
    "# for val in df_train.P_emaildomain.unique():\n",
    "#     non_fraud_count = df_train[(df_train.P_emaildomain==val) & (df_train.isFraud==0)].shape[0]\n",
    "#     fraud_count = df_train[(df_train.P_emaildomain==val) & (df_train.isFraud==1)].shape[0]\n",
    "    \n",
    "#     list_perc.append(fraud_count/non_fraud_count)\n",
    "    \n",
    "#     list_fraud_count.append(fraud_count)\n",
    "#     list_non_fraud_count.append(non_fraud_count)\n",
    "    \n",
    "# col_email = pd.Series(df_train.P_emaildomain.unique(), name='email')\n",
    "# col_perc = pd.Series(list_perc, name='fraud_perc')\n",
    "# col_fraud_count = pd.Series(list_fraud_count, name='fraud_count')\n",
    "# col_non_fraud_count = pd.Series(list_non_fraud_count, name='non_fraud_count')\n",
    "\n",
    "# # col_perc\n",
    "# df_email_fe = pd.concat([col_email, col_perc, col_fraud_count, col_non_fraud_count], axis=1)\n",
    "# # df_email_fe\n",
    "# # df_train[(df_train.P_emaildomain=='outlook.com') & (df_train.isFraud==1)].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: less occurring email domains are more likely to have higher fraud_perc because they are \n",
    "# perhaps an email provider with less resources. The card that the holder has attached to certain email\n",
    "# addresses puts them at higher risk for fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# df_temp3 = df_features.copy()\n",
    "# df_temp3['ProductCD_copy'] = le.fit_transform(df_raw['ProductCD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete once finished. \n",
    "le = LabelEncoder()\n",
    "\n",
    "df_raw.card6 = df_raw.card6.fillna(df_raw.card6.mode()[0])\n",
    "df_raw.P_emaildomain = df_raw.P_emaildomain.fillna(df_raw.P_emaildomain.mode()[0])\n",
    "df_raw.ProductCD = df_raw.ProductCD.fillna(df_raw.ProductCD.mode()[0])\n",
    "\n",
    "df_features['P_emaildomain_copy'] = le.fit_transform(df_raw['P_emaildomain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a method that tacks on original imputed features from df_raw, imputes them, then tests them.. \n",
    "# then we need a method that creates and keeps these features. \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# we have tested the features that work and are good. We now need to create these features\n",
    "# as part of the dataset. \n",
    "\n",
    "for col in list_feat_test:\n",
    "    col_mode = df_raw[col].mode()[0]\n",
    "    df_raw[col] = df_raw[col].fillna(col_mode)\n",
    "    df_features[col] = le.fit_transform(df_raw[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new feature method needs to take the featre and append it to the main dataframe, all the features \n",
    "# we include, then it needs to save each of them, then score and give us results. Then it needs to take in\n",
    "# features that we want to take from df_raw and create new feature ratio from that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping original feature addr1\n",
      "['addr1']\n",
      "Creating new features from addr1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     56945\n",
      "           1       0.06      0.75      0.11      2109\n",
      "\n",
      "    accuracy                           0.56     59054\n",
      "   macro avg       0.52      0.66      0.41     59054\n",
      "weighted avg       0.95      0.56      0.69     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "200  model score    0.0     11.0   0.000000  0.000000            0.010611   \n",
      "201  model score    0.0      9.0   0.000000  0.000000            0.012445   \n",
      "202  model score    0.0     11.0   0.000000  0.000000            0.011636   \n",
      "203  model score    0.0      9.0   0.000000  0.000000            0.008117   \n",
      "0    model score  519.0  25234.0   0.059275  0.753912            2.458069   \n",
      "\n",
      "         tn       tp  \n",
      "200     0.0     89.0  \n",
      "201     0.0     91.0  \n",
      "202     0.0     89.0  \n",
      "203     0.0     91.0  \n",
      "0    1590.0  31711.0  \n",
      "Dropping original feature card2\n",
      "['addr1', 'card2']\n",
      "Creating new features from card2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.68      0.80     56945\n",
      "           1       0.07      0.69      0.13      2109\n",
      "\n",
      "    accuracy                           0.68     59054\n",
      "   macro avg       0.53      0.69      0.47     59054\n",
      "weighted avg       0.95      0.68      0.78     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "201  model score    0.0      9.0   0.000000  0.000000            0.012445   \n",
      "202  model score    0.0     11.0   0.000000  0.000000            0.011636   \n",
      "203  model score    0.0      9.0   0.000000  0.000000            0.008117   \n",
      "204  model score  519.0  25234.0   0.059275  0.753912            2.458069   \n",
      "0    model score  645.0  18222.0   0.074368  0.694168            4.479069   \n",
      "\n",
      "         tn       tp  \n",
      "201     0.0     91.0  \n",
      "202     0.0     89.0  \n",
      "203     0.0     91.0  \n",
      "204  1590.0  31711.0  \n",
      "0    1464.0  38723.0  \n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineering():\n",
    "    '''create new features for columns without ordinal values'''\n",
    "    def __init__(self):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.df_raw = df_raw.copy()\n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        \n",
    "        self.col = []\n",
    "        self.col_fe = []\n",
    "        self.df_new_feat = pd.DataFrame()\n",
    "        self.list_drop_col = []\n",
    "        self.str_list_col_fe = []\n",
    "\n",
    "    def feature_testing(self, bool_drop_col, list_feat):\n",
    "        '''testing and scoring new potential features'''\n",
    "        if list_feat:\n",
    "            for col in list_feat:\n",
    "                self.col_fe = col\n",
    "                if col in df_features.columns:\n",
    "                    df_feat = fe.create_test_feature(bool_drop_col, col)\n",
    "#                     df_feat = df_feat[0:1000] ### delete\n",
    "                    model.create_df_score_model(df_feat, list_feat)\n",
    "                else:\n",
    "                    print(\"\\nColumn\", col, \"does not exist in dataframe.\\n\")\n",
    "            self.col_fe = []\n",
    "            \n",
    "    def final_features(self, bool_drop_col, list_feat):\n",
    "        '''creates final new features'''\n",
    "        df_feat = fe.create_feature(bool_drop_col, list_feat)\n",
    "#         df_feat = df_feat[0:1000] ### delete \n",
    "        for col in list_feat:\n",
    "            col_fe = self._append_col_lists(col)\n",
    "            self._fill_na(df_feat, col_fe)\n",
    "            self._concat_df_new_feat(df_feat, col_fe)\n",
    "        self._convert_list_to_string(list_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def _append_col_lists(self, col):\n",
    "        '''appending columns and new feature column names'''\n",
    "        col_fe = col + '_fe'\n",
    "        self.col.append(col)\n",
    "        self.col_fe.append(col_fe)\n",
    "        return col_fe\n",
    "    \n",
    "    def _fill_na(self, df_feat, col_fe):\n",
    "        '''fill na values for new features'''\n",
    "        col_mode = df_feat[col_fe].mode()[0]\n",
    "        df_feat[col_fe] = df_feat[col_fe].fillna(col_mode)\n",
    "        \n",
    "    def _concat_df_new_feat(self, df_feat, col_fe):\n",
    "        '''adding new feauture columns to one dataframe'''\n",
    "        df_temp = df_feat[col_fe]\n",
    "        self.df_new_feat = pd.concat([self.df_new_feat, df_temp], axis=1)\n",
    "    \n",
    "    def _convert_list_to_string(self, list_feat):\n",
    "        '''convert list to string to print later'''\n",
    "        str_temp = ''\n",
    "        for val in list_feat:\n",
    "            str_temp = str_temp + val + ' '\n",
    "        self.str_list_col_fe = str_temp\n",
    "        \n",
    "    def create_final_df(self):\n",
    "        '''creates final dataframe for model'''\n",
    "        df_feat = pd.concat([df_features, self.df_new_feat], axis=1)\n",
    "#         df_feat = pd.concat([df_features[0:1000], self.df_new_feat], axis=1) ### delete\n",
    "        print('list to drop', self.list_drop_col)\n",
    "        df_feat = df_feat.drop(self.list_drop_col, axis=1)\n",
    "        return df_feat\n",
    "\n",
    "    def create_test_feature(self, bool_drop_col, col):\n",
    "        '''creates correllated ratio to target column'''\n",
    "        df_feat = df_features.copy()\n",
    "        df_feat = self._calculate_target_perc(col, df_feat) \n",
    "        df_feat = self._map_col(col, df_feat)\n",
    "        df_feat = self._create_ratio(df_feat)\n",
    "        df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def create_feature(self, bool_drop_col, list_col):\n",
    "        '''creating new feature'''\n",
    "        df_feat = self.df_feat\n",
    "        for col in list_col:\n",
    "            df_feat = self._check_col_exist(col, df_feat)\n",
    "            df_feat = self._calculate_target_perc(col, df_feat) \n",
    "            df_feat = self._map_col(col, df_feat)\n",
    "            df_feat = self._create_ratio(df_feat)\n",
    "            df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat \n",
    "    \n",
    "    def _check_col_exist(self, col, df_feat):\n",
    "        '''recreates original column from original dataframe'''\n",
    "        if col not in df_feat.columns:\n",
    "            df_feat[col] = df_raw[col]\n",
    "            df_feat[col] = self._fill_na_2(col, df_feat)\n",
    "            df_feat[col] = self._label_encode(col, df_feat)\n",
    "        return df_feat\n",
    "        \n",
    "    def _fill_na_2(self, col, df_feat):\n",
    "        '''filling null values'''\n",
    "        mode_col = df_feat[col].mode()[0]\n",
    "        return df_feat[col].fillna(mode_col)\n",
    "\n",
    "    def _label_encode(self, col, df_feat):\n",
    "        '''label encoding columns pulled from original df_raw'''\n",
    "        le = LabelEncoder()\n",
    "        df_feat[col] = le.fit_transform(df_feat[col])\n",
    "        return df_feat[col]\n",
    "    \n",
    "    def _drop_column(self, bool_drop_col, col, df_feat):\n",
    "        '''dropping or keeping columns'''\n",
    "        if bool_drop_col:\n",
    "            print(\"Dropping original feature\", col)\n",
    "            if (col in df_features.columns):    \n",
    "                self.list_drop_col.append(col)\n",
    "                print(self.list_drop_col)\n",
    "        else:\n",
    "            print(\"Keeping original feature\", col)\n",
    "        return df_feat\n",
    "\n",
    "    def aggregate_features(self, list_col, val_aggreg):\n",
    "        for col in list_col:\n",
    "            df_groupby = self.df_raw.groupby(col).mean()\n",
    "            dict_aggreg_col = df_groupby[[val_aggreg]].to_dict()\n",
    "            self.df_feat[col + '_fe'] = self.df_raw[col].map(dict_aggreg_col['TransactionAmt'])\n",
    "            col_mode = self.df_feat[col + '_fe'].mode()[0]\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col + '_fe'].fillna(col_mode)\n",
    "\n",
    "    def _calculate_target_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage for each column'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        \n",
    "        for val in unique_col_values:\n",
    "            list_perc = self._append_fraud_percentage(df_feat, col_val, val, list_perc)    \n",
    "        self._create_dict(col_val, list_perc, unique_col_values) # call _create_dict \n",
    "        return df_feat\n",
    "    \n",
    "    def _append_fraud_percentage(self, df_feat, col_val, val, list_perc):\n",
    "        '''calculating fraud percentage and adding to list'''\n",
    "        fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                            & (df_feat[col_target]==1)].shape[0]\n",
    "        non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "        if (non_fraud_total==0):\n",
    "            list_perc.append(0)\n",
    "        else: \n",
    "            list_perc.append(fraud_total/non_fraud_total)\n",
    "        return list_perc\n",
    "\n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self, col, df_feat):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for val in dict_keys:\n",
    "            df_feat[col + '_fe'] = df_feat[col].map(self.dict_all_feat[val])\n",
    "            self.new_col.append(col + '_fe')\n",
    "        return df_feat\n",
    "            \n",
    "    def _create_ratio(self, df_feat):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "            col_min_val = df_feat[df_feat[val] > 0][val].min()\n",
    "            df_feat[val] = df_feat[val]/col_min_val\n",
    "        self.new_col = []\n",
    "        return df_feat\n",
    "    \n",
    "fe = FeatureEngineering()\n",
    "\n",
    "# bool_drop_col = True\n",
    "# df_feat = fe.final_features(bool_drop_col, list_feat = ['P_emaildomain', 'card6'])\n",
    "\n",
    "# bool_drop_col = True\n",
    "# df_feat = fe.final_features(bool_drop_col, list_feat=['addr1','card2'])\n",
    "## df_feat = fe.final_features(bool_drop_col, list_feat=['addr1'])\n",
    "\n",
    "# bool_drop_col = False\n",
    "# df_feat = fe.final_features(bool_drop_col, list_feat = ['card5', 'V317'])\n",
    "\n",
    "# fe.list_drop_col.append('C4')\n",
    "# df_feat = fe.create_final_df()\n",
    "# df_feat\n",
    "\n",
    "bool_drop_col = True\n",
    "df_feat = fe.feature_testing(bool_drop_col, list_feat=['addr1','card2'])\n",
    "df_feat\n",
    "\n",
    "# if we are feature testing, we need to parse and append one column and df \n",
    "# score at a time. \n",
    "\n",
    "# fe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.create_df_score_model(df_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping original feature addr1\n",
      "['addr1', 'addr1', 'addr1', 'addr1', 'addr1', 'card2', 'addr1']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93       100\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.50      0.43      0.47       100\n",
      "weighted avg       1.00      0.87      0.93       100\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "     feat_tested   fn    fp  precision  recall  time_elapsed (min)   tn    tp\n",
      "194         NaN  0.0  11.0        0.0     0.0            0.013967  0.0  89.0\n",
      "195         NaN  0.0  11.0        0.0     0.0            0.008750  0.0  89.0\n",
      "196         NaN  0.0  11.0        0.0     0.0            0.011092  0.0  89.0\n",
      "197         NaN  0.0   9.0        0.0     0.0            0.008311  0.0  91.0\n",
      "0           NaN  0.0  13.0        0.0     0.0            0.011297  0.0  87.0\n",
      "Dropping original feature card2\n",
      "['addr1', 'addr1', 'addr1', 'addr1', 'addr1', 'card2', 'addr1', 'card2']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       100\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       100\n",
      "   macro avg       0.50      0.46      0.48       100\n",
      "weighted avg       1.00      0.91      0.95       100\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "     feat_tested   fn    fp  precision  recall  time_elapsed (min)   tn    tp\n",
      "195         NaN  0.0  11.0        0.0     0.0            0.008750  0.0  89.0\n",
      "196         NaN  0.0  11.0        0.0     0.0            0.011092  0.0  89.0\n",
      "197         NaN  0.0   9.0        0.0     0.0            0.008311  0.0  91.0\n",
      "198         NaN  0.0  13.0        0.0     0.0            0.011297  0.0  87.0\n",
      "0           NaN  0.0   9.0        0.0     0.0            0.008578  0.0  91.0\n"
     ]
    }
   ],
   "source": [
    "class Model():\n",
    "    def __init__(self, bool_smote):\n",
    "#         X_train, self.X_test, y_train, self.y_test = self._create_dataframe(df_features)\n",
    "#         self.X_train, self.y_train = self._apply_smote(bool_smote, X_train, y_train)\n",
    "        self.col_fe = [] # we will comment this out and use model.col_fe through out\n",
    "        self.col = [] # comment out? \n",
    "#         self.df_new_feat = pd.DataFrame()\n",
    "        self.list_drop_col = [] # delete? moved to fe class        \n",
    "\n",
    "    def create_df_score_model(self, df_feat, list_feat):\n",
    "        '''takes final dataframe and scores model'''\n",
    "        X_train, X_test, y_train, y_test = self._create_dataframe(df_feat)\n",
    "        X_train, y_train = self._apply_smote(True, X_train, y_train)\n",
    "        model = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "        y_pred, y_test, elapsed_time = self.add_model(model, X_train, y_train,\n",
    "                                                      X_test, y_test) \n",
    "        df_scores, df_temp, y_test, y_pred = self._score_model(y_pred, y_test, \n",
    "                                                               elapsed_time)\n",
    "        self._convert_list_to_string(list_feat) ###\n",
    "        \n",
    "        self._save_results(df_scores, df_temp, y_test, y_pred)\n",
    "        fe.col_fe = [] ## added here\n",
    "            \n",
    "    def _create_dataframe(self, df_feat):\n",
    "        '''create and splitting dataframe'''\n",
    "        X = df_feat.drop(col_target, axis=1)\n",
    "        X = X.drop(col_id, axis=1)\n",
    "        y = df_feat[col_target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.1, \n",
    "                                                            random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def _apply_smote(self, bool_smote, X_train, y_train):\n",
    "        '''applying smote to split training set'''\n",
    "        if bool_smote:\n",
    "            sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "            X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "            return X_train_res, y_train_res\n",
    "        else:\n",
    "            return X_train, y_train\n",
    "        \n",
    "    def add_model(self, model, X_train, y_train, X_test, y_test):        \n",
    "        '''fitting model and calculating time elapsed'''\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        return y_pred, y_test, elapsed_time\n",
    "        \n",
    "    def _score_model(self, y_pred, y_test, elapsed_time):      \n",
    "        '''creating dataframe with score results'''\n",
    "        col_recall, col_precision, col_time = self._calc_rec_prec(y_test, y_pred, \n",
    "                                                                  elapsed_time)        \n",
    "        df_conf_matrix = self._confusion_matrix(y_test, y_pred)\n",
    "        df_temp = pd.concat([col_recall, col_precision, df_conf_matrix, col_time], axis=1)\n",
    "        if fe.col_fe:\n",
    "            df_temp = self._concat_new_feat(df_temp)\n",
    "        df_scores = self._read_create_score_file(df_temp)\n",
    "        return df_scores, df_temp, y_test, y_pred\n",
    "    \n",
    "    def _convert_list_to_string(self, list_feat):\n",
    "        '''convert list to string to print later'''\n",
    "        str_temp = ''\n",
    "        for val in list_feat:\n",
    "            str_temp = str_temp + val + ' '\n",
    "        fe.str_list_col_fe = str_temp\n",
    "\n",
    "    def _calc_rec_prec(self, y_test, y_pred, elapsed_time):\n",
    "        '''calculating recall, precision and elapsed time'''\n",
    "        col_recall = pd.Series(recall_score(y_test, y_pred), name='recall')\n",
    "        col_precision = pd.Series(precision_score(y_test, y_pred), name='precision')\n",
    "        col_time = pd.Series(elapsed_time, name='time_elapsed (min)')\n",
    "        return col_recall, col_precision, col_time\n",
    "    \n",
    "    def _confusion_matrix(self, y_test, y_pred):\n",
    "        '''creating confusion matrix dataframe'''\n",
    "        df_conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "        val_tp = pd.Series(df_conf_matrix[0][0], name='tp')\n",
    "        val_fn = pd.Series(df_conf_matrix[0][1], name='fn')\n",
    "        val_fp = pd.Series(df_conf_matrix[1][0], name='fp')\n",
    "        val_tn = pd.Series(df_conf_matrix[1][1], name='tn')\n",
    "        return pd.concat([val_fn, val_fp, val_tp, val_tn], axis=1)\n",
    "\n",
    "    def _concat_new_feat(self, df_temp):\n",
    "        '''concatenate scoring results'''        \n",
    "        print(\"Creating new features from\", fe.col_fe, '\\n')\n",
    "        if len(fe.col_fe) > 1: \n",
    "            fe.col_fe = \"model score\"\n",
    "        col_fe = pd.Series(fe.col_fe, name='feat_tested')\n",
    "        return pd.concat([col_fe, df_temp], axis=1)\n",
    "    \n",
    "    def _read_create_score_file(self, df_temp):\n",
    "        '''reading or creating df_scores file'''\n",
    "        try: \n",
    "            df_scores = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "            df_scores = df_scores.drop('Unnamed: 0', axis=1)\n",
    "        except:\n",
    "            print(\"\\nCreating df_scores.csv file.\") \n",
    "            df_scores = df_temp\n",
    "        return df_scores\n",
    "            \n",
    "    def _save_results(self, df_scores, df_temp, y_test, y_pred):\n",
    "        '''printing scores for new features'''            \n",
    "        df_scores = pd.concat([df_scores, df_temp], axis=0)\n",
    "        df_scores.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "        classif_report = classification_report(y_test, y_pred)\n",
    "        self._print_summary(classif_report, df_scores) \n",
    "        \n",
    "        self._save_summary(classif_report)\n",
    "\n",
    "    def _print_summary(self, classif_report, df_scores):\n",
    "        print(classif_report)\n",
    "        print('\\nPrinting df_scores...\\n\\n', df_scores.tail(5))\n",
    "    \n",
    "    def _save_summary(self, classif_report):\n",
    "        file_summary = open('/Users/krahman/work/fraud_detection/saved_files/df_scores_summary.txt', \"a\")\n",
    "        file_summary.write('New features created from: ' \n",
    "                           + fe.str_list_col_fe \n",
    "                           + '\\n')\n",
    "        file_summary.write(classif_report)\n",
    "        file_summary.close()\n",
    "        \n",
    "model = Model(bool_smote=True)      \n",
    "# model.add_model(LogisticRegression(random_state=42, n_jobs=-1))\n",
    "\n",
    "# KEEP\n",
    "bool_drop_col = True\n",
    "model.feature_testing(bool_drop_col, list_feat=['addr1','card2']) #,'card3','C1', \n",
    "#                                                 'V294','V279','C14','V306','D2','D10'])\n",
    "# bool_drop_col = False\n",
    "# model.feature_testing(bool_drop_col, list_feat=['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "# bool_drop_col = True\n",
    "# test_dropping_col = ['addr2', 'card1', 'C4', 'D15']\n",
    "# model.feature_testing(bool_drop_col, list_feat=test_dropping_col)\n",
    "\n",
    "\n",
    "# list_feat2 = ['card6_copy']\n",
    "# list_feat2 = ['P_emaildomain_copy']\n",
    "# bool_drop_col = True\n",
    "# model.feature_testing(bool_drop_col, list_feat=list_feat2)\n",
    "# GOOD FEAT: card6_copy\n",
    "\n",
    "# create card6 feature by if card6 not in df_feat, then copy from df_raw onto df_feat, dont drop it, create feature\n",
    "\n",
    "# bool_drop_col = True\n",
    "# df_feat = model.final_features(bool_drop_col, list_feat = ['P_emaildomain', 'card6'])\n",
    "# bool_drop_col = True\n",
    "# df_feat = fe.create_feature(bool_drop_col, ['addr1','card2','card3','C1','V294','V279','C14','V306','D2','D10'])\n",
    "# bool_drop_col = False\n",
    "# df_feat = model.final_features(bool_drop_col, list_feat = ['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "\n",
    "\n",
    "# list_feat = ['addr1', 'addr2']\n",
    "# df_feat_temp = model.final_features(bool_drop_col, list_feat)\n",
    "# bool_drop_col = True\n",
    "# df_feat = model.final_features(bool_drop_col, list_feat = ['addr1','card2','card3','C1','V294','V279','C14','V306','D2','D10'])\n",
    "# bool_drop_col = False\n",
    "# df_feat = model.final_features(bool_drop_col, list_feat = ['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "# ])#\n",
    "# columns to drop \n",
    "\n",
    "# model.list_drop_col.append('C4')\n",
    "# df_feat = model.create_final_df()\n",
    "# df_feat\n",
    "\n",
    "# bool_drop_col = False\n",
    "# model.final_features(bool_drop_col, list_feat=['addr1','card2','card3','C1', \n",
    "#                                                 'V294','V279','C14','V306','D2','D10'])\n",
    "\n",
    "# model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.create_df_score_model(df_feat)\n",
    "# 369.0 all col\n",
    "# 398.0 remove P_emaildomain\n",
    "# 410.0 remove card6\n",
    "# 395.0 drop C4\n",
    "# 415.0 add all back in\n",
    "# 368.0 test again with C14\n",
    "# test without running fe class, just run model class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le = LabelEncoder()\n",
    "# df_temp = df_raw.copy()\n",
    "mode_card6 = df_temp.card6.mode()[0]\n",
    "mode_card6\n",
    "df_temp.card6 = df_temp.card6.fillna(mode_card6)\n",
    "\n",
    "le.fit_transform(df_temp.card6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NEXT, add feature list to summary.txt then test with PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features.drop('P_emaildomain_copy',axis=1)\n",
    "# df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # there after, we can decide on our feature set and move on with the project. We need to add SVM and DT in our\n",
    "# # model class. Then we need to tune the models. we need to create features for this. \n",
    "\n",
    "# # test columns to drop and which to not. Then add if then column drop attribute. \n",
    "# # test the feature set below... then test with dropping. \n",
    "# # list_feat = ['p_email_domain_copy', 'ProductCD_copy', 'TransactionAmt']\n",
    "# # model.feature_testing(list_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we still need to test these 'ProductCD', 'card6', 'P_emaildomain_copy'\n",
    "# NEXT, create feature from TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feat_tested</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>time_elapsed (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>C14</td>\n",
       "      <td>0.757705</td>\n",
       "      <td>0.059956</td>\n",
       "      <td>511</td>\n",
       "      <td>25055</td>\n",
       "      <td>31890</td>\n",
       "      <td>1598</td>\n",
       "      <td>2.101308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>V306</td>\n",
       "      <td>0.732575</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>564</td>\n",
       "      <td>23486</td>\n",
       "      <td>33459</td>\n",
       "      <td>1545</td>\n",
       "      <td>3.337878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>V69</td>\n",
       "      <td>0.712186</td>\n",
       "      <td>0.061785</td>\n",
       "      <td>607</td>\n",
       "      <td>22808</td>\n",
       "      <td>34137</td>\n",
       "      <td>1502</td>\n",
       "      <td>3.675979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.709341</td>\n",
       "      <td>0.062113</td>\n",
       "      <td>613</td>\n",
       "      <td>22589</td>\n",
       "      <td>34356</td>\n",
       "      <td>1496</td>\n",
       "      <td>2.762055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.750119</td>\n",
       "      <td>0.059384</td>\n",
       "      <td>527</td>\n",
       "      <td>25058</td>\n",
       "      <td>31887</td>\n",
       "      <td>1582</td>\n",
       "      <td>3.022812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>D3</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>592</td>\n",
       "      <td>23194</td>\n",
       "      <td>33751</td>\n",
       "      <td>1517</td>\n",
       "      <td>0.930650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>D4</td>\n",
       "      <td>0.683736</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>667</td>\n",
       "      <td>19607</td>\n",
       "      <td>37338</td>\n",
       "      <td>1442</td>\n",
       "      <td>2.575204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>D10</td>\n",
       "      <td>0.728781</td>\n",
       "      <td>0.060579</td>\n",
       "      <td>572</td>\n",
       "      <td>23835</td>\n",
       "      <td>33110</td>\n",
       "      <td>1537</td>\n",
       "      <td>3.160460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>D11</td>\n",
       "      <td>0.700332</td>\n",
       "      <td>0.062077</td>\n",
       "      <td>632</td>\n",
       "      <td>22316</td>\n",
       "      <td>34629</td>\n",
       "      <td>1477</td>\n",
       "      <td>2.387672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>D15</td>\n",
       "      <td>0.710289</td>\n",
       "      <td>0.061573</td>\n",
       "      <td>611</td>\n",
       "      <td>22831</td>\n",
       "      <td>34114</td>\n",
       "      <td>1498</td>\n",
       "      <td>2.827159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.753912</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>519</td>\n",
       "      <td>25234</td>\n",
       "      <td>31711</td>\n",
       "      <td>1590</td>\n",
       "      <td>1.666380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.709815</td>\n",
       "      <td>0.062915</td>\n",
       "      <td>612</td>\n",
       "      <td>22297</td>\n",
       "      <td>34648</td>\n",
       "      <td>1497</td>\n",
       "      <td>2.305792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.707918</td>\n",
       "      <td>0.084298</td>\n",
       "      <td>616</td>\n",
       "      <td>16218</td>\n",
       "      <td>40727</td>\n",
       "      <td>1493</td>\n",
       "      <td>3.235723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.694168</td>\n",
       "      <td>0.074368</td>\n",
       "      <td>645</td>\n",
       "      <td>18222</td>\n",
       "      <td>38723</td>\n",
       "      <td>1464</td>\n",
       "      <td>3.163514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.682314</td>\n",
       "      <td>0.067382</td>\n",
       "      <td>670</td>\n",
       "      <td>19917</td>\n",
       "      <td>37028</td>\n",
       "      <td>1439</td>\n",
       "      <td>2.246798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>card5</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.059111</td>\n",
       "      <td>513</td>\n",
       "      <td>25404</td>\n",
       "      <td>31541</td>\n",
       "      <td>1596</td>\n",
       "      <td>1.900319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>C4</td>\n",
       "      <td>0.708867</td>\n",
       "      <td>0.063131</td>\n",
       "      <td>614</td>\n",
       "      <td>22186</td>\n",
       "      <td>34759</td>\n",
       "      <td>1495</td>\n",
       "      <td>4.133367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.728307</td>\n",
       "      <td>0.061935</td>\n",
       "      <td>573</td>\n",
       "      <td>23264</td>\n",
       "      <td>33681</td>\n",
       "      <td>1536</td>\n",
       "      <td>3.885754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>V317</td>\n",
       "      <td>0.735894</td>\n",
       "      <td>0.061656</td>\n",
       "      <td>557</td>\n",
       "      <td>23620</td>\n",
       "      <td>33325</td>\n",
       "      <td>1552</td>\n",
       "      <td>3.386921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>V294</td>\n",
       "      <td>0.706496</td>\n",
       "      <td>0.062197</td>\n",
       "      <td>619</td>\n",
       "      <td>22466</td>\n",
       "      <td>34479</td>\n",
       "      <td>1490</td>\n",
       "      <td>2.225459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>V279</td>\n",
       "      <td>0.717876</td>\n",
       "      <td>0.061268</td>\n",
       "      <td>595</td>\n",
       "      <td>23197</td>\n",
       "      <td>33748</td>\n",
       "      <td>1514</td>\n",
       "      <td>3.103863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>C14</td>\n",
       "      <td>0.748222</td>\n",
       "      <td>0.060945</td>\n",
       "      <td>531</td>\n",
       "      <td>24314</td>\n",
       "      <td>32631</td>\n",
       "      <td>1578</td>\n",
       "      <td>2.887051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>V306</td>\n",
       "      <td>0.728781</td>\n",
       "      <td>0.060638</td>\n",
       "      <td>572</td>\n",
       "      <td>23810</td>\n",
       "      <td>33135</td>\n",
       "      <td>1537</td>\n",
       "      <td>3.201493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>V69</td>\n",
       "      <td>0.718824</td>\n",
       "      <td>0.061357</td>\n",
       "      <td>593</td>\n",
       "      <td>23192</td>\n",
       "      <td>33753</td>\n",
       "      <td>1516</td>\n",
       "      <td>1.963103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.719772</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>591</td>\n",
       "      <td>23371</td>\n",
       "      <td>33574</td>\n",
       "      <td>1518</td>\n",
       "      <td>3.569480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.734471</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>560</td>\n",
       "      <td>24253</td>\n",
       "      <td>32692</td>\n",
       "      <td>1549</td>\n",
       "      <td>2.047391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>D3</td>\n",
       "      <td>0.733049</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>563</td>\n",
       "      <td>23869</td>\n",
       "      <td>33076</td>\n",
       "      <td>1546</td>\n",
       "      <td>3.213005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>D4</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>536</td>\n",
       "      <td>24802</td>\n",
       "      <td>32143</td>\n",
       "      <td>1573</td>\n",
       "      <td>2.122101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>D10</td>\n",
       "      <td>0.680891</td>\n",
       "      <td>0.068870</td>\n",
       "      <td>673</td>\n",
       "      <td>19415</td>\n",
       "      <td>37530</td>\n",
       "      <td>1436</td>\n",
       "      <td>2.375799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>D11</td>\n",
       "      <td>0.743006</td>\n",
       "      <td>0.059682</td>\n",
       "      <td>542</td>\n",
       "      <td>24689</td>\n",
       "      <td>32256</td>\n",
       "      <td>1567</td>\n",
       "      <td>2.693483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>D15</td>\n",
       "      <td>0.699384</td>\n",
       "      <td>0.063997</td>\n",
       "      <td>634</td>\n",
       "      <td>21573</td>\n",
       "      <td>35372</td>\n",
       "      <td>1475</td>\n",
       "      <td>2.362112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.694168</td>\n",
       "      <td>0.074368</td>\n",
       "      <td>645</td>\n",
       "      <td>18222</td>\n",
       "      <td>38723</td>\n",
       "      <td>1464</td>\n",
       "      <td>3.217459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.829303</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>360</td>\n",
       "      <td>30387</td>\n",
       "      <td>26558</td>\n",
       "      <td>1749</td>\n",
       "      <td>3.956196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>card5</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.059111</td>\n",
       "      <td>513</td>\n",
       "      <td>25404</td>\n",
       "      <td>31541</td>\n",
       "      <td>1596</td>\n",
       "      <td>1.932541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.703651</td>\n",
       "      <td>0.063563</td>\n",
       "      <td>625</td>\n",
       "      <td>21863</td>\n",
       "      <td>35082</td>\n",
       "      <td>1484</td>\n",
       "      <td>22.401922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.682788</td>\n",
       "      <td>0.063554</td>\n",
       "      <td>669</td>\n",
       "      <td>21218</td>\n",
       "      <td>35727</td>\n",
       "      <td>1440</td>\n",
       "      <td>1.518705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>C4</td>\n",
       "      <td>0.691797</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>650</td>\n",
       "      <td>20839</td>\n",
       "      <td>36106</td>\n",
       "      <td>1459</td>\n",
       "      <td>2.196399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>D15</td>\n",
       "      <td>0.706496</td>\n",
       "      <td>0.061680</td>\n",
       "      <td>619</td>\n",
       "      <td>22667</td>\n",
       "      <td>34278</td>\n",
       "      <td>1490</td>\n",
       "      <td>3.036361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.712660</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>606</td>\n",
       "      <td>22920</td>\n",
       "      <td>34025</td>\n",
       "      <td>1503</td>\n",
       "      <td>2.297874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.712660</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>606</td>\n",
       "      <td>22920</td>\n",
       "      <td>34025</td>\n",
       "      <td>1503</td>\n",
       "      <td>2.126026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
       "18          18         C14  0.757705   0.059956  511  25055  31890  1598   \n",
       "19          19        V306  0.732575   0.061723  564  23486  33459  1545   \n",
       "20          20         V69  0.712186   0.061785  607  22808  34137  1502   \n",
       "21          21          D1  0.709341   0.062113  613  22589  34356  1496   \n",
       "22          22          D2  0.750119   0.059384  527  25058  31887  1582   \n",
       "23          23          D3  0.719298   0.061390  592  23194  33751  1517   \n",
       "24          24          D4  0.683736   0.068507  667  19607  37338  1442   \n",
       "25          25         D10  0.728781   0.060579  572  23835  33110  1537   \n",
       "26          26         D11  0.700332   0.062077  632  22316  34629  1477   \n",
       "27          27         D15  0.710289   0.061573  611  22831  34114  1498   \n",
       "28          28       addr1  0.753912   0.059275  519  25234  31711  1590   \n",
       "29          29       addr2  0.709815   0.062915  612  22297  34648  1497   \n",
       "30          30       card1  0.707918   0.084298  616  16218  40727  1493   \n",
       "31          31       card2  0.694168   0.074368  645  18222  38723  1464   \n",
       "32          32       card3  0.682314   0.067382  670  19917  37028  1439   \n",
       "33          33       card5  0.756757   0.059111  513  25404  31541  1596   \n",
       "34          34          C4  0.708867   0.063131  614  22186  34759  1495   \n",
       "35          35          C1  0.728307   0.061935  573  23264  33681  1536   \n",
       "36          36        V317  0.735894   0.061656  557  23620  33325  1552   \n",
       "37          37        V294  0.706496   0.062197  619  22466  34479  1490   \n",
       "38          38        V279  0.717876   0.061268  595  23197  33748  1514   \n",
       "39          39         C14  0.748222   0.060945  531  24314  32631  1578   \n",
       "40          40        V306  0.728781   0.060638  572  23810  33135  1537   \n",
       "41          41         V69  0.718824   0.061357  593  23192  33753  1516   \n",
       "42          42          D1  0.719772   0.060991  591  23371  33574  1518   \n",
       "43          43          D2  0.734471   0.060034  560  24253  32692  1549   \n",
       "44          44          D3  0.733049   0.060830  563  23869  33076  1546   \n",
       "45          45          D4  0.745851   0.059640  536  24802  32143  1573   \n",
       "46          46         D10  0.680891   0.068870  673  19415  37530  1436   \n",
       "47          47         D11  0.743006   0.059682  542  24689  32256  1567   \n",
       "48          48         D15  0.699384   0.063997  634  21573  35372  1475   \n",
       "49          49       card2  0.694168   0.074368  645  18222  38723  1464   \n",
       "50          50       addr1  0.829303   0.054425  360  30387  26558  1749   \n",
       "51          51       card5  0.756757   0.059111  513  25404  31541  1596   \n",
       "52          52       addr2  0.703651   0.063563  625  21863  35082  1484   \n",
       "53          53       card1  0.682788   0.063554  669  21218  35727  1440   \n",
       "54          54          C4  0.691797   0.065432  650  20839  36106  1459   \n",
       "55          55         D15  0.706496   0.061680  619  22667  34278  1490   \n",
       "56          56       addr2  0.712660   0.061540  606  22920  34025  1503   \n",
       "57           0       addr2  0.712660   0.061540  606  22920  34025  1503   \n",
       "\n",
       "    time_elapsed (min)  \n",
       "18            2.101308  \n",
       "19            3.337878  \n",
       "20            3.675979  \n",
       "21            2.762055  \n",
       "22            3.022812  \n",
       "23            0.930650  \n",
       "24            2.575204  \n",
       "25            3.160460  \n",
       "26            2.387672  \n",
       "27            2.827159  \n",
       "28            1.666380  \n",
       "29            2.305792  \n",
       "30            3.235723  \n",
       "31            3.163514  \n",
       "32            2.246798  \n",
       "33            1.900319  \n",
       "34            4.133367  \n",
       "35            3.885754  \n",
       "36            3.386921  \n",
       "37            2.225459  \n",
       "38            3.103863  \n",
       "39            2.887051  \n",
       "40            3.201493  \n",
       "41            1.963103  \n",
       "42            3.569480  \n",
       "43            2.047391  \n",
       "44            3.213005  \n",
       "45            2.122101  \n",
       "46            2.375799  \n",
       "47            2.693483  \n",
       "48            2.362112  \n",
       "49            3.217459  \n",
       "50            3.956196  \n",
       "51            1.932541  \n",
       "52           22.401922  \n",
       "53            1.518705  \n",
       "54            2.196399  \n",
       "55            3.036361  \n",
       "56            2.297874  \n",
       "57            2.126026  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_read = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "df_temp_read[len(df_temp_read)-40:]\n",
    "# df_temp_read = df_temp_read[df_temp_read.fn>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drop_true = df_temp_read.loc[0:27,:] # [df_temp_read.fn < 601]\n",
    "# # df_drop_true = df_drop_true[]\n",
    "# df_drop_false = df_temp_read.loc[28:,:]\n",
    "\n",
    "# df_drop_true['fn_drop'] = df_drop_true['fn']\n",
    "# df_drop_false['fn_no_drop'] = df_drop_false['fn']\n",
    "\n",
    "# df_temp = df_drop_true.merge(df_drop_false, how='inner', on='feat_tested')\n",
    "# df_temp[['feat_tested', 'fn_drop', 'fn_no_drop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_drop = ['addr1','card2', 'card3', 'C1', 'V294', 'V279','C14',\n",
    "#            'V306','D2','D10']\n",
    "# col_keep = ['card5', 'V317', 'V69', 'D1','D3','D4','D11']\n",
    "# test_drop_altogether = ['addr2', 'card1', 'C4', 'D15']\n",
    "# next, test features by dropping each column individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it reads the csv, creates a dataframe, then appends the results, then saves over the old version and keeps\n",
    "# # a record of all columns in the tested dataframe.\n",
    "\n",
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# # we want to test a feature for feature engineering... we must \n",
    "\n",
    "# for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "#     print(col_original, col_new)\n",
    "#     X[col_new] = fe.df_feat[col_new]\n",
    "#     X = X.drop(col_original, axis=1)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    \n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "# #     X = X.drop(col, axis=1)\n",
    "#     print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['time_delta'] = df_temp['time_delta']\n",
    "# fe.df_feat['time_delta_week'] = df_temp['time_delta']/7\n",
    "# fe.df_feat['time_delta_month'] = df_temp['time_delta']/30\n",
    "# fe.df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe','time_delta_fe_week'],axis=1)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['TransactionAmt'] = df_features['TransactionAmt']\n",
    "# list(fe.df_feat)\n",
    "# fe.list_new_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe','addr1_fe'],axis=1)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# val_aggreg = 'TransactionAmt'\n",
    "# list_col = ['card2', 'C4', 'C1', 'V317', 'ProductCD', 'V294', 'V279', 'C14', 'card6', 'V306', 'V69']\n",
    "# fe.aggregate_features(list_col, val_aggreg)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### implement into feature engineering class. days lapsed\n",
    "df_temp = fe.df_feat[['TransactionDT']]\n",
    "df_temp['time_delta'] = 0\n",
    "len_df_temp = df_temp.shape[0]\n",
    "for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "    val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "    val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "    val_time_delta = val_time_2 - val_time_1\n",
    "    df_temp.loc[i, 'time_delta'] = val_time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# ### PCA + SMOTE testing algorithm ###\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# # applying PCA\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "# # pca = PCA(n_components=250)\n",
    "# pca = PCA()\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)\n",
    "\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # applying SMOTE\n",
    "# sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "\n",
    "# # fit logistic regression\n",
    "# model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# # predict\n",
    "# y_pred = model_lr_pca_sm.predict(X_train2)\n",
    "# # time\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print('\\nTime elapsed:', elapsed_time / 60)\n",
    "# print(confusion_matrix(y_train2, y_pred))\n",
    "# print(classification_report(y_train2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns[275:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columnsa[275:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NEXT, get our score working properly again... What did we do to score \n",
    "# LogisticRegression Base\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "# fit logistic regression\n",
    "model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# predict\n",
    "y_pred = model_lr_pca_sm.predict(X_test)\n",
    "# time\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# BASE SCORE\n",
    "# Time elapsed: 4.251827295621236\n",
    "# [[33985 22960]\n",
    "#  [  601  1508]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.60      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# RESULT: addr1_fe only\n",
    "\n",
    "# RESULT: time_delta_fe, addr1\n",
    "# Time elapsed: 5.163579479853312\n",
    "# [[26551 30394]\n",
    "#  [  363  1746]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.47      0.63     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.48     59054\n",
    "#    macro avg       0.52      0.65      0.37     59054\n",
    "# weighted avg       0.95      0.48      0.61     59054\n",
    "\n",
    "# RESULT: time_delta_fe, time_delta_week_fe\n",
    "# Time elapsed: 3.142271514733632\n",
    "# [[32540 24405]\n",
    "#  [  560  1549]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.57      0.72     56945\n",
    "#            1       0.06      0.73      0.11      2109\n",
    "\n",
    "#     accuracy                           0.58     59054\n",
    "#    macro avg       0.52      0.65      0.42     59054\n",
    "# weighted avg       0.95      0.58      0.70     59054\n",
    "\n",
    "\n",
    "# RESULT: created time_delta_fe\n",
    "# Time elapsed: 3.1532896359761557\n",
    "# [[26260 30685]\n",
    "#  [  359  1750]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.46      0.63     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.47     59054\n",
    "#    macro avg       0.52      0.65      0.36     59054\n",
    "# weighted avg       0.95      0.47      0.61     59054\n",
    "\n",
    "# RESULT: time_delta_fe only. dropping addr1_fe\n",
    "# Time elapsed: 6.11533077955246\n",
    "# [[26893 30052]\n",
    "#  [  365  1744]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.47      0.64     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.48     59054\n",
    "#    macro avg       0.52      0.65      0.37     59054\n",
    "# weighted avg       0.95      0.48      0.62     59054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.list_new_feat\n",
    "'TransactionAmt_fe', 'card1_fe', 'card2_fe','card3_fe', 'card5_fe', 'addr1_fe', 'addr2_fe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression feature testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.drop(col_target, axis=1)\n",
    "X = X.drop(col_id, axis=1)\n",
    "y = df_features[col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 'TransactionAmt_fe', 'card1_fe', 'card2_fe','card3_fe', 'card5_fe', 'addr1_fe', 'addr2_fe'\n",
    "# Good: addr2_fe, \n",
    "# Bad: TransactionAmt_fe, card1_fe, card2_fe, card3_fe, card5_fe\n",
    "# build a function that after a feature is created, you then have it test the feature and provide you results.. \n",
    "\n",
    "for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "    print(col_original, col_new)\n",
    "    X[col_new] = fe.df_feat[col_new]\n",
    "    X = X.drop(col_original, axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "    model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "#     X = X.drop(col, axis=1)\n",
    "    print(list(X.columns))\n",
    "# RESULTS: Base: 601\n",
    "\n",
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # good fe: C2_fe, card2_fe, V294_fe, V317_fe, V279_fe, V306_fe\n",
    "# # bad fe: C1_fe, ProductCD_fe, V294_fe, C14_fe, card6_fe, V69_fe\n",
    "# for col in list_col_fe:\n",
    "#     X[col] = fe.df_feat[col]    \n",
    "#     print(col)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     X = X.drop(col, axis=1)\n",
    "    \n",
    "# # good: C2_fe, \n",
    "# # not good: card2_fe, C4_fe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior information \n",
    "# C2_fe\n",
    "\n",
    "# Time elapsed: 6.717598664760589\n",
    "# [[33735 23210]\n",
    "#  [  595  1514]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.59      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# card2_fe\n",
    "\n",
    "# Time elapsed: 7.546754765510559\n",
    "# [[35200 21745]\n",
    "#  [  649  1460]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.62      0.76     56945\n",
    "#            1       0.06      0.69      0.12      2109\n",
    "\n",
    "#     accuracy                           0.62     59054\n",
    "#    macro avg       0.52      0.66      0.44     59054\n",
    "# weighted avg       0.95      0.62      0.74     59054\n",
    "\n",
    "# C4_fe\n",
    "\n",
    "# Time elapsed: 5.034457282225291\n",
    "# [[36521 20424]\n",
    "#  [  602  1507]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.64      0.78     56945\n",
    "#            1       0.07      0.71      0.13      2109\n",
    "\n",
    "#     accuracy                           0.64     59054\n",
    "#    macro avg       0.53      0.68      0.45     59054\n",
    "# weighted avg       0.95      0.64      0.75     59054\n",
    "\n",
    "# C1_fe\n",
    "\n",
    "# Time elapsed: 5.847904968261719\n",
    "# [[40085 16860]\n",
    "#  [  701  1408]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.70      0.82     56945\n",
    "#            1       0.08      0.67      0.14      2109\n",
    "\n",
    "#     accuracy                           0.70     59054\n",
    "#    macro avg       0.53      0.69      0.48     59054\n",
    "# weighted avg       0.95      0.70      0.80     59054\n",
    "\n",
    "# V317_fe\n",
    "\n",
    "# Time elapsed: 4.49170538187027\n",
    "# [[33842 23103]\n",
    "#  [  583  1526]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.59      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# ProductCD_fe\n",
    "\n",
    "# Time elapsed: 5.576840949058533\n",
    "# [[41354 15591]\n",
    "#  [  737  1372]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.73      0.84     56945\n",
    "#            1       0.08      0.65      0.14      2109\n",
    "\n",
    "#     accuracy                           0.72     59054\n",
    "#    macro avg       0.53      0.69      0.49     59054\n",
    "# weighted avg       0.95      0.72      0.81     59054\n",
    "\n",
    "# V294_fe\n",
    "\n",
    "# Time elapsed: 4.640570282936096\n",
    "# [[37922 19023]\n",
    "#  [  698  1411]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.67      0.79     56945\n",
    "#            1       0.07      0.67      0.13      2109\n",
    "\n",
    "#     accuracy                           0.67     59054\n",
    "#    macro avg       0.53      0.67      0.46     59054\n",
    "# weighted avg       0.95      0.67      0.77     59054\n",
    "\n",
    "# V279_fe\n",
    "\n",
    "# Time elapsed: 3.3400171319643657\n",
    "# [[33443 23502]\n",
    "#  [  577  1532]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.59      0.74     56945\n",
    "#            1       0.06      0.73      0.11      2109\n",
    "\n",
    "#     accuracy                           0.59     59054\n",
    "#    macro avg       0.52      0.66      0.42     59054\n",
    "# weighted avg       0.95      0.59      0.71     59054\n",
    "\n",
    "# C14_fe\n",
    "\n",
    "# Time elapsed: 6.974740914503733\n",
    "# [[35823 21122]\n",
    "#  [  599  1510]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.63      0.77     56945\n",
    "#            1       0.07      0.72      0.12      2109\n",
    "\n",
    "#     accuracy                           0.63     59054\n",
    "#    macro avg       0.53      0.67      0.44     59054\n",
    "# weighted avg       0.95      0.63      0.74     59054\n",
    "\n",
    "# card6_fe\n",
    "\n",
    "# Time elapsed: 3.6439321478207907\n",
    "# [[36705 20240]\n",
    "#  [  640  1469]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.64      0.78     56945\n",
    "#            1       0.07      0.70      0.12      2109\n",
    "\n",
    "#     accuracy                           0.65     59054\n",
    "#    macro avg       0.53      0.67      0.45     59054\n",
    "# weighted avg       0.95      0.65      0.76     59054\n",
    "\n",
    "# V306_fe\n",
    "\n",
    "# Time elapsed: 2.792719868818919\n",
    "# [[34359 22586]\n",
    "#  [  592  1517]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.60      0.75     56945\n",
    "#            1       0.06      0.72      0.12      2109\n",
    "\n",
    "#     accuracy                           0.61     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.61      0.73     59054\n",
    "\n",
    "# V69_fe\n",
    "\n",
    "# Time elapsed: 5.5301028688748675\n",
    "# [[39833 17112]\n",
    "#  [  694  1415]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.70      0.82     56945\n",
    "#            1       0.08      0.67      0.14      2109\n",
    "\n",
    "#     accuracy                           0.70     59054\n",
    "#    macro avg       0.53      0.69      0.48     59054\n",
    "# weighted avg       0.95      0.70      0.79     59054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop('card2_fe',axis=1)\n",
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "for col in list_col_fe:\n",
    "    X[col] = fe.df_feat[col]    \n",
    "    print(col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    # SMOTE\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    # fit decision tree\n",
    "    model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "    model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "    # predict\n",
    "    y_pred = model_dt_pca_smote.predict(X_train)\n",
    "    # time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    X = X.drop(col, axis=1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decision tree\n",
    "for col in list_col_fe:\n",
    "    X[col] = fe.df_feat[col]    \n",
    "    print(col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    # applying SMOTE\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    # fit decision tree\n",
    "    model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "    model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "    # predict\n",
    "    y_pred = model_dt_pca_smote.predict(X_test)\n",
    "    # time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    X = X.drop(col, axis=1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree Base\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "# fit decision tree\n",
    "model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "# predict\n",
    "y_pred = model_dt_pca_smote.predict(X_test)\n",
    "# time\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "\n",
    "# [[55791  1154]\n",
    "#  [  941  1168]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.98      0.98     56945\n",
    "#            1       0.50      0.55      0.53      2109\n",
    "\n",
    "#     accuracy                           0.96     59054\n",
    "#    macro avg       0.74      0.77      0.75     59054\n",
    "# weighted avg       0.97      0.96      0.97     59054\n",
    "\n",
    "\n",
    "# Time elapsed: 8.485406096776327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit logistic regression\n",
    "# model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# # predict\n",
    "# y_pred = model_lr_pca_sm.predict(X_train2)\n",
    "# # time\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print('\\nTime elapsed:', elapsed_time / 60)\n",
    "# print(confusion_matrix(y_train2, y_pred))\n",
    "# print(classification_report(y_train2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULT: C4_fe with TransactionAmt\n",
    "\n",
    "# RESULT: Base Score, smote only, no pca\n",
    "# [[245073 267859]\n",
    "#  [  3447  15107]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.48      0.64    512932\n",
    "#            1       0.05      0.81      0.10     18554\n",
    "\n",
    "#     accuracy                           0.49    531486\n",
    "#    macro avg       0.52      0.65      0.37    531486\n",
    "# weighted avg       0.95      0.49      0.62    531486\n",
    "\n",
    "# Scores below reflect _fe's\n",
    "# RESULTS: drop card6_fe\n",
    "# Time elapsed: 3.520830734570821\n",
    "# [[361114 151818]\n",
    "#  [  4823  13731]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.70      0.82    512932\n",
    "#            1       0.08      0.74      0.15     18554\n",
    "\n",
    "#     accuracy                           0.71    531486\n",
    "#    macro avg       0.53      0.72      0.49    531486\n",
    "# weighted avg       0.96      0.71      0.80    531486\n",
    "\n",
    "# RESULTS: card6_fe \n",
    "# Time elapsed: 3.569287049770355\n",
    "# [[362083 150849]\n",
    "#  [  4745  13809]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.71      0.82    512932\n",
    "#            1       0.08      0.74      0.15     18554\n",
    "\n",
    "#     accuracy                           0.71    531486\n",
    "#    macro avg       0.54      0.73      0.49    531486\n",
    "# weighted avg       0.96      0.71      0.80    531486\n",
    "\n",
    "# RESULTS: dropped features and used PCA, worstened score\n",
    "# [[413977  98955]\n",
    "#  [  4747  13807]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.81      0.89    512932\n",
    "#            1       0.12      0.74      0.21     18554\n",
    "\n",
    "#     accuracy                           0.80    531486\n",
    "#    macro avg       0.56      0.78      0.55    531486\n",
    "# weighted avg       0.96      0.80      0.87    531486\n",
    "\n",
    "# RESULTS: drop low ranking features found in decision tree\n",
    "# [[329812 183120]\n",
    "#  [  4810  13744]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.64      0.78    512932\n",
    "#            1       0.07      0.74      0.13     18554\n",
    "\n",
    "#     accuracy                           0.65    531486\n",
    "#    macro avg       0.53      0.69      0.45    531486\n",
    "# weighted avg       0.95      0.65      0.76    531486\n",
    "\n",
    "# RESULTS: without PCA\n",
    "# [[298715 214217]\n",
    "#  [  3509  15045]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.58      0.73    512932\n",
    "#            1       0.07      0.81      0.12     18554\n",
    "\n",
    "#     accuracy                           0.59    531486\n",
    "#    macro avg       0.53      0.70      0.43    531486\n",
    "# weighted avg       0.96      0.59      0.71    531486\n",
    "\n",
    "# RESULTS: keep ohe for email and create p email feature calculate email domain fraud feature\n",
    "# [[434421  78511]\n",
    "#  [  4429  14125]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.84    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.84      0.89    531486\n",
    "\n",
    "# RESULTS: with new feature, try dropping ohe p_email and test\n",
    "# [[435499  77433]\n",
    "#  [  4539  14015]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.85    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.85      0.89    531486\n",
    "\n",
    "# RESULTS: cut FP rate quite a bit. fixing fraud perc calculation by doing fraud/non fraud for each value in each column\n",
    "# [[434423  78509]\n",
    "#  [  4430  14124]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.84    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.84      0.89    531486\n",
    "\n",
    "\n",
    "# RESULTS: adding 60 for one hot encoding\n",
    "# [[403339 109593]\n",
    "#  [  4393  14161]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.79      0.88    512932\n",
    "#            1       0.11      0.76      0.20     18554\n",
    "\n",
    "#     accuracy                           0.79    531486\n",
    "#    macro avg       0.55      0.77      0.54    531486\n",
    "# weighted avg       0.96      0.79      0.85    531486\n",
    "\n",
    "# RESULTS: fe for 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card5'\n",
    "# [[397116 115816]\n",
    "#  [  4490  14064]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.77      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: only addr6. Creating ratio ranking of higher risk areas for fraud. \n",
    "# [[396866 116066]\n",
    "#  [  4534  14020]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# NEXT, test creating iqr range instead of percentage values, instead of what we did\n",
    "# with addr5, then create one for addr2, then create an addr7 based on interaction with addr2. \n",
    "\n",
    "\n",
    "\n",
    "# RESULTS: only addr5. testing mapping percentage values transformed..\n",
    "# [[396898 116034]\n",
    "#  [  4535  14019]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with only addr3, addr4\n",
    "# [[396868 116064]\n",
    "#  [  4544  14010]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: w/o addr1, addr2, addr3, addr4\n",
    "# [[396629 116303]\n",
    "#  [  4545  14009]]\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with only addr1, addr2\n",
    "# [[396803 116129]\n",
    "#  [  4555  13999]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.75      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with addr1, addf2, addr3, addr4\n",
    "# [[396877 116055]\n",
    "#  [  4549  14005]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.75      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - SMOTE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree smote only (pca commented out)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # applying PCA\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "# # pca = PCA(n_components=250)\n",
    "# pca = PCA()\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.1, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "\n",
    "model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "\n",
    "# Feature importance\n",
    "col_name = pd.Series(X.columns, name='col')\n",
    "col_feat_rank = pd.Series(model_dt_pca_smote.feature_importances_, name='feat_rank')\n",
    "df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1).sort_values('feat_rank', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "sns.barplot(df_feat_rank.feat_rank[0:10], df_feat_rank.col[0:10], palette='Blues_d')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "df_feat_rank[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EDA on C4 and TransactionAmt\n",
    "# df_temp = fe.df_feat\n",
    "\n",
    "# sns.lineplot(x='C4', y='TransactionAmt', data=df_temp)\n",
    "# plt.title('C4 versus Transaction Amount')\n",
    "# plt.show()\n",
    "\n",
    "# sns.scatterplot(x='C4', y='TransactionAmt', hue='isFraud', data=df_temp)\n",
    "# plt.title('C4 versus Transaction Amount')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the type of card is highly correllated with debit, credit, etc. figure out which feature to create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_lr_pca_sm.predict(X_pca)\n",
    "\n",
    "# cross validation\n",
    "# result = cross_val_score(model_lr_pca_sm, X_train2, y_train2, cv=10, n_jobs=-1, scoring='recall_score')\n",
    "# result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes, do we need to visualize our results?? We need to look at our confusion matrix\n",
    "# and decide how to improve our results from here... Test and see what happens if we \n",
    "# increase our principal components... test removing columns, adding columns, imputing\n",
    "# certain columns all together. \n",
    "\n",
    "# test imputing 500 or less for ohe. Then test dropping card1 due to its number\n",
    "# of unique values that would make our data very high dimensional. We can try only ohe for\n",
    "# the entire dataset to see how our model performs over all... Though.. it will likely run \n",
    "# out of memory and crash. \n",
    "\n",
    "# ALSO test probabilities on logisticregression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# plt.hist(y_pred_prob[:,1], bins=8)\n",
    "# plt.xlim(0,1)\n",
    "# plt.title(\"Histogram of Probability of Fraud\")\n",
    "# plt.xlabel(\"Predicted probability of Fraud\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# y_pred_class = binarize(y_pred_prob, 0.5)[:,1]\n",
    "\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.title(\"ROC curve for fraud detection classifier\")\n",
    "# plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "# plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_threshold(threshold):\n",
    "#     print(\"Sensitivity:\", tpr[thresholds > threshold][-1])\n",
    "#     print(\"Specificity:\", 1 - fpr[thresholds > threshold][-1],'\\n')\n",
    "    \n",
    "# evaluate_threshold(.5)\n",
    "# evaluate_threshold(.2)\n",
    "# evaluate_threshold(.1)\n",
    "\n",
    "# print(roc_auc_score(y, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_test2) # actual prediction test data set\n",
    "# print('y_pred_actual on test set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_actual))\n",
    "# print(classification_report(y_test2, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_test2)\n",
    "# y_pred_class = binarize(y_pred_proba, 0.5)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_class))\n",
    "# print(classification_report(y_test2, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_pca) # actual full data set\n",
    "# print('Logistic Regression')\n",
    "# print('y_pred_actual full data set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y, y_pred_actual))\n",
    "# print(classification_report(y, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba full data set\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_pca)#[:,1]#[0:10]\n",
    "# y_pred_class = binarize(y_pred_proba, 0.2)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using Logistic Regression, PCA, SMOTE\\n\")\n",
    "# y_pred_pca_sm = model_lr_pca.predict(X_test2)\n",
    "# # y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_lr_pca.score(X_test2, y_test2))\n",
    "# print(recall_score(y_test2, y_pred_pca_sm))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test2, y_pred_pca_sm))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test2, y_pred_pca_sm))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred_pca_sm_whole = model_lr_pca.predict(X_pca)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_lr_pca.score(X_pca, y))\n",
    "# print(recall_score(y, y_pred_pca_sm_whole))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred_pca_sm_whole))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred_pca_sm_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('dataframe length: ' + str(df_features.shape[0]))\n",
    "# print('TransactionDT unique: ' + str(len(df_features.TransactionDT.unique())))\n",
    "# print('is not fraud: ' + str(df_features[df_features.isFraud==0].shape[0]))\n",
    "# print('is fraud: ' + str(df_features[df_features.isFraud==1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # KEEP\n",
    "# fig = plt.figure(figsize=(15,4))\n",
    "# df_temp = df_features\n",
    "# sns.kdeplot(df_temp.loc[(df_temp.isFraud==0), 'TransactionDT'], color='b', shade=True, label='Not Fraud')\n",
    "# sns.kdeplot(df_temp.loc[(df_temp.isFraud==1), 'TransactionDT'], color='r', shade=True, label='Fraud')\n",
    "# plt.title('Transaction Date Versus Fraud')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='TransactionDT', y='TransactionDT', hue='isFraud', data=df_features)\n",
    "# plt.title(\"Transaction Date Versus Fraud\")\n",
    "# plt.show()\n",
    "\n",
    "# we want to figure out how to create more features from TransactionDT.. \n",
    "# are certain transactions more likely. in general, to be fraudualant around a certain day? \n",
    "# we have transactionID yet we dont have the specific card of who it belongs to.. \n",
    "# if card1 is the unique identifier... and we did a groupby on fraud.. \n",
    "# we have average spent per day as an option... \n",
    "# create a feature that is average spent per day for non fraud versus average spent per day for fraud.. \n",
    "# what would the describe method reveal for us? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using PCA\\n\")\n",
    "# y_pred_pca = model_dt_pca_smote.predict(X_test2)\n",
    "# # y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_dt_pca_smote.score(X_test2, y_test2))\n",
    "# print(recall_score(y_test2, y_pred_pca))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test2, y_pred_pca))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test2, y_pred_pca))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred_pca = model_dt_pca_smote.predict(X_pca)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_dt_pca_smote.score(X_pca, y))\n",
    "# print(recall_score(y, y_pred_pca))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred_pca))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Variance ratio:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(\"\\nPrincipal components explained:\")\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # explaining variance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))\n",
    "\n",
    "# # # predicting on original dataset\n",
    "# # y_pred = clf_lr.predict(X)\n",
    "# # print(\"\\nTest Results\")\n",
    "# # print(clf_lr.score(X, y))\n",
    "# # print(recall_score(y, y_pred))\n",
    "# # print(\"\\nConfusion Matrix\")\n",
    "# # print(confusion_matrix(y, y_pred))\n",
    "# # print('\\nClassification Report:\\n')\n",
    "# # print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X2 = StandardScaler().fit_transform(X)\n",
    "# pca3 = PCA(n_components=275)\n",
    "# pcomponents = pca3.fit_transform(scaled_X2)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # applying SMOTE to train set to correct class imbalance\n",
    "# sm = SMOTE(random_state=42, ratio = 1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# # fitting to residuals created by SMOTE\n",
    "# clf_lr = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "# clf_lr.fit(X_train_res, y_train_res);\n",
    "\n",
    "# # predicting on test set\n",
    "# y_test_pred = clf_lr.predict(X_test)\n",
    "# print(\"Validation results\")\n",
    "# print(clf_lr.score(X_test, y_test))\n",
    "# print(recall_score(y_test, y_test_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test, y_test_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# y_pred = clf_lr.predict(X)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(clf_lr.score(X, y))\n",
    "# print(recall_score(y, y_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
