{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_train = train_transaction.merge(train_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.info(); # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.info(); # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# train_transaction_sum = train_transaction.duplicated().sum()\n",
    "# train_identity_sum = train_identity.duplicated().sum()\n",
    "# columns = train_transaction.columns\n",
    "# print('Train transaction duplicates: {}\\nTrain identity duplicates: {} \\n'.format(train_transaction_sum, train_identity_sum))\n",
    "# # print('Train feature columns:\\n', list(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "# D = time elapsed between each transaction, card = card information, C = counting, ie how many addresses \n",
    "# associated with card, M=True/False, V created features on ranking, counting, etc. \n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# boolean columns. convert via dummy variable. We dont know if true/false is better than one or the other. \n",
    "# col_bool = col_m\n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))\n",
    "\n",
    "# columns removed dist1, dist2, R_emaildomain, DeviceInfo, DeviceType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 195 columns with null values.\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "                \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()\n",
    "# df_null_info\n",
    "\n",
    "# determine what to do with columns that have too many unique values... obviously.. types of solutions\n",
    "# would be to put \"MISSING\" for those that dont have an email address... but you will need to evaluate \n",
    "# and make instead a counter of unique values, then append that and look at the CSV via google sheets. use \n",
    "# something like the code below \n",
    "\n",
    "# Planning - our preprocessing method must automatically drop missing values, but we can't do that because\n",
    "# we need to see about filling them in first, then decide if we need to drop them. Right now, we need to\n",
    "# create a dataframe that shows unique values for each column with missing values. \n",
    "\n",
    "# we need to look at each variable and see if it's unique or categorical. We need to use possibly PCA...? How do\n",
    "# we handle so many variables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoded: addr1 unique 333\n",
      "label encoded: addr2 unique 75\n",
      "dummies encoded: ProductCD unique 5\n",
      "dummies encoded: P_emaildomain unique 59\n",
      "label encoded: card1 unique 13553\n",
      "label encoded: card2 unique 501\n",
      "label encoded: card3 unique 115\n",
      "dummies encoded: card4 unique 4\n",
      "label encoded: card5 unique 120\n",
      "dummies encoded: card6 unique 4\n",
      "dummies encoded: M1 unique 2\n",
      "dummies encoded: M2 unique 2\n",
      "dummies encoded: M3 unique 2\n",
      "dummies encoded: M4 unique 3\n",
      "dummies encoded: M6 unique 2\n",
      "new dataframe shape:(590540, 285)\n"
     ]
    }
   ],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_summary = df_features.groupby('isFraud')\n",
    "fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_summary.csv')\n",
    "\n",
    "corr = df_features.corr()\n",
    "corr.to_csv('/Users/krahman/work/fraud_detection/saved_files/corr_matrix.csv')\n",
    "corr2 = corr[corr['isFraud']>.17]\n",
    "corr2 = corr2.loc[:,corr2.index]\n",
    "\n",
    "sns.heatmap(corr2,\n",
    "           xticklabels=corr2.columns.values,\n",
    "           yticklabels=corr2.columns.values)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X.card1, y)\n",
    "# sns.regplot(x='card5_237.0', y='isFraud', data=pp.df_train, logistic=True, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dropping Features On Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# y_test = pp.df_train[col_target] #.rename(columns=['isFraud'])\n",
    "# y_test = pd.Series(y_test)\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing dropping columns\n",
    "# model_lr_results = pd.DataFrame()\n",
    "# model_recall = []\n",
    "# model_precision = []\n",
    "# model_auc_score = []\n",
    "\n",
    "# for col in ['addr1', 'addr2', 'P_emaildomain', 'card1', 'card2', 'card3', 'card5']:\n",
    "#     print('Dropping: ', col)\n",
    "#     X_drop = X.drop(col, axis=1)\n",
    "# #     X_drop = X_drop.loc[:10000,:]\n",
    "#     y_drop = y#[:10001]\n",
    "    \n",
    "#     scaled_X = StandardScaler().fit_transform(X_drop)\n",
    "#     # pca\n",
    "#     pca = PCA()\n",
    "#     pcomponents = pca.fit_transform(scaled_X)\n",
    "#     X_pca = pd.DataFrame(data=pcomponents)\n",
    "#     # split\n",
    "#     X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y_drop, test_size=0.1, random_state=42)\n",
    "#     # smote\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "#     # model fit\n",
    "#     model_lr_pca = LogisticRegression(random_state=42)\n",
    "#     model_lr_pca.fit(X_train_res, y_train_res)\n",
    "#     # predict\n",
    "#     y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "#     y_pred_class = binarize(y_pred_prob, 0.5)[:,1]\n",
    "#     # scoring\n",
    "#     model_recall.append(recall_score(y_drop, y_pred_class))\n",
    "#     model_precision.append(precision_score(y_drop, y_pred_class))\n",
    "#     model_auc_score.append(roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "#     print(confusion_matrix(y_drop, y_pred_class))\n",
    "#     print(classification_report(y_drop, y_pred_class))\n",
    "#     print('AUC: ', roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "\n",
    "# model_recall = pd.Series(model_recall, name='recall')\n",
    "# model_precision = pd.Series(model_precision, name='precision')\n",
    "# model_auc_score = pd.Series(model_auc_score, name='auc_score')\n",
    "# model_results_final = pd.concat([model_auc_score, model_recall, model_precision],axis=1)\n",
    "# model_results_final\n",
    "\n",
    "# # it's apparent that label encoding on some of these don't really matter and if we drop them.. it doesn't really\n",
    "# # matter.. \n",
    "# # dropping these columns has little impact with logistic regression.. \n",
    "\n",
    "# # tune logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELETE\n",
    "\n",
    "# model_lr_results = pd.DataFrame()\n",
    "# model_recall = []\n",
    "# model_precision = []\n",
    "# model_auc_score = []\n",
    "\n",
    "#     model_recall.append(recall_score(y_drop, y_pred_class))\n",
    "#     model_precision.append(precision_score(y_drop, y_pred_class))\n",
    "#     model_auc_score.append(roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "\n",
    "# model_recall = pd.Series(model_recall, name='recall')\n",
    "# model_precision = pd.Series(model_precision, name='precision')\n",
    "# model_auc_score = pd.Series(model_auc_score, name='auc_score')\n",
    "# model_results_final = pd.concat([model_auc_score, model_recall, model_precision],axis=1)\n",
    "# model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DELETE\n",
    "\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "# df_temp[0:20]\n",
    "# pd.DataFrame(pca.components_, columns=list(X_temp.columns), index=range(0,225))\n",
    "# pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA (2 components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing our data, which is required for PCA.\n",
    "scaled_X = StandardScaler().fit_transform(X)\n",
    "pd.DataFrame(scaled_X, columns=X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA instantiate and fit \n",
    "pca = PCA(n_components=2)\n",
    "pcomponents = pca.fit_transform(scaled_X)\n",
    "X_pca = pd.DataFrame(data = pcomponents, columns=['PC1','PC2'])\n",
    "print(X_pca.shape)\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two principal components scatter plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca['PC1'], X_pca['PC2'], c=y['isFraud'])\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "\n",
    "# explaining vaariance\n",
    "print('Variance ratio:')\n",
    "print(pca.explained_variance_ratio_)\n",
    "# interpreting principal components\n",
    "print('\\nPrincipal components explained:')\n",
    "pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA to all features (all components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA().fit(scaled_X)\n",
    "# pca2.explained_variance_ratio_\n",
    "# np.cumsum(pca2.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca2.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)')\n",
    "plt.title('Credit Card Fraud Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model w/ SMOTE only - base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(random_state=42)\n",
    "model_lr.fit(X_train_res, y_train_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test set w/o PCA\n",
    "print(\"Predicting using only SMOTE (and w/o PCA)\\n\")\n",
    "y_pred_test1 = model_lr.predict(X_test1)\n",
    "print(\"Test set:\")\n",
    "print(\"Validation results\")\n",
    "print(model_lr.score(X_test1, y_test1))\n",
    "print(recall_score(y_test1, y_pred_test1))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y_test1, y_pred_test1))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test1, y_pred_test1))\n",
    "\n",
    "# predicting on original dataset\n",
    "print(\"Whole dataset:\")\n",
    "y_pred = model_lr.predict(X)\n",
    "print(\"\\nTest Results\")\n",
    "print(model_lr.score(X, y))\n",
    "print(recall_score(y, y_pred))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression w/PCA  w/SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "           fit_reg=False, hue='isFraud')\n",
    "plt.title('addr1 versus addr2')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(df_features.addr1)\n",
    "plt.title('Addr1 Distribution')\n",
    "plt.show()\n",
    "\n",
    "# sns.distplot(df_features['addr3'])\n",
    "# plt.title('Addr3 Distribution')\n",
    "# plt.show()\n",
    "\n",
    "# sns.lmplot(x='addr3', y='addr4', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.title('addr3 versus addr4')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_features.addr2, kde=False)\n",
    "# plt.show()\n",
    "# df_features.addr2.value_counts(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in df_features.addr2.unique():\n",
    "#     if df_features.addr2.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_features.addr2.unique())\n",
    "# df_features.addr2.sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_train[df_train['isFraud']==1]\n",
    "df_test = df_test.P_emaildomain.value_counts()\n",
    "df_test\n",
    "# df_test.groupby()\n",
    "sns.distplot(df_test)\n",
    "# just because a email address is common, doesnt increase the likelihood of it being fraud.\n",
    "# however, if the email address out of all others tend to have higher fraudulancy, now we have signal. \n",
    "# we need to see the distribution of fraud for our email variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Email Class\n",
    "# P_emaildomain\n",
    "# list(df_train.columns)\n",
    "# df_train.P_emaildomain.unique()\n",
    "list_perc = []\n",
    "list_fraud_count = []\n",
    "list_non_fraud_count = []\n",
    "for val in df_train.P_emaildomain.unique():\n",
    "    non_fraud_count = df_train[(df_train.P_emaildomain==val) & (df_train.isFraud==0)].shape[0]\n",
    "    fraud_count = df_train[(df_train.P_emaildomain==val) & (df_train.isFraud==1)].shape[0]\n",
    "    \n",
    "    list_perc.append(fraud_count/non_fraud_count)\n",
    "    \n",
    "    list_fraud_count.append(fraud_count)\n",
    "    list_non_fraud_count.append(non_fraud_count)\n",
    "    \n",
    "col_email = pd.Series(df_train.P_emaildomain.unique(), name='email')\n",
    "col_perc = pd.Series(list_perc, name='fraud_perc')\n",
    "col_fraud_count = pd.Series(list_fraud_count, name='fraud_count')\n",
    "col_non_fraud_count = pd.Series(list_non_fraud_count, name='non_fraud_count')\n",
    "\n",
    "# col_perc\n",
    "df_email_fe = pd.concat([col_email, col_perc, col_fraud_count, col_non_fraud_count], axis=1)\n",
    "# df_email_fe\n",
    "# df_train[(df_train.P_emaildomain=='outlook.com') & (df_train.isFraud==1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df_email_fe.fraud_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_email_fe.sort_values('fraud_perc', ascending=False)\n",
    "# Hypothesis: less occurring email domains are more likely to have higher fraud_perc because they are \n",
    "# perhaps an email provider with less resources. The card that the holder has attached to certain email\n",
    "# addresses puts them at higher risk for fraud. \n",
    "email_fraud_perc_min = df_email_fe[df_email_fe['fraud_perc']>0]['fraud_perc'].min()\n",
    "0.688889/email_fraud_perc_min\n",
    "# NEXT, we need to imput email and test our results... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_addr1 = {}\n",
    "# for val in df_features.addr1.unique():\n",
    "#     val_percentage = df_features[df_features['addr1']==val].shape[0]/df_features.shape[0]\n",
    "#     dict_addr1.update([(val, val_percentage)])\n",
    "    \n",
    "# dict_addr2 = {}\n",
    "# for val in df_features.addr1.unique():\n",
    "#     val_percentage = df_features[df_features['addr2']==val].shape[0]/df_features.shape[0]\n",
    "#     dict_addr2.update([(val, val_percentage)])\n",
    "    \n",
    "# df_features['addr3'] = df_features['addr1'].map(dict_addr1)\n",
    "# df_features['addr4'] = df_features['addr2'].map(dict_addr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# # X = X.drop('addr1', axis=1)\n",
    "# # X = X.drop('addr2', axis=1)\n",
    "# y = df_features[col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating feature engineering class from this block of code. \n",
    "# list_fraud_perc = []\n",
    "# df_temp = df_features\n",
    "\n",
    "# # calc percentage\n",
    "# for val in df_features.addr1.unique():\n",
    "#     fraud_perc = df_temp[(df_temp.addr1==val) & (df_temp.isFraud==1)].shape[0]/df_temp.shape[0]\n",
    "#     list_fraud_perc.append(fraud_perc)\n",
    "    \n",
    "# series_fraud_perc = pd.Series(list_fraud_perc)\n",
    "# series_col_name = pd.Series(df_features.addr1.unique())\n",
    "# df_addr1_fr = pd.concat([series_col_name, series_fraud_perc], keys=['col_val', 'fraud_perc'], axis=1)\n",
    "# df_addr1_fr = df_addr1_fr.sort_values('fraud_perc', ascending=False).reset_index(drop=True)\n",
    "# # print(df_addr1_fr)\n",
    "\n",
    "# # creating ratio of values more likely to have fraud within the region.\n",
    "# df_addr1_fr['fraud_multip'] = 0\n",
    "# fraud_perc_min = df_addr1_fr[df_addr1_fr.fraud_perc>0].fraud_perc.min() \n",
    "# for val in df_addr1_fr.col_val.unique():\n",
    "#     val_fraud_perc = df_addr1_fr[df_addr1_fr.col_val==val]['fraud_perc']\n",
    "#     val_fraud_ratio = val_fraud_perc / fraud_perc_min\n",
    "#     val_index = df_addr1_fr[df_addr1_fr.col_val==val].index\n",
    "#     df_addr1_fr.loc[val_index, 'fraud_multip'] = val_fraud_ratio\n",
    "# # print(df_addr1_fr)\n",
    "# # creating and mapping dictionary values\n",
    "# df_addr6 = df_addr1_fr[['col_val','fraud_multip']].set_index('col_val').to_dict()\n",
    "# dict_addr6_fraud_multip = df_addr6['fraud_multip']\n",
    "# df_features['addr6'] = df_features.addr1.map(dict_addr6_fraud_multip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_feat1 = {'col1': {0:'they', 1:'them'}}\n",
    "# dict_feat2 = {'col2': {0:'him', 1:'her'}}\n",
    "# dict_all_feat = {}\n",
    "# dict_all_feat.update(dict_feat1)\n",
    "# dict_all_feat.update(dict_feat2)\n",
    "# dict_all_feat\n",
    "# list(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to know that if we process P_emaildomain_2, if we are properly creating the ratios...\n",
    "# then we need to decide if we have already created the ratios properly for our other fe's. \n",
    "df_features['P_emaildomain_2'] = df_train['P_emaildomain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>...</th>\n",
       "      <th>M4_M1</th>\n",
       "      <th>M4_M2</th>\n",
       "      <th>M6_T</th>\n",
       "      <th>addr1_fe</th>\n",
       "      <th>addr2_fe</th>\n",
       "      <th>card1_fe</th>\n",
       "      <th>card2_fe</th>\n",
       "      <th>card3_fe</th>\n",
       "      <th>card5_fe</th>\n",
       "      <th>P_emaildomain_2_fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.285776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.393939</td>\n",
       "      <td>53.384489</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>9.237736</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.288929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.477727</td>\n",
       "      <td>74.807840</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>13.703223</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.161296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.577798</td>\n",
       "      <td>26.425206</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>2.274288</td>\n",
       "      <td>34.577807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.120587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.947229</td>\n",
       "      <td>17.790293</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>2.822371</td>\n",
       "      <td>7.708132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.257885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.882353</td>\n",
       "      <td>52.038936</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>13.703223</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>3577535</td>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.711321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.372666</td>\n",
       "      <td>53.384489</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>6.204501</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590536</td>\n",
       "      <td>3577536</td>\n",
       "      <td>0</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.452078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.257699</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>8.205715</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590537</td>\n",
       "      <td>3577537</td>\n",
       "      <td>0</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.720269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.734121</td>\n",
       "      <td>19.364771</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>8.205715</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590538</td>\n",
       "      <td>3577538</td>\n",
       "      <td>0</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.464734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.695459</td>\n",
       "      <td>32.481951</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>8.205715</td>\n",
       "      <td>7.380276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590539</td>\n",
       "      <td>3577539</td>\n",
       "      <td>0</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.738072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.925445</td>\n",
       "      <td>34.696214</td>\n",
       "      <td>2.946859</td>\n",
       "      <td>13.703223</td>\n",
       "      <td>13.592138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt   C1   C2   C3  \\\n",
       "0             2987000        0          86400           68.50  1.0  1.0  0.0   \n",
       "1             2987001        0          86401           29.00  1.0  1.0  0.0   \n",
       "2             2987002        0          86469           59.00  1.0  1.0  0.0   \n",
       "3             2987003        0          86499           50.00  2.0  5.0  0.0   \n",
       "4             2987004        0          86506           50.00  1.0  1.0  0.0   \n",
       "...               ...      ...            ...             ...  ...  ...  ...   \n",
       "590535        3577535        0       15811047           49.00  2.0  1.0  0.0   \n",
       "590536        3577536        0       15811049           39.50  1.0  1.0  0.0   \n",
       "590537        3577537        0       15811079           30.95  1.0  1.0  0.0   \n",
       "590538        3577538        0       15811088          117.00  1.0  1.0  0.0   \n",
       "590539        3577539        0       15811131          279.95  2.0  1.0  0.0   \n",
       "\n",
       "         C4   C5   C6  ...  M4_M1  M4_M2  M6_T  addr1_fe  addr2_fe  \\\n",
       "0       0.0  0.0  1.0  ...      0      1     1  2.285776       1.0   \n",
       "1       0.0  0.0  1.0  ...      0      0     1  3.288929       1.0   \n",
       "2       0.0  0.0  1.0  ...      0      0     0  4.161296       1.0   \n",
       "3       0.0  0.0  4.0  ...      0      0     0  4.120587       1.0   \n",
       "4       0.0  0.0  1.0  ...      0      0     0  4.257885       1.0   \n",
       "...     ...  ...  ...  ...    ...    ...   ...       ...       ...   \n",
       "590535  0.0  1.0  0.0  ...      0      0     0  3.711321       1.0   \n",
       "590536  0.0  0.0  1.0  ...      0      0     1  3.452078       1.0   \n",
       "590537  0.0  1.0  1.0  ...      0      0     1  3.720269       1.0   \n",
       "590538  0.0  0.0  3.0  ...      0      0     1  2.464734       1.0   \n",
       "590539  0.0  1.0  1.0  ...      0      0     1  2.738072       1.0   \n",
       "\n",
       "          card1_fe   card2_fe  card3_fe   card5_fe  P_emaildomain_2_fe  \n",
       "0       169.393939  53.384489  2.946859   9.237736           13.592138  \n",
       "1        27.477727  74.807840  2.946859  13.703223           13.592138  \n",
       "2         4.577798  26.425206  2.946859   2.274288           34.577807  \n",
       "3         7.947229  17.790293  2.946859   2.822371            7.708132  \n",
       "4        32.882353  52.038936  2.946859  13.703223           13.592138  \n",
       "...            ...        ...       ...        ...                 ...  \n",
       "590535    2.372666  53.384489  2.946859   6.204501           13.592138  \n",
       "590536    0.000000  30.257699  2.946859   8.205715           13.592138  \n",
       "590537   10.734121  19.364771  2.946859   8.205715           13.592138  \n",
       "590538   14.695459  32.481951  2.946859   8.205715            7.380276  \n",
       "590539   22.925445  34.696214  2.946859  13.703223           13.592138  \n",
       "\n",
       "[590540 rows x 286 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_col = ['addr1', 'addr2', 'card1', 'card2', 'card3', 'card5', 'P_emaildomain_2']\n",
    "\n",
    "class FeatureEngineering():\n",
    "    '''create engineered features for columns without ordinal values'''\n",
    "    def __init__(self, list_col):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        self._create_feature()\n",
    "        \n",
    "    def _create_feature(self):\n",
    "        '''main method that executes functions'''\n",
    "        for col_val in list_col:\n",
    "#             self._calculate_fraud_perc(col_val, self.df_feat)\n",
    "            self._calculate_fraud_perc_test2(col_val, self.df_feat)\n",
    "            \n",
    "        self._map_col()\n",
    "        self._create_ratio()\n",
    "        self.df_feat = self.df_feat.drop(list_col, axis=1)\n",
    "            \n",
    "    def _calculate_fraud_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage per unique column value'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==1)]\n",
    "            fraud_total = fraud_total.shape[0]\n",
    "            list_perc.append(fraud_total/self.len_df_feat)\n",
    "        self._create_dict(col_val, list_perc, unique_col_values)\n",
    "    \n",
    "    def _calculate_fraud_perc_test2(self, col_val, df_feat):\n",
    "        # NEXT, we need to divide by shape for fraud==1 and fraud==0 and see how it all performs.. \n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==1)].shape[0]\n",
    "            non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "            \n",
    "            if (non_fraud_total==0):\n",
    "                list_perc.append(0)\n",
    "            else: \n",
    "                list_perc.append(fraud_total/non_fraud_total)\n",
    "        self._create_dict(col_val, list_perc, unique_col_values)\n",
    "        \n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for col, key in zip(list_col, dict_keys):\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col].map(self.dict_all_feat[key])\n",
    "            self.new_col.append(col + '_fe')\n",
    "            \n",
    "    def _create_ratio(self):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "            col_min_val = self.df_feat[self.df_feat[val] > 0][val].min()\n",
    "            self.df_feat[val] = self.df_feat[val]/col_min_val\n",
    "\n",
    "fe = FeatureEngineering(list_col)\n",
    "fe.df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat.addr2_fe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.addr2.value_counts()[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_features[df_features.isFraud==1].addr1.shape[0]\n",
    "# df_temp = df_features[['addr1', 'addr2', 'isFraud']]\n",
    "# df_temp = df_temp[df_temp.isFraud==1]\n",
    "\n",
    "# sns.scatterplot(x='addr1', y='addr2', data=df_temp)\n",
    "# plt.title('addr1 and addr2 (fraud only)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features[df_features.isFraud==1].addr2.shape[0]\n",
    "# df_features.addr2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating test feature addr6 \n",
    "# # creating ratio of values more likely to have fraud within the region.\n",
    "# df_addr1_fr['fraud_multip'] = 0\n",
    "# fraud_perc_min = df_addr1_fr[df_addr1_fr.fraud_perc>0].fraud_perc.min() \n",
    "# for val in df_addr1_fr.col_val.unique():\n",
    "#     val_fraud_perc = df_addr1_fr[df_addr1_fr.col_val==val]['fraud_perc']\n",
    "#     val_fraud_ratio = val_fraud_perc / fraud_perc_min\n",
    "#     val_index = df_addr1_fr[df_addr1_fr.col_val==val].index\n",
    "#     df_addr1_fr.loc[val_index, 'fraud_multip'] = val_fraud_ratio\n",
    "\n",
    "# # creating and mapping dictionary values\n",
    "# df_addr6 = df_addr1_fr[['col_val','fraud_multip']].set_index('col_val').to_dict()\n",
    "# dict_addr6_fraud_multip = df_addr6['fraud_multip']\n",
    "# df_features['addr6'] = df_features.addr1.map(dict_addr6_fraud_multip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT, create a fraud ratio based on addr2.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoded: addr1 unique 333\n",
    "# dummies encoded: addr2 unique 75\n",
    "# dummies encoded: ProductCD unique 5\n",
    "# dummies encoded: P_emaildomain unique 59\n",
    "# label encoded: card1 unique 13553\n",
    "# label encoded: card2 unique 501\n",
    "# label encoded: card3 unique 115\n",
    "# dummies encoded: card4 unique 4\n",
    "# label encoded: card5 unique 120\n",
    "# dummies encoded: card6 unique 4\n",
    "# dummies encoded: M1 unique 2\n",
    "# dummies encoded: M2 unique 2\n",
    "# dummies encoded: M3 unique 2\n",
    "# dummies encoded: M4 unique 3\n",
    "# dummies encoded: M6 unique 2\n",
    "\n",
    "# list(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.distplot(df_features[df_features.isFraud==0]['card1'])\n",
    "# plt.title('Card1 not Fraud')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features[df_features.isFraud==1]['card1'])\n",
    "# plt.title('Card1 is Fraud')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('is fraud')\n",
    "# print(df_features[df_features.isFraud==0]['card1'].value_counts()[0:10])\n",
    "# print('is not fraud')\n",
    "# print(df_features[df_features.isFraud==1]['card1'].value_counts()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_features.card1.value_counts()\n",
    "# df_features[df_features.isFraud==1]['card1']\n",
    "# df_features[df_features.isFraud==1]['card1'].value_counts()[0:40]\n",
    "# sns.distplot(df_features[df_features.isFraud==1]['card1'])\n",
    "\n",
    "# for val in df_features.card1.unique():\n",
    "# NEXT, take card1, calculate perc occurrance for each variable and attach to that fe dataframe we have going.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_addr1_fr[60:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_addr1_new = df_addr1_fr.set_index('col_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to dictionary\n",
    "# dict_addr1_new = df_addr1_new.to_dict()\n",
    "# dict_addr1_new['fraud_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features['addr5'] = df_features['addr1'].map(dict_addr1_new['fraud_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features['addr5']\n",
    "# list(df_features.columns)\n",
    "# df_features['addr1'].map(dict_addr1_new['fraud_perc'])\n",
    "# df_features['addr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_test = StandardScaler()\n",
    "# scaler_test_scaled = scaler_test.fit_transform(df_addr1_fr)\n",
    "# pd.DataFrame(scaler_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_addr1_fr[df_addr1_fr['fraud_perc']>0]\n",
    "\n",
    "# sns.distplot(df_addr1_fr[df_addr1_fr['fraud_perc']>0]['fraud_perc'])\n",
    "# plt.title('Addr1 Fraud Percentages')\n",
    "# plt.show()\n",
    "\n",
    "# sns.boxplot(df_addr1_fr[df_addr1_fr['fraud_perc']>0]['fraud_perc'])\n",
    "# plt.title('Addr1 Fraud Percentages')\n",
    "# plt.show()\n",
    "\n",
    "# what if we just map what we already have.. we map our current values as percentages into another column...\n",
    "# well, we should still bin these values... \n",
    "\n",
    "# interquartile range gets 1, outliers get 2 and the big outlier gets 3, others get 0. Test this... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sns.distplot(df_addr1_fr['fraud_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(X.addr2, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransactionDT',\n",
       " 'TransactionAmt',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'C8',\n",
       " 'C9',\n",
       " 'C10',\n",
       " 'C11',\n",
       " 'C12',\n",
       " 'C13',\n",
       " 'C14',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'D3',\n",
       " 'D4',\n",
       " 'D10',\n",
       " 'D11',\n",
       " 'D15',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'V29',\n",
       " 'V30',\n",
       " 'V31',\n",
       " 'V32',\n",
       " 'V33',\n",
       " 'V34',\n",
       " 'V35',\n",
       " 'V36',\n",
       " 'V37',\n",
       " 'V38',\n",
       " 'V39',\n",
       " 'V40',\n",
       " 'V41',\n",
       " 'V42',\n",
       " 'V43',\n",
       " 'V44',\n",
       " 'V45',\n",
       " 'V46',\n",
       " 'V47',\n",
       " 'V48',\n",
       " 'V49',\n",
       " 'V50',\n",
       " 'V51',\n",
       " 'V52',\n",
       " 'V53',\n",
       " 'V54',\n",
       " 'V55',\n",
       " 'V56',\n",
       " 'V57',\n",
       " 'V58',\n",
       " 'V59',\n",
       " 'V60',\n",
       " 'V61',\n",
       " 'V62',\n",
       " 'V63',\n",
       " 'V64',\n",
       " 'V65',\n",
       " 'V66',\n",
       " 'V67',\n",
       " 'V68',\n",
       " 'V69',\n",
       " 'V70',\n",
       " 'V71',\n",
       " 'V72',\n",
       " 'V73',\n",
       " 'V74',\n",
       " 'V75',\n",
       " 'V76',\n",
       " 'V77',\n",
       " 'V78',\n",
       " 'V79',\n",
       " 'V80',\n",
       " 'V81',\n",
       " 'V82',\n",
       " 'V83',\n",
       " 'V84',\n",
       " 'V85',\n",
       " 'V86',\n",
       " 'V87',\n",
       " 'V88',\n",
       " 'V89',\n",
       " 'V90',\n",
       " 'V91',\n",
       " 'V92',\n",
       " 'V93',\n",
       " 'V94',\n",
       " 'V95',\n",
       " 'V96',\n",
       " 'V97',\n",
       " 'V98',\n",
       " 'V99',\n",
       " 'V100',\n",
       " 'V101',\n",
       " 'V102',\n",
       " 'V103',\n",
       " 'V104',\n",
       " 'V105',\n",
       " 'V106',\n",
       " 'V107',\n",
       " 'V108',\n",
       " 'V109',\n",
       " 'V110',\n",
       " 'V111',\n",
       " 'V112',\n",
       " 'V113',\n",
       " 'V114',\n",
       " 'V115',\n",
       " 'V116',\n",
       " 'V117',\n",
       " 'V118',\n",
       " 'V119',\n",
       " 'V120',\n",
       " 'V121',\n",
       " 'V122',\n",
       " 'V123',\n",
       " 'V124',\n",
       " 'V125',\n",
       " 'V126',\n",
       " 'V127',\n",
       " 'V128',\n",
       " 'V129',\n",
       " 'V130',\n",
       " 'V131',\n",
       " 'V132',\n",
       " 'V133',\n",
       " 'V134',\n",
       " 'V135',\n",
       " 'V136',\n",
       " 'V137',\n",
       " 'V279',\n",
       " 'V280',\n",
       " 'V281',\n",
       " 'V282',\n",
       " 'V283',\n",
       " 'V284',\n",
       " 'V285',\n",
       " 'V286',\n",
       " 'V287',\n",
       " 'V288',\n",
       " 'V289',\n",
       " 'V290',\n",
       " 'V291',\n",
       " 'V292',\n",
       " 'V293',\n",
       " 'V294',\n",
       " 'V295',\n",
       " 'V296',\n",
       " 'V297',\n",
       " 'V298',\n",
       " 'V299',\n",
       " 'V300',\n",
       " 'V301',\n",
       " 'V302',\n",
       " 'V303',\n",
       " 'V304',\n",
       " 'V305',\n",
       " 'V306',\n",
       " 'V307',\n",
       " 'V308',\n",
       " 'V309',\n",
       " 'V310',\n",
       " 'V311',\n",
       " 'V312',\n",
       " 'V313',\n",
       " 'V314',\n",
       " 'V315',\n",
       " 'V316',\n",
       " 'V317',\n",
       " 'V318',\n",
       " 'V319',\n",
       " 'V320',\n",
       " 'V321',\n",
       " 'ProductCD_H',\n",
       " 'ProductCD_R',\n",
       " 'ProductCD_S',\n",
       " 'ProductCD_W',\n",
       " 'P_emaildomain_anonymous.com',\n",
       " 'P_emaildomain_aol.com',\n",
       " 'P_emaildomain_att.net',\n",
       " 'P_emaildomain_bellsouth.net',\n",
       " 'P_emaildomain_cableone.net',\n",
       " 'P_emaildomain_centurylink.net',\n",
       " 'P_emaildomain_cfl.rr.com',\n",
       " 'P_emaildomain_charter.net',\n",
       " 'P_emaildomain_comcast.net',\n",
       " 'P_emaildomain_cox.net',\n",
       " 'P_emaildomain_earthlink.net',\n",
       " 'P_emaildomain_embarqmail.com',\n",
       " 'P_emaildomain_frontier.com',\n",
       " 'P_emaildomain_frontiernet.net',\n",
       " 'P_emaildomain_gmail',\n",
       " 'P_emaildomain_gmail.com',\n",
       " 'P_emaildomain_gmx.de',\n",
       " 'P_emaildomain_hotmail.co.uk',\n",
       " 'P_emaildomain_hotmail.com',\n",
       " 'P_emaildomain_hotmail.de',\n",
       " 'P_emaildomain_hotmail.es',\n",
       " 'P_emaildomain_hotmail.fr',\n",
       " 'P_emaildomain_icloud.com',\n",
       " 'P_emaildomain_juno.com',\n",
       " 'P_emaildomain_live.com',\n",
       " 'P_emaildomain_live.com.mx',\n",
       " 'P_emaildomain_live.fr',\n",
       " 'P_emaildomain_mac.com',\n",
       " 'P_emaildomain_mail.com',\n",
       " 'P_emaildomain_me.com',\n",
       " 'P_emaildomain_msn.com',\n",
       " 'P_emaildomain_netzero.com',\n",
       " 'P_emaildomain_netzero.net',\n",
       " 'P_emaildomain_optonline.net',\n",
       " 'P_emaildomain_outlook.com',\n",
       " 'P_emaildomain_outlook.es',\n",
       " 'P_emaildomain_prodigy.net.mx',\n",
       " 'P_emaildomain_protonmail.com',\n",
       " 'P_emaildomain_ptd.net',\n",
       " 'P_emaildomain_q.com',\n",
       " 'P_emaildomain_roadrunner.com',\n",
       " 'P_emaildomain_rocketmail.com',\n",
       " 'P_emaildomain_sbcglobal.net',\n",
       " 'P_emaildomain_sc.rr.com',\n",
       " 'P_emaildomain_servicios-ta.com',\n",
       " 'P_emaildomain_suddenlink.net',\n",
       " 'P_emaildomain_twc.com',\n",
       " 'P_emaildomain_verizon.net',\n",
       " 'P_emaildomain_web.de',\n",
       " 'P_emaildomain_windstream.net',\n",
       " 'P_emaildomain_yahoo.co.jp',\n",
       " 'P_emaildomain_yahoo.co.uk',\n",
       " 'P_emaildomain_yahoo.com',\n",
       " 'P_emaildomain_yahoo.com.mx',\n",
       " 'P_emaildomain_yahoo.de',\n",
       " 'P_emaildomain_yahoo.es',\n",
       " 'P_emaildomain_yahoo.fr',\n",
       " 'P_emaildomain_ymail.com',\n",
       " 'card4_discover',\n",
       " 'card4_mastercard',\n",
       " 'card4_visa',\n",
       " 'card6_credit',\n",
       " 'card6_debit',\n",
       " 'card6_debit or credit',\n",
       " 'M1_T',\n",
       " 'M2_T',\n",
       " 'M3_T',\n",
       " 'M4_M1',\n",
       " 'M4_M2',\n",
       " 'M6_T',\n",
       " 'addr1_fe',\n",
       " 'addr2_fe',\n",
       " 'card1_fe',\n",
       " 'card2_fe',\n",
       " 'card3_fe',\n",
       " 'card5_fe',\n",
       " 'P_emaildomain_2_fe']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# X = X.drop('addr1', axis=1)\n",
    "# X = X.drop('addr2', axis=1)\n",
    "# X = X.drop('addr3', axis=1)\n",
    "# X = X.drop('addr4', axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "X = fe.df_feat.drop(col_target, axis=1)\n",
    "X = X.drop(col_id, axis=1)\n",
    "y = df_features[col_target]\n",
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransactionDT',\n",
       " 'TransactionAmt',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'C8',\n",
       " 'C9',\n",
       " 'C10',\n",
       " 'C11',\n",
       " 'C12',\n",
       " 'C13',\n",
       " 'C14',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'D3',\n",
       " 'D4',\n",
       " 'D10',\n",
       " 'D11',\n",
       " 'D15',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'V29',\n",
       " 'V30',\n",
       " 'V31',\n",
       " 'V32',\n",
       " 'V33',\n",
       " 'V34',\n",
       " 'V35',\n",
       " 'V36',\n",
       " 'V37',\n",
       " 'V38',\n",
       " 'V39',\n",
       " 'V40',\n",
       " 'V41',\n",
       " 'V42',\n",
       " 'V43',\n",
       " 'V44',\n",
       " 'V45',\n",
       " 'V46',\n",
       " 'V47',\n",
       " 'V48',\n",
       " 'V49',\n",
       " 'V50',\n",
       " 'V51',\n",
       " 'V52',\n",
       " 'V53',\n",
       " 'V54',\n",
       " 'V55',\n",
       " 'V56',\n",
       " 'V57',\n",
       " 'V58',\n",
       " 'V59',\n",
       " 'V60',\n",
       " 'V61',\n",
       " 'V62',\n",
       " 'V63',\n",
       " 'V64',\n",
       " 'V65',\n",
       " 'V66',\n",
       " 'V67',\n",
       " 'V68',\n",
       " 'V69',\n",
       " 'V70',\n",
       " 'V71',\n",
       " 'V72',\n",
       " 'V73',\n",
       " 'V74',\n",
       " 'V75',\n",
       " 'V76',\n",
       " 'V77',\n",
       " 'V78',\n",
       " 'V79',\n",
       " 'V80',\n",
       " 'V81',\n",
       " 'V82',\n",
       " 'V83',\n",
       " 'V84',\n",
       " 'V85',\n",
       " 'V86',\n",
       " 'V87',\n",
       " 'V88',\n",
       " 'V89',\n",
       " 'V90',\n",
       " 'V91',\n",
       " 'V92',\n",
       " 'V93',\n",
       " 'V94',\n",
       " 'V95',\n",
       " 'V96',\n",
       " 'V97',\n",
       " 'V98',\n",
       " 'V99',\n",
       " 'V100',\n",
       " 'V101',\n",
       " 'V102',\n",
       " 'V103',\n",
       " 'V104',\n",
       " 'V105',\n",
       " 'V106',\n",
       " 'V107',\n",
       " 'V108',\n",
       " 'V109',\n",
       " 'V110',\n",
       " 'V111',\n",
       " 'V112',\n",
       " 'V113',\n",
       " 'V114',\n",
       " 'V115',\n",
       " 'V116',\n",
       " 'V117',\n",
       " 'V118',\n",
       " 'V119',\n",
       " 'V120',\n",
       " 'V121',\n",
       " 'V122',\n",
       " 'V123',\n",
       " 'V124',\n",
       " 'V125',\n",
       " 'V126',\n",
       " 'V127',\n",
       " 'V128',\n",
       " 'V129',\n",
       " 'V130',\n",
       " 'V131',\n",
       " 'V132',\n",
       " 'V133',\n",
       " 'V134',\n",
       " 'V135',\n",
       " 'V136',\n",
       " 'V137',\n",
       " 'V279',\n",
       " 'V280',\n",
       " 'V281',\n",
       " 'V282',\n",
       " 'V283',\n",
       " 'V284',\n",
       " 'V285',\n",
       " 'V286',\n",
       " 'V287',\n",
       " 'V288',\n",
       " 'V289',\n",
       " 'V290',\n",
       " 'V291',\n",
       " 'V292',\n",
       " 'V293',\n",
       " 'V294',\n",
       " 'V295',\n",
       " 'V296',\n",
       " 'V297',\n",
       " 'V298',\n",
       " 'V299',\n",
       " 'V300',\n",
       " 'V301',\n",
       " 'V302',\n",
       " 'V303',\n",
       " 'V304',\n",
       " 'V305',\n",
       " 'V306',\n",
       " 'V307',\n",
       " 'V308',\n",
       " 'V309',\n",
       " 'V310',\n",
       " 'V311',\n",
       " 'V312',\n",
       " 'V313',\n",
       " 'V314',\n",
       " 'V315',\n",
       " 'V316',\n",
       " 'V317',\n",
       " 'V318',\n",
       " 'V319',\n",
       " 'V320',\n",
       " 'V321',\n",
       " 'ProductCD_H',\n",
       " 'ProductCD_R',\n",
       " 'ProductCD_S',\n",
       " 'ProductCD_W',\n",
       " 'P_emaildomain_anonymous.com',\n",
       " 'P_emaildomain_aol.com',\n",
       " 'P_emaildomain_att.net',\n",
       " 'P_emaildomain_bellsouth.net',\n",
       " 'P_emaildomain_cableone.net',\n",
       " 'P_emaildomain_centurylink.net',\n",
       " 'P_emaildomain_cfl.rr.com',\n",
       " 'P_emaildomain_charter.net',\n",
       " 'P_emaildomain_comcast.net',\n",
       " 'P_emaildomain_cox.net',\n",
       " 'P_emaildomain_earthlink.net',\n",
       " 'P_emaildomain_embarqmail.com',\n",
       " 'P_emaildomain_frontier.com',\n",
       " 'P_emaildomain_frontiernet.net',\n",
       " 'P_emaildomain_gmail',\n",
       " 'P_emaildomain_gmail.com',\n",
       " 'P_emaildomain_gmx.de',\n",
       " 'P_emaildomain_hotmail.co.uk',\n",
       " 'P_emaildomain_hotmail.com',\n",
       " 'P_emaildomain_hotmail.de',\n",
       " 'P_emaildomain_hotmail.es',\n",
       " 'P_emaildomain_hotmail.fr',\n",
       " 'P_emaildomain_icloud.com',\n",
       " 'P_emaildomain_juno.com',\n",
       " 'P_emaildomain_live.com',\n",
       " 'P_emaildomain_live.com.mx',\n",
       " 'P_emaildomain_live.fr',\n",
       " 'P_emaildomain_mac.com',\n",
       " 'P_emaildomain_mail.com',\n",
       " 'P_emaildomain_me.com',\n",
       " 'P_emaildomain_msn.com',\n",
       " 'P_emaildomain_netzero.com',\n",
       " 'P_emaildomain_netzero.net',\n",
       " 'P_emaildomain_optonline.net',\n",
       " 'P_emaildomain_outlook.com',\n",
       " 'P_emaildomain_outlook.es',\n",
       " 'P_emaildomain_prodigy.net.mx',\n",
       " 'P_emaildomain_protonmail.com',\n",
       " 'P_emaildomain_ptd.net',\n",
       " 'P_emaildomain_q.com',\n",
       " 'P_emaildomain_roadrunner.com',\n",
       " 'P_emaildomain_rocketmail.com',\n",
       " 'P_emaildomain_sbcglobal.net',\n",
       " 'P_emaildomain_sc.rr.com',\n",
       " 'P_emaildomain_servicios-ta.com',\n",
       " 'P_emaildomain_suddenlink.net',\n",
       " 'P_emaildomain_twc.com',\n",
       " 'P_emaildomain_verizon.net',\n",
       " 'P_emaildomain_web.de',\n",
       " 'P_emaildomain_windstream.net',\n",
       " 'P_emaildomain_yahoo.co.jp',\n",
       " 'P_emaildomain_yahoo.co.uk',\n",
       " 'P_emaildomain_yahoo.com',\n",
       " 'P_emaildomain_yahoo.com.mx',\n",
       " 'P_emaildomain_yahoo.de',\n",
       " 'P_emaildomain_yahoo.es',\n",
       " 'P_emaildomain_yahoo.fr',\n",
       " 'P_emaildomain_ymail.com',\n",
       " 'card4_discover',\n",
       " 'card4_mastercard',\n",
       " 'card4_visa',\n",
       " 'card6_credit',\n",
       " 'card6_debit',\n",
       " 'card6_debit or credit',\n",
       " 'M1_T',\n",
       " 'M2_T',\n",
       " 'M3_T',\n",
       " 'M4_M1',\n",
       " 'M4_M2',\n",
       " 'M6_T',\n",
       " 'addr1_fe',\n",
       " 'addr2_fe',\n",
       " 'card1_fe',\n",
       " 'card2_fe',\n",
       " 'card3_fe',\n",
       " 'card5_fe',\n",
       " 'P_emaildomain_2_fe']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing algorithm ###\n",
    "import time\n",
    "start_time = time.time()\n",
    "# applying PCA\n",
    "scaled_X = StandardScaler().fit_transform(X)\n",
    "# pca = PCA(n_components=250)\n",
    "pca = PCA()\n",
    "pcomponents = pca.fit_transform(scaled_X)\n",
    "X_pca = pd.DataFrame(data=pcomponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic regression\n",
    "model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# predict\n",
    "y_pred = model_lr_pca_sm.predict(X_train2)\n",
    "# time\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS: NEXT, test without PCA\n",
    "\n",
    "# RESULTS: NEXT, keep ohe for email and create p email feature calculate email domain fraud feature\n",
    "\n",
    "\n",
    "# RESULTS: with new feature, try dropping ohe p_email and test\n",
    "# [[435499  77433]\n",
    "#  [  4539  14015]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.85    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.85      0.89    531486\n",
    "\n",
    "# RESULTS: cut FP rate quite a bit. fixing fraud perc calculation by doing fraud/non fraud for each value in each column\n",
    "# [[434423  78509]\n",
    "#  [  4430  14124]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.84    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.84      0.89    531486\n",
    "\n",
    "\n",
    "# RESULTS: adding 60 for one hot encoding\n",
    "# [[403339 109593]\n",
    "#  [  4393  14161]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.79      0.88    512932\n",
    "#            1       0.11      0.76      0.20     18554\n",
    "\n",
    "#     accuracy                           0.79    531486\n",
    "#    macro avg       0.55      0.77      0.54    531486\n",
    "# weighted avg       0.96      0.79      0.85    531486\n",
    "\n",
    "# RESULTS: fe for 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card5'\n",
    "# [[397116 115816]\n",
    "#  [  4490  14064]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.77      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: only addr6. Creating ratio ranking of higher risk areas for fraud. \n",
    "# [[396866 116066]\n",
    "#  [  4534  14020]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# NEXT, test creating iqr range instead of percentage values, instead of what we did\n",
    "# with addr5, then create one for addr2, then create an addr7 based on interaction with addr2. \n",
    "\n",
    "\n",
    "\n",
    "# RESULTS: only addr5. testing mapping percentage values transformed..\n",
    "# [[396898 116034]\n",
    "#  [  4535  14019]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with only addr3, addr4\n",
    "# [[396868 116064]\n",
    "#  [  4544  14010]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: w/o addr1, addr2, addr3, addr4\n",
    "# [[396629 116303]\n",
    "#  [  4545  14009]]\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with only addr1, addr2\n",
    "# [[396803 116129]\n",
    "#  [  4555  13999]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.75      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with addr1, addf2, addr3, addr4\n",
    "# [[396877 116055]\n",
    "#  [  4549  14005]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.75      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_lr_pca_sm.predict(X_pca)\n",
    "\n",
    "# cross validation\n",
    "# result = cross_val_score(model_lr_pca_sm, X_train2, y_train2, cv=10, n_jobs=-1, scoring='recall_score')\n",
    "# result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes, do we need to visualize our results?? We need to look at our confusion matrix\n",
    "# and decide how to improve our results from here... Test and see what happens if we \n",
    "# increase our principal components... test removing columns, adding columns, imputing\n",
    "# certain columns all together. \n",
    "\n",
    "# test imputing 500 or less for ohe. Then test dropping card1 due to its number\n",
    "# of unique values that would make our data very high dimensional. We can try only ohe for\n",
    "# the entire dataset to see how our model performs over all... Though.. it will likely run \n",
    "# out of memory and crash. \n",
    "\n",
    "# ALSO test probabilities on logisticregression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "plt.hist(y_pred_prob[:,1], bins=8)\n",
    "plt.xlim(0,1)\n",
    "plt.title(\"Histogram of Probability of Fraud\")\n",
    "plt.xlabel(\"Predicted probability of Fraud\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "y_pred_class = binarize(y_pred_prob, 0.5)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y, y_pred_class))\n",
    "print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title(\"ROC curve for fraud detection classifier\")\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(threshold):\n",
    "    print(\"Sensitivity:\", tpr[thresholds > threshold][-1])\n",
    "    print(\"Specificity:\", 1 - fpr[thresholds > threshold][-1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_threshold(.5)\n",
    "evaluate_threshold(.2)\n",
    "evaluate_threshold(.1)\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob[:,1]))\n",
    "# NEXT CONT, from here on youtube vid 49:00. once we finish the video\n",
    "# go back to improving the model using feature selection, eda, \n",
    "# and decision tree eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_actual = model_lr_pca.predict(X_test2) # actual prediction test data set\n",
    "print('y_pred_actual on test set\\n')\n",
    "print(y_pred_actual[0:10])\n",
    "print(confusion_matrix(y_test2, y_pred_actual))\n",
    "print(classification_report(y_test2, y_pred_actual))\n",
    "\n",
    "print('y_pred_proba\\n')\n",
    "y_pred_proba = model_lr_pca.predict_proba(X_test2)\n",
    "y_pred_class = binarize(y_pred_proba, 0.5)[:,1]\n",
    "print(y_pred_class[0:10])\n",
    "print(confusion_matrix(y_test2, y_pred_class))\n",
    "print(classification_report(y_test2, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_actual = model_lr_pca.predict(X_pca) # actual full data set\n",
    "print('Logistic Regression')\n",
    "print('y_pred_actual full data set\\n')\n",
    "print(y_pred_actual[0:10])\n",
    "print(confusion_matrix(y, y_pred_actual))\n",
    "print(classification_report(y, y_pred_actual))\n",
    "\n",
    "print('y_pred_proba full data set\\n')\n",
    "y_pred_proba = model_lr_pca.predict_proba(X_pca)#[:,1]#[0:10]\n",
    "y_pred_class = binarize(y_pred_proba, 0.2)[:,1]\n",
    "print(y_pred_class[0:10])\n",
    "print(confusion_matrix(y, y_pred_class))\n",
    "print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicting on test set w/o PCA\n",
    "print(\"Predicting using Logistic Regression, PCA, SMOTE\\n\")\n",
    "y_pred_pca_sm = model_lr_pca.predict(X_test2)\n",
    "# y_pred_test1 = model_lr.predict(X_test1)\n",
    "print(\"Test set:\")\n",
    "print(\"Validation results\")\n",
    "print(model_lr_pca.score(X_test2, y_test2))\n",
    "print(recall_score(y_test2, y_pred_pca_sm))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y_test2, y_pred_pca_sm))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test2, y_pred_pca_sm))\n",
    "\n",
    "# predicting on original dataset\n",
    "print(\"Whole dataset:\")\n",
    "y_pred_pca_sm_whole = model_lr_pca.predict(X_pca)\n",
    "print(\"\\nTest Results\")\n",
    "print(model_lr_pca.score(X_pca, y))\n",
    "print(recall_score(y, y_pred_pca_sm_whole))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y, y_pred_pca_sm_whole))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y, y_pred_pca_sm_whole))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - w/PCA w/SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_pca_smote.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_pca_smote.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_dt_pca_smote.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test set w/o PCA\n",
    "print(\"Predicting using PCA\\n\")\n",
    "y_pred_pca = model_dt_pca_smote.predict(X_test2)\n",
    "# y_pred_test1 = model_lr.predict(X_test1)\n",
    "print(\"Test set:\")\n",
    "print(\"Validation results\")\n",
    "print(model_dt_pca_smote.score(X_test2, y_test2))\n",
    "print(recall_score(y_test2, y_pred_pca))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y_test2, y_pred_pca))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test2, y_pred_pca))\n",
    "\n",
    "# predicting on original dataset\n",
    "print(\"Whole dataset:\")\n",
    "y_pred_pca = model_dt_pca_smote.predict(X_pca)\n",
    "print(\"\\nTest Results\")\n",
    "print(model_dt_pca_smote.score(X_pca, y))\n",
    "print(recall_score(y, y_pred_pca))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y, y_pred_pca))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y, y_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"\\nPrincipal components explained:\")\n",
    "pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # explaining variance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))\n",
    "\n",
    "# # # predicting on original dataset\n",
    "# # y_pred = clf_lr.predict(X)\n",
    "# # print(\"\\nTest Results\")\n",
    "# # print(clf_lr.score(X, y))\n",
    "# # print(recall_score(y, y_pred))\n",
    "# # print(\"\\nConfusion Matrix\")\n",
    "# # print(confusion_matrix(y, y_pred))\n",
    "# # print('\\nClassification Report:\\n')\n",
    "# # print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X2 = StandardScaler().fit_transform(X)\n",
    "# pca3 = PCA(n_components=275)\n",
    "# pcomponents = pca3.fit_transform(scaled_X2)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying SMOTE to train set to correct class imbalance\n",
    "sm = SMOTE(random_state=42, ratio = 1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting to residuals created by SMOTE\n",
    "clf_lr = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf_lr.fit(X_train_res, y_train_res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test set\n",
    "y_test_pred = clf_lr.predict(X_test)\n",
    "print(\"Validation results\")\n",
    "print(clf_lr.score(X_test, y_test))\n",
    "print(recall_score(y_test, y_test_pred))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on original dataset\n",
    "y_pred = clf_lr.predict(X)\n",
    "print(\"\\nTest Results\")\n",
    "print(clf_lr.score(X, y))\n",
    "print(recall_score(y, y_pred))\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf = LogisticRegression(class_weight='balanced').fit(X_train, y_train)\n",
    "# clf.predict(X_test)\n",
    "# clf.score(X_test, y_test)\n",
    "# 0.7870216903822372 \n",
    "# 0.8013998429794899 < 60\n",
    "# 0.5085411973583608 < 1000\n",
    "# 0.63556873752431 < 60 dropped col_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # confusion matrix\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read up on class im balance and correct it. \n",
    "# perhaps we can one by one run our model through a decision tree and do one hot encoding for one big \n",
    "# categorical column at a time lets say 13,000 unique values, then we can see of the new 13,000 columns we\n",
    "# have if any actually have predictive value for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "\n",
    "# # define iv\n",
    "# iv = X.columns\n",
    "\n",
    "# # fit the logistic regression function\n",
    "# logReg = sm.Logit(y_train, X_train)\n",
    "# answer = logReg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in pp.df_train.columns:\n",
    "#     if (pp.df_train[pp.df_train[val]=='nan'].shape[0]) > 0:\n",
    "#         print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pp.df_train\n",
    "# # lets find out which columns are object... \n",
    "# list_col_object = []\n",
    "# for val in pp.df_train.columns:\n",
    "#     if pp.df_train[val].dtype=='O':\n",
    "#         list_col_object.append(val)\n",
    "        \n",
    "# pp.df_train[list_col_object]\n",
    "# # for card2, nan was the most commonly seen value... so it imputed that...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in pp.df_train.columns:\n",
    "#     if pp.df_train[pp.df_train[val]=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_col_object = []\n",
    "# for val in pp.df_train.columns:\n",
    "#     if pp.df_train[val]:\n",
    "#         list_col_object.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(pp.df_train[list_col_object].isnull())\n",
    "# pp.df_train['card2'].unique()\n",
    "# pp.df_train[df_train['card2']=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(np.sum(pp.df_train.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clean the data before thinking about applying PCA. \n",
    "# 1. Determine which columns are continuous, which are ranking.\n",
    "# 2. Determine which columns are bool (easy)\n",
    "# 3. Determine which columns are categorical, then impute with pandas (we dont know which columns means what\n",
    "#    so we cant assume True or better than False, etc.)\n",
    "# 4. After \n",
    "\n",
    "# 1. impute all objects columns with one hot encoding\n",
    "# 1.1 What's a categorical? \n",
    "# We know the V's are ranking.. we need to discern meaning, \n",
    "\n",
    "# 2. figure out if we should do pca next. we should do that next..\n",
    "# 3. then stand up the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(df_train['V14'])\n",
    "# sns.barplot(df_train['V196'])\n",
    "# we need to imput the mode here.. \n",
    "# df_train['V14'].mode()\n",
    "# df_train['V22'].unique()\n",
    "# for val in col_v:\n",
    "#     print(val)\n",
    "#     print(df_train[val].unique())\n",
    "# we ned to descern what is a 0 1 outcome then impute.\n",
    "\n",
    "# col = 'V290'\n",
    "# series_temp = df_train[col].fillna(df_train[col].mode()[0])\n",
    "# plt.hist(series_temp);\n",
    "# missing_val = np.sum(df_train[col].isnull())\n",
    "# print('Missing values: ' + str(missing_val))\n",
    "# print(\"REAL VALUE COUNTS: \")\n",
    "# df_train[col].value_counts().head()\n",
    "\n",
    "# col = 'card4'\n",
    "# series_temp = df_train[col].fillna(df_train[col].mode()[0])\n",
    "# plt.hist(series_temp);\n",
    "# df_train[col].value_counts()\n",
    "\n",
    "# col = 'D1'\n",
    "# series_temp = df_train[col].fillna(df_train[col].mean())\n",
    "# plt.hist(series_temp);\n",
    "# df_train['D1'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
