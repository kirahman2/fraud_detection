{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_raw = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.head() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.info(); # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.info(); # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_null = df_train.isnull().any()\n",
    "# df_null = pd.DataFrame(list_null).reset_index()\n",
    "# df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.loc[:,df_train.isnull().any()]['id_34'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# train_transaction_sum = train_transaction.duplicated().sum()\n",
    "# train_identity_sum = train_identity.duplicated().sum()\n",
    "# columns = train_transaction.columns\n",
    "# print('Train transaction duplicates: {}\\nTrain identity duplicates: {} \\n'.format(train_transaction_sum, train_identity_sum))\n",
    "# # print('Train feature columns:\\n', list(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.dtypes # KEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many transactions are in the dataset?\n",
    "# df_train.shape # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the fraud rate of the data set?\n",
    "# fraud_rate = df_train.isFraud.value_counts() / 590540\n",
    "# fraud_rate  # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the statistical overview of the data set?\n",
    "# df_train.describe() # KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary = df_train.groupby('isFraud')\n",
    "# fraud_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_groupby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "# D = time elapsed between each transaction, card = card information, C = counting, ie how many addresses \n",
    "# associated with card, M=True/False, V created features on ranking, counting, etc. \n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# boolean columns. convert via dummy variable. We dont know if true/false is better than one or the other. \n",
    "# col_bool = col_m\n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))\n",
    "\n",
    "# columns removed dist1, dist2, R_emaildomain, DeviceInfo, DeviceType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train.copy()\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "#                 self.list_mode_value.append('MISSING')\n",
    "\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "#                 print(\"fillna,\" + str(val))\n",
    "\n",
    "#                 self.df_train[val] = self.df_train[val].fillna('MISSING')\n",
    "    \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()\n",
    "# df_null_info\n",
    "\n",
    "# determine what to do with columns that have too many unique values... obviously.. types of solutions\n",
    "# would be to put \"MISSING\" for those that dont have an email address... but you will need to evaluate \n",
    "# and make instead a counter of unique values, then append that and look at the CSV via google sheets. use \n",
    "# something like the code below \n",
    "\n",
    "# TEST: test imputing with missing instead of mode to see if we have improvements in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoded: addr1 unique 333\n",
      "label encoded: addr2 unique 75\n",
      "dummies encoded: ProductCD unique 5\n",
      "dummies encoded: P_emaildomain unique 59\n",
      "label encoded: card1 unique 13553\n",
      "label encoded: card2 unique 501\n",
      "label encoded: card3 unique 115\n",
      "dummies encoded: card4 unique 4\n",
      "label encoded: card5 unique 120\n",
      "dummies encoded: card6 unique 4\n",
      "dummies encoded: M1 unique 2\n",
      "dummies encoded: M2 unique 2\n",
      "dummies encoded: M3 unique 2\n",
      "dummies encoded: M4 unique 3\n",
      "dummies encoded: M6 unique 2\n",
      "new dataframe shape:(590540, 285)\n"
     ]
    }
   ],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['addr1', 'addr2', 'ProductCD', 'P_emaildomain', 'card1', 'card2', 'card3', 'card4', \n",
    "#  'card5', 'card6', 'M1', 'M2', 'M3', 'M4', 'M6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>V40</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isFraud</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.221568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V40</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.213533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V44</td>\n",
       "      <td>0.217870</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.515480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V45</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.608788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V51</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.257145</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.196567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V52</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.745758</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.296102</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>0.207535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V86</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.604776</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.212453</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V87</td>\n",
       "      <td>0.221568</td>\n",
       "      <td>0.213533</td>\n",
       "      <td>0.515480</td>\n",
       "      <td>0.608788</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>0.207535</td>\n",
       "      <td>0.850021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          isFraud       V40       V44       V45       V51       V52       V86  \\\n",
       "isFraud  1.000000  0.174672  0.217870  0.235436  0.182007  0.195492  0.222343   \n",
       "V40      0.174672  1.000000  0.225232  0.271469  0.744831  0.745758  0.217055   \n",
       "V44      0.217870  0.225232  1.000000  0.905537  0.257145  0.251881  0.604776   \n",
       "V45      0.235436  0.271469  0.905537  1.000000  0.257400  0.296102  0.585396   \n",
       "V51      0.182007  0.744831  0.257145  0.257400  1.000000  0.954315  0.212453   \n",
       "V52      0.195492  0.745758  0.251881  0.296102  0.954315  1.000000  0.215183   \n",
       "V86      0.222343  0.217055  0.604776  0.585396  0.212453  0.215183  1.000000   \n",
       "V87      0.221568  0.213533  0.515480  0.608788  0.196567  0.207535  0.850021   \n",
       "\n",
       "              V87  \n",
       "isFraud  0.221568  \n",
       "V40      0.213533  \n",
       "V44      0.515480  \n",
       "V45      0.608788  \n",
       "V51      0.196567  \n",
       "V52      0.207535  \n",
       "V86      0.850021  \n",
       "V87      1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_summary = df_features.groupby('isFraud')\n",
    "fraud_summary.mean().to_csv('/Users/krahman/work/fraud_detection/saved_files/fraud_summary.csv')\n",
    "\n",
    "corr = df_features.corr()\n",
    "corr.to_csv('/Users/krahman/work/fraud_detection/saved_files/corr_matrix.csv')\n",
    "corr2 = corr[corr['isFraud']>.17]\n",
    "corr2 = corr2.loc[:,corr2.index]\n",
    "\n",
    "sns.heatmap(corr2,\n",
    "           xticklabels=corr2.columns.values,\n",
    "           yticklabels=corr2.columns.values)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,4))\n",
    "# sns.barplot(x='V44', y='V44', hue='isFraud', data=df_train)\n",
    "# plt.show()\n",
    "\n",
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X.card1, y)\n",
    "# sns.regplot(x='card5_237.0', y='isFraud', data=pp.df_train, logistic=True, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dropping Features On Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# y_test = pp.df_train[col_target] #.rename(columns=['isFraud'])\n",
    "# y_test = pd.Series(y_test)\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing dropping columns\n",
    "# model_lr_results = pd.DataFrame()\n",
    "# model_recall = []\n",
    "# model_precision = []\n",
    "# model_auc_score = []\n",
    "\n",
    "# for col in ['addr1', 'addr2', 'P_emaildomain', 'card1', 'card2', 'card3', 'card5']:\n",
    "#     print('Dropping: ', col)\n",
    "#     X_drop = X.drop(col, axis=1)\n",
    "# #     X_drop = X_drop.loc[:10000,:]\n",
    "#     y_drop = y#[:10001]\n",
    "    \n",
    "#     scaled_X = StandardScaler().fit_transform(X_drop)\n",
    "#     # pca\n",
    "#     pca = PCA()\n",
    "#     pcomponents = pca.fit_transform(scaled_X)\n",
    "#     X_pca = pd.DataFrame(data=pcomponents)\n",
    "#     # split\n",
    "#     X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y_drop, test_size=0.1, random_state=42)\n",
    "#     # smote\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "#     # model fit\n",
    "#     model_lr_pca = LogisticRegression(random_state=42)\n",
    "#     model_lr_pca.fit(X_train_res, y_train_res)\n",
    "#     # predict\n",
    "#     y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "#     y_pred_class = binarize(y_pred_prob, 0.5)[:,1]\n",
    "#     # scoring\n",
    "#     model_recall.append(recall_score(y_drop, y_pred_class))\n",
    "#     model_precision.append(precision_score(y_drop, y_pred_class))\n",
    "#     model_auc_score.append(roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "#     print(confusion_matrix(y_drop, y_pred_class))\n",
    "#     print(classification_report(y_drop, y_pred_class))\n",
    "#     print('AUC: ', roc_auc_score(y_drop, y_pred_prob[:,1]))\n",
    "\n",
    "# model_recall = pd.Series(model_recall, name='recall')\n",
    "# model_precision = pd.Series(model_precision, name='precision')\n",
    "# model_auc_score = pd.Series(model_auc_score, name='auc_score')\n",
    "# model_results_final = pd.concat([model_auc_score, model_recall, model_precision],axis=1)\n",
    "# model_results_final\n",
    "\n",
    "# # it's apparent that label encoding on some of these don't really matter and if we drop them.. it doesn't really\n",
    "# # matter.. \n",
    "# # dropping these columns has little impact with logistic regression.. \n",
    "\n",
    "# # tune logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DELETE\n",
    "\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final\n",
    "\n",
    "# df_temp = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "# df_temp[0:20]\n",
    "# pd.DataFrame(pca.components_, columns=list(X_temp.columns), index=range(0,225))\n",
    "# pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA (2 components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardizing our data, which is required for PCA.\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # PCA instantiate and fit \n",
    "# pca = PCA(n_components=2)\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data = pcomponents, columns=['PC1','PC2'])\n",
    "# print(X_pca.shape)\n",
    "# X_pca.head()\n",
    "\n",
    "# # two principal components scatter plot\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.scatter(X_pca['PC1'], X_pca['PC2'], c=y['isFraud'])\n",
    "# plt.xlabel('First principal component')\n",
    "# plt.ylabel('Second principal component')\n",
    "\n",
    "# # explaining vaariance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA to all features (all components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca2 = PCA().fit(scaled_X)\n",
    "# plt.plot(np.cumsum(pca2.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Variance (%)')\n",
    "# plt.title('Credit Card Fraud Explained Variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model w/ SMOTE only - base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # Apply SMOTE\n",
    "# sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train1, y_train1)\n",
    "\n",
    "# model_lr = LogisticRegression(random_state=42)\n",
    "# model_lr.fit(X_train_res, y_train_res) \n",
    "\n",
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using only SMOTE (and w/o PCA)\\n\")\n",
    "# y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_lr.score(X_test1, y_test1))\n",
    "# print(recall_score(y_test1, y_pred_test1))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test1, y_pred_test1))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test1, y_pred_test1))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred = model_lr.predict(X)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_lr.score(X, y))\n",
    "# print(recall_score(y, y_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression w/PCA  w/SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(x='addr1', y='addr2', data=df_features,\n",
    "#            fit_reg=False, hue='isFraud')\n",
    "# plt.title('addr1 versus addr2')\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(df_features.addr1)\n",
    "# plt.title('Addr1 Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EDA Email Class\n",
    "# # P_emaildomain\n",
    "# # list(df_train.columns)\n",
    "# # df_train.P_emaildomain.unique()\n",
    "# list_perc = []\n",
    "# list_fraud_count = []\n",
    "# list_non_fraud_count = []\n",
    "# for val in df_train.P_emaildomain.unique():\n",
    "#     non_fraud_count = df_train[(df_train.P_emaildomain==val) & (df_train.isFraud==0)].shape[0]\n",
    "#     fraud_count = df_train[(df_train.P_emaildomain==val) & (df_train.isFraud==1)].shape[0]\n",
    "    \n",
    "#     list_perc.append(fraud_count/non_fraud_count)\n",
    "    \n",
    "#     list_fraud_count.append(fraud_count)\n",
    "#     list_non_fraud_count.append(non_fraud_count)\n",
    "    \n",
    "# col_email = pd.Series(df_train.P_emaildomain.unique(), name='email')\n",
    "# col_perc = pd.Series(list_perc, name='fraud_perc')\n",
    "# col_fraud_count = pd.Series(list_fraud_count, name='fraud_count')\n",
    "# col_non_fraud_count = pd.Series(list_non_fraud_count, name='non_fraud_count')\n",
    "\n",
    "# # col_perc\n",
    "# df_email_fe = pd.concat([col_email, col_perc, col_fraud_count, col_non_fraud_count], axis=1)\n",
    "# # df_email_fe\n",
    "# # df_train[(df_train.P_emaildomain=='outlook.com') & (df_train.isFraud==1)].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: less occurring email domains are more likely to have higher fraud_perc because they are \n",
    "# perhaps an email provider with less resources. The card that the holder has attached to certain email\n",
    "# addresses puts them at higher risk for fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw.dtypes\n",
    "# df_features = df_\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features['P_emaildomain_copy'] = df_train['P_emaildomain']\n",
    "class FeatureEngineering():\n",
    "    '''create engineered features for columns without ordinal values'''\n",
    "    def __init__(self):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.df_raw = df_raw.copy()\n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "#         self.list_new_feat = [] # delete redundant\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        \n",
    "    def create_feature(self, col):\n",
    "        '''creates correllated ratio to target column'''\n",
    "        df_feat = df_features.copy()\n",
    "        \n",
    "        for col in df_temp_fe.columns:\n",
    "            df_temp_fe2 = pd.concat([df_features, df_temp_fe[col]], axis=1)\n",
    "            df_feat = self._calculate_fraud_perc(col, df_feat) \n",
    "            df_feat = self._map_col(col, df_feat)\n",
    "            df_feat = self._create_ratio(df_feat)\n",
    "            df_feat = df_feat.drop(col, axis=1)\n",
    "        \n",
    "#         df_feat = self._calculate_fraud_perc(col, df_feat) \n",
    "# #         self.list_new_feat.append(col_val + '_fe') ### delete?\n",
    "#         df_feat = self._map_col(col, df_feat)\n",
    "#         df_feat = self._create_ratio(df_feat)\n",
    "#         df_feat = df_feat.drop(col, axis=1)\n",
    "# #         print(list(df_feat.columns))\n",
    "\n",
    "        return df_feat\n",
    "\n",
    "    def aggregate_features(self, list_col, val_aggreg):\n",
    "        for col in list_col:\n",
    "            df_groupby = self.df_raw.groupby(col).mean()\n",
    "            dict_aggreg_col = df_groupby[[val_aggreg]].to_dict()\n",
    "            self.df_feat[col + '_fe'] = self.df_raw[col].map(dict_aggreg_col['TransactionAmt'])\n",
    "            col_mode = self.df_feat[col + '_fe'].mode()[0]\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col + '_fe'].fillna(col_mode)\n",
    "\n",
    "    def _calculate_fraud_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage for each column'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==1)].shape[0]\n",
    "            non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "            if (non_fraud_total==0):\n",
    "                list_perc.append(0)\n",
    "            else: \n",
    "                list_perc.append(fraud_total/non_fraud_total)\n",
    "        self._create_dict(col_val, list_perc, unique_col_values) # call _create_dict \n",
    "        return df_feat\n",
    "\n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self, col, df_feat):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for val in dict_keys:\n",
    "            df_feat[col + '_fe'] = df_feat[col].map(self.dict_all_feat[val])\n",
    "            self.new_col.append(col + '_fe')\n",
    "        return df_feat\n",
    "            \n",
    "    def _create_ratio(self, df_feat):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "#             print(val) ### delete\n",
    "            col_min_val = df_feat[df_feat[val] > 0][val].min()\n",
    "            df_feat[val] = df_feat[val]/col_min_val\n",
    "        self.new_col = []\n",
    "        return df_feat\n",
    "#             \n",
    "\n",
    "# list_col = ['addr1', 'addr2', 'card1', 'card2', 'card3', 'card5', 'P_emaildomain_copy']\n",
    "# list_col = ['addr1'] # needed for instantiating fe class.\n",
    "fe = FeatureEngineering()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_col = ['TransactionAmt']#, 'card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new feature from card2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78     56945\n",
      "           1       0.07      0.72      0.13      2109\n",
      "\n",
      "    accuracy                           0.65     59054\n",
      "   macro avg       0.53      0.68      0.45     59054\n",
      "weighted avg       0.95      0.65      0.76     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "536       card1  0.711712   0.084118  608  16343  40602  1501   \n",
      "537       card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "538       card3  0.738739   0.060043  551  24390  32555  1558   \n",
      "539       card5  0.738739   0.059339  551  24698  32247  1558   \n",
      "0         card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "536            3.294828  \n",
      "537            3.457456  \n",
      "538            3.500424  \n",
      "539            3.619894  \n",
      "0              4.987315  \n",
      "Creating new feature from C4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.67      0.79     56945\n",
      "           1       0.07      0.67      0.13      2109\n",
      "\n",
      "    accuracy                           0.67     59054\n",
      "   macro avg       0.53      0.67      0.46     59054\n",
      "weighted avg       0.95      0.67      0.77     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "537       card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "538       card3  0.738739   0.060043  551  24390  32555  1558   \n",
      "539       card5  0.738739   0.059339  551  24698  32247  1558   \n",
      "540       card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "0            C4  0.673779   0.069732  688  18957  37988  1421   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "537            3.457456  \n",
      "538            3.500424  \n",
      "539            3.619894  \n",
      "540            4.987315  \n",
      "0              3.560533  \n",
      "Creating new feature from C1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.58      0.73     56945\n",
      "           1       0.06      0.74      0.11      2109\n",
      "\n",
      "    accuracy                           0.58     59054\n",
      "   macro avg       0.52      0.66      0.42     59054\n",
      "weighted avg       0.95      0.58      0.71     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "538       card3  0.738739   0.060043  551  24390  32555  1558   \n",
      "539       card5  0.738739   0.059339  551  24698  32247  1558   \n",
      "540       card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "541          C4  0.673779   0.069732  688  18957  37988  1421   \n",
      "0            C1  0.738265   0.060835  552  24037  32908  1557   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "538            3.500424  \n",
      "539            3.619894  \n",
      "540            4.987315  \n",
      "541            3.560533  \n",
      "0              3.325386  \n",
      "Creating new feature from V317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.59      0.74     56945\n",
      "           1       0.06      0.73      0.11      2109\n",
      "\n",
      "    accuracy                           0.60     59054\n",
      "   macro avg       0.52      0.66      0.43     59054\n",
      "weighted avg       0.95      0.60      0.72     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "539       card5  0.738739   0.059339  551  24698  32247  1558   \n",
      "540       card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "541          C4  0.673779   0.069732  688  18957  37988  1421   \n",
      "542          C1  0.738265   0.060835  552  24037  32908  1557   \n",
      "0          V317  0.729256   0.062325  571  23139  33806  1538   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "539            3.619894  \n",
      "540            4.987315  \n",
      "541            3.560533  \n",
      "542            3.325386  \n",
      "0              3.473626  \n",
      "\n",
      "Column ProductCD does not exist in dataframe.\n",
      "\n",
      "Creating new feature from V294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.59      0.74     56945\n",
      "           1       0.06      0.72      0.11      2109\n",
      "\n",
      "    accuracy                           0.60     59054\n",
      "   macro avg       0.52      0.65      0.43     59054\n",
      "weighted avg       0.95      0.60      0.72     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "540       card2  0.720247   0.070052  590  20165  36780  1519   \n",
      "541          C4  0.673779   0.069732  688  18957  37988  1421   \n",
      "542          C1  0.738265   0.060835  552  24037  32908  1557   \n",
      "543        V317  0.729256   0.062325  571  23139  33806  1538   \n",
      "0          V294  0.717402   0.061223  596  23200  33745  1513   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "540            4.987315  \n",
      "541            3.560533  \n",
      "542            3.325386  \n",
      "543            3.473626  \n",
      "0              3.329275  \n",
      "Creating new feature from V279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.57      0.72     56945\n",
      "           1       0.06      0.73      0.11      2109\n",
      "\n",
      "    accuracy                           0.57     59054\n",
      "   macro avg       0.52      0.65      0.41     59054\n",
      "weighted avg       0.95      0.57      0.70     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "541          C4  0.673779   0.069732  688  18957  37988  1421   \n",
      "542          C1  0.738265   0.060835  552  24037  32908  1557   \n",
      "543        V317  0.729256   0.062325  571  23139  33806  1538   \n",
      "544        V294  0.717402   0.061223  596  23200  33745  1513   \n",
      "0          V279  0.732101   0.058992  565  24629  32316  1544   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "541            3.560533  \n",
      "542            3.325386  \n",
      "543            3.473626  \n",
      "544            3.329275  \n",
      "0              1.150144  \n",
      "Creating new feature from C14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     56945\n",
      "           1       0.06      0.76      0.11      2109\n",
      "\n",
      "    accuracy                           0.57     59054\n",
      "   macro avg       0.52      0.66      0.41     59054\n",
      "weighted avg       0.95      0.57      0.69     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "542          C1  0.738265   0.060835  552  24037  32908  1557   \n",
      "543        V317  0.729256   0.062325  571  23139  33806  1538   \n",
      "544        V294  0.717402   0.061223  596  23200  33745  1513   \n",
      "545        V279  0.732101   0.058992  565  24629  32316  1544   \n",
      "0           C14  0.757705   0.059956  511  25055  31890  1598   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "542            3.325386  \n",
      "543            3.473626  \n",
      "544            3.329275  \n",
      "545            1.150144  \n",
      "0              2.036437  \n",
      "\n",
      "Column card6 does not exist in dataframe.\n",
      "\n",
      "Creating new feature from V306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.59      0.74     56945\n",
      "           1       0.06      0.73      0.11      2109\n",
      "\n",
      "    accuracy                           0.59     59054\n",
      "   macro avg       0.52      0.66      0.42     59054\n",
      "weighted avg       0.95      0.59      0.71     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "543        V317  0.729256   0.062325  571  23139  33806  1538   \n",
      "544        V294  0.717402   0.061223  596  23200  33745  1513   \n",
      "545        V279  0.732101   0.058992  565  24629  32316  1544   \n",
      "546         C14  0.757705   0.059956  511  25055  31890  1598   \n",
      "0          V306  0.732575   0.061723  564  23486  33459  1545   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "543            3.473626  \n",
      "544            3.329275  \n",
      "545            1.150144  \n",
      "546            2.036437  \n",
      "0              3.428800  \n",
      "Creating new feature from V69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.60      0.74     56945\n",
      "           1       0.06      0.71      0.11      2109\n",
      "\n",
      "    accuracy                           0.60     59054\n",
      "   macro avg       0.52      0.66      0.43     59054\n",
      "weighted avg       0.95      0.60      0.72     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "544        V294  0.717402   0.061223  596  23200  33745  1513   \n",
      "545        V279  0.732101   0.058992  565  24629  32316  1544   \n",
      "546         C14  0.757705   0.059956  511  25055  31890  1598   \n",
      "547        V306  0.732575   0.061723  564  23486  33459  1545   \n",
      "0           V69  0.712186   0.061785  607  22808  34137  1502   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "544            3.329275  \n",
      "545            1.150144  \n",
      "546            2.036437  \n",
      "547            3.428800  \n",
      "0              3.744155  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new feature from D1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.60      0.75     56945\n",
      "           1       0.06      0.71      0.11      2109\n",
      "\n",
      "    accuracy                           0.61     59054\n",
      "   macro avg       0.52      0.66      0.43     59054\n",
      "weighted avg       0.95      0.61      0.72     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "545        V279  0.732101   0.058992  565  24629  32316  1544   \n",
      "546         C14  0.757705   0.059956  511  25055  31890  1598   \n",
      "547        V306  0.732575   0.061723  564  23486  33459  1545   \n",
      "548         V69  0.712186   0.061785  607  22808  34137  1502   \n",
      "0            D1  0.709341   0.062113  613  22589  34356  1496   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "545            1.150144  \n",
      "546            2.036437  \n",
      "547            3.428800  \n",
      "548            3.744155  \n",
      "0              3.203725  \n",
      "Creating new feature from D2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     56945\n",
      "           1       0.06      0.75      0.11      2109\n",
      "\n",
      "    accuracy                           0.57     59054\n",
      "   macro avg       0.52      0.66      0.41     59054\n",
      "weighted avg       0.95      0.57      0.69     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "546         C14  0.757705   0.059956  511  25055  31890  1598   \n",
      "547        V306  0.732575   0.061723  564  23486  33459  1545   \n",
      "548         V69  0.712186   0.061785  607  22808  34137  1502   \n",
      "549          D1  0.709341   0.062113  613  22589  34356  1496   \n",
      "0            D2  0.750119   0.059384  527  25058  31887  1582   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "546            2.036437  \n",
      "547            3.428800  \n",
      "548            3.744155  \n",
      "549            3.203725  \n",
      "0              3.429228  \n",
      "Creating new feature from D3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.59      0.74     56945\n",
      "           1       0.06      0.72      0.11      2109\n",
      "\n",
      "    accuracy                           0.60     59054\n",
      "   macro avg       0.52      0.66      0.43     59054\n",
      "weighted avg       0.95      0.60      0.72     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "547        V306  0.732575   0.061723  564  23486  33459  1545   \n",
      "548         V69  0.712186   0.061785  607  22808  34137  1502   \n",
      "549          D1  0.709341   0.062113  613  22589  34356  1496   \n",
      "550          D2  0.750119   0.059384  527  25058  31887  1582   \n",
      "0            D3  0.719298   0.061390  592  23194  33751  1517   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "547            3.428800  \n",
      "548            3.744155  \n",
      "549            3.203725  \n",
      "550            3.429228  \n",
      "0              1.187169  \n",
      "Creating new feature from D4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79     56945\n",
      "           1       0.07      0.68      0.12      2109\n",
      "\n",
      "    accuracy                           0.66     59054\n",
      "   macro avg       0.53      0.67      0.46     59054\n",
      "weighted avg       0.95      0.66      0.76     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "548         V69  0.712186   0.061785  607  22808  34137  1502   \n",
      "549          D1  0.709341   0.062113  613  22589  34356  1496   \n",
      "550          D2  0.750119   0.059384  527  25058  31887  1582   \n",
      "551          D3  0.719298   0.061390  592  23194  33751  1517   \n",
      "0            D4  0.683736   0.068507  667  19607  37338  1442   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "548            3.744155  \n",
      "549            3.203725  \n",
      "550            3.429228  \n",
      "551            1.187169  \n",
      "0              2.951713  \n",
      "Creating new feature from D10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.58      0.73     56945\n",
      "           1       0.06      0.73      0.11      2109\n",
      "\n",
      "    accuracy                           0.59     59054\n",
      "   macro avg       0.52      0.66      0.42     59054\n",
      "weighted avg       0.95      0.59      0.71     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "549          D1  0.709341   0.062113  613  22589  34356  1496   \n",
      "550          D2  0.750119   0.059384  527  25058  31887  1582   \n",
      "551          D3  0.719298   0.061390  592  23194  33751  1517   \n",
      "552          D4  0.683736   0.068507  667  19607  37338  1442   \n",
      "0           D10  0.728781   0.060579  572  23835  33110  1537   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "549            3.203725  \n",
      "550            3.429228  \n",
      "551            1.187169  \n",
      "552            2.951713  \n",
      "0              4.441769  \n",
      "Creating new feature from D11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.61      0.75     56945\n",
      "           1       0.06      0.70      0.11      2109\n",
      "\n",
      "    accuracy                           0.61     59054\n",
      "   macro avg       0.52      0.65      0.43     59054\n",
      "weighted avg       0.95      0.61      0.73     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "550          D2  0.750119   0.059384  527  25058  31887  1582   \n",
      "551          D3  0.719298   0.061390  592  23194  33751  1517   \n",
      "552          D4  0.683736   0.068507  667  19607  37338  1442   \n",
      "553         D10  0.728781   0.060579  572  23835  33110  1537   \n",
      "0           D11  0.700332   0.062077  632  22316  34629  1477   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "550            3.429228  \n",
      "551            1.187169  \n",
      "552            2.951713  \n",
      "553            4.441769  \n",
      "0              3.142613  \n",
      "Creating new feature from D15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.60      0.74     56945\n",
      "           1       0.06      0.71      0.11      2109\n",
      "\n",
      "    accuracy                           0.60     59054\n",
      "   macro avg       0.52      0.65      0.43     59054\n",
      "weighted avg       0.95      0.60      0.72     59054\n",
      "\n",
      "printing df_scores...\n",
      "     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
      "551          D3  0.719298   0.061390  592  23194  33751  1517   \n",
      "552          D4  0.683736   0.068507  667  19607  37338  1442   \n",
      "553         D10  0.728781   0.060579  572  23835  33110  1537   \n",
      "554         D11  0.700332   0.062077  632  22316  34629  1477   \n",
      "0           D15  0.710289   0.061573  611  22831  34114  1498   \n",
      "\n",
      "     time_elapsed (min)  \n",
      "551            1.187169  \n",
      "552            2.951713  \n",
      "553            4.441769  \n",
      "554            3.142613  \n",
      "0              3.267297  \n"
     ]
    }
   ],
   "source": [
    "class Model():\n",
    "    def __init__(self, bool_smote):\n",
    "#         X_train, self.X_test, y_train, self.y_test = self._create_dataframe(df_features)\n",
    "#         self.X_train, self.y_train = self._apply_smote(bool_smote, X_train, y_train)\n",
    "        self.col_fe = []\n",
    "        \n",
    "    def _create_dataframe(self, df_feat):\n",
    "        '''create and splitting dataframe'''\n",
    "        X = df_feat.drop(col_target, axis=1)\n",
    "        X = X.drop(col_id, axis=1)\n",
    "        y = df_feat[col_target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.1, \n",
    "                                                            random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def feature_testing(self, list_feat):\n",
    "        '''testing and scoring new potential features'''\n",
    "        if list_feat:\n",
    "            for col in list_feat:\n",
    "                self.col_fe = col\n",
    "                if col in df_features.columns:\n",
    "                    df_feat = fe.create_feature(col)\n",
    "#                     df_feat = df_feat[0:1000] ### DELETE\n",
    "                    X_train, X_test, y_train, y_test = self._create_dataframe(df_feat) \n",
    "                    X_train, y_train = self._apply_smote(True, X_train, y_train)\n",
    "                    model = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "                    self.add_model(model, X_train, y_train, X_test, y_test) # also handles scoring\n",
    "                else:\n",
    "                    print(\"\\nColumn\", col,\"does not exist in dataframe.\\n\")\n",
    "            self.col_fe = []\n",
    "\n",
    "    def _apply_smote(self, bool_smote, X_train, y_train):\n",
    "        '''applying smote to split training set'''\n",
    "        if bool_smote:\n",
    "            sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "            X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "            return X_train_res, y_train_res\n",
    "        else:\n",
    "            return X_train, y_train\n",
    "        \n",
    "    def add_model(self, temp_model, X_train, y_train, X_test, y_test):        \n",
    "        '''adding and scoring model'''\n",
    "        model = temp_model\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        self._score_model(y_pred, y_test, elapsed_time)\n",
    "        \n",
    "    def _score_model(self, y_pred, y_test, elapsed_time):      \n",
    "        '''creating dataframe with score results'''\n",
    "        col_recall = pd.Series(recall_score(y_test, y_pred), name='recall')\n",
    "        col_precision = pd.Series(precision_score(y_test, y_pred), name='precision')\n",
    "        col_time = pd.Series(elapsed_time, name='time_elapsed (min)')\n",
    "        df_conf_matrix = self._confusion_matrix(y_test, y_pred)\n",
    "        df_temp = pd.concat([col_recall, col_precision, df_conf_matrix, col_time], axis=1)\n",
    "        \n",
    "        if self.col_fe:\n",
    "            print(\"Creating new feature from\", self.col_fe)\n",
    "            col_fe = pd.Series(self.col_fe, name='feat_tested')\n",
    "            df_temp = pd.concat([col_fe, df_temp], axis=1)\n",
    "            \n",
    "        df_scores = self._read_create_file(df_temp)\n",
    "        self._save_results(df_scores, df_temp, y_test, y_pred)\n",
    "        \n",
    "    def _read_create_file(self, df_temp):\n",
    "        '''reading or creating df_scores file'''\n",
    "        try: \n",
    "            df_scores = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "            df_scores = df_scores.drop('Unnamed: 0', axis=1)\n",
    "        except:\n",
    "            print(\"\\nCreating df_scores.csv file.\") \n",
    "            df_scores = df_temp\n",
    "        return df_scores\n",
    "            \n",
    "    def _save_results(self, df_scores, df_temp, y_test, y_pred):\n",
    "        '''printing scores for new features'''            \n",
    "        df_scores = pd.concat([df_scores, df_temp], axis=0)\n",
    "        df_scores.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "        classif_report = classification_report(y_test, y_pred)\n",
    "        print(classif_report)\n",
    "        print('printing df_scores...\\n', df_scores.tail(5))\n",
    "        file_summary = open('/Users/krahman/work/fraud_detection/saved_files/df_scores_summary.txt', \"r+\")\n",
    "        file_summary.write(self.col_fe)\n",
    "        file_summary.write(classif_report)\n",
    "        file_summary.close()\n",
    "        \n",
    "    def _confusion_matrix(self, y_test, y_pred):\n",
    "        '''creating confusion matrix dataframe'''\n",
    "        df_conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "        val_tp = pd.Series(df_conf_matrix[0][0], name='tp')\n",
    "        val_fn = pd.Series(df_conf_matrix[0][1], name='fn')\n",
    "        val_fp = pd.Series(df_conf_matrix[1][0], name='fp')\n",
    "        val_tn = pd.Series(df_conf_matrix[1][1], name='tn')\n",
    "        return pd.concat([val_fn, val_fp, val_tp, val_tn], axis=1)\n",
    "        \n",
    "model = Model(bool_smote=True)      \n",
    "# model.add_model(LogisticRegression(random_state=42, n_jobs=-1))\n",
    "# model.feature_testing(list_feat=['addr1', 'addr2,', 'card2'])\n",
    "\n",
    "# model.feature_testing(list_feat=['addr1', 'addr2', 'card1', 'card2', 'card3', 'card5',\n",
    "#  'card2', 'C4', 'C1', 'V317', 'ProductCD', 'V294', 'V279', 'C14', 'card6', 'V306', 'V69', 'D1','D2',\n",
    "#  'D3','D4','D10','D11','D15'])\n",
    "\n",
    "\n",
    "\n",
    "model.feature_testing(list_feat=['card2', 'C4', 'C1', 'V317', 'V294', 'V279', \n",
    "                        'C14', 'card6', 'V306', 'V69', 'D1','D2', 'D3','D4','D10','D11','D15'])\n",
    "# GOOD FEATURES: ['addr1', 'card2', 'card3', 'card5', 'C1', 'V317', \n",
    "#                 'V279', 'V294', 'C14', 'V306', 'D2', 'D3', 'D10']\n",
    "                                 \n",
    "#  list_feat = ['days_7',\n",
    "#  'time_days_7','time_days_14','time_days_21','time_days_30','time_days_45','time_days_60','time_days_90',\n",
    "#  'time_days_12','minutes_lapsed','hours_lapsed','seconds_lapsed', 'p_email_domain_copy', 'ProductCD']\n",
    "\n",
    "\n",
    "# there after, we can decide on our feature set and move on with the project. We need to add SVM and DT in our\n",
    "# model class. Then we need to tune the models. we need to create features for this. \n",
    "\n",
    "# NEXT, run all features, then test to see what happens if we don't drop the column paired with each new feature\n",
    "# then create method that creates time lapsed methods... we also need to test without dropping columns...\n",
    "\n",
    "# we still need to test these 'ProductCD', 'card6', 'P_emaildomain_copy'\n",
    "\n",
    "# NEXT, review the results of not dropping. \n",
    "# some of these columms should not be dropped... Most of them should not be dropped..\n",
    "# we need to test without dropping.. but we keep getting the same score. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_fe = df_features[['TransactionDT']].copy()\n",
    "df_temp_fe['time_delta'] = 0\n",
    "len_df_temp_fe = df_temp_fe.shape[0]\n",
    "\n",
    "for i in range(1,len(df_temp_fe['TransactionDT'][0:len_df_temp_fe])):\n",
    "    val_time_1 = df_temp_fe.loc[i - 1, 'TransactionDT']\n",
    "    val_time_2 = df_temp_fe.loc[i, 'TransactionDT']\n",
    "    val_time_delta = val_time_2 - val_time_1\n",
    "    df_temp_fe.loc[i, 'time_delta'] = val_time_delta\n",
    "\n",
    "df_temp_fe['days_lapsed_7'] = df_temp_fe['time_delta']/7\n",
    "df_temp_fe['days_lapsed_14'] = df_temp_fe['time_delta']/14\n",
    "df_temp_fe['days_lapsed_21'] = df_temp_fe['time_delta']/21\n",
    "df_temp_fe['days_lapsed_30'] = df_temp_fe['time_delta']/30\n",
    "df_temp_fe['days_lapsed_45'] = df_temp_fe['time_delta']/45\n",
    "df_temp_fe['days_lapsed_60'] = df_temp_fe['time_delta']/60\n",
    "df_temp_fe['days_lapsed_90'] = df_temp_fe['time_delta']/90\n",
    "df_temp_fe['days_lapsed_365'] = df_temp_fe['time_delta']/365\n",
    "\n",
    "# we need to test these additional columns...\n",
    "df_temp_fe['s_minutes_lapsed'] = df_temp_fe['time_delta']/60 # minutes\n",
    "df_temp_fe['s_hours_lapsed'] = df_temp_fe['time_delta']/3600 # hours\n",
    "df_temp_fe['s_days_lapsed_1'] = df_temp_fe['time_delta']/86400\n",
    "df_temp_fe['s_days_lapsed_7'] = df_temp_fe['time_delta']/604800\n",
    "df_temp_fe['s_days_lapsed_14'] = df_temp_fe['time_delta']/1209600\n",
    "df_temp_fe['s_days_lapsed_30'] = df_temp_fe['time_delta']/2592000\n",
    "df_temp_fe['s_days_lapsed_90'] = df_temp_fe['time_delta']/7776000\n",
    "df_temp_fe['s_days_lapsed_180'] = df_temp_fe['time_delta']/15552000\n",
    "\n",
    "df_temp_fe = df_temp_fe.drop(['TransactionDT', 'time_delta'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_temp_fe.columns:\n",
    "    df_temp_fe2 = pd.concat([df_features,df_temp_fe[col]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>card4_visa</th>\n",
       "      <th>card6_credit</th>\n",
       "      <th>card6_debit</th>\n",
       "      <th>card6_debit or credit</th>\n",
       "      <th>M1_T</th>\n",
       "      <th>M2_T</th>\n",
       "      <th>M3_T</th>\n",
       "      <th>M4_M1</th>\n",
       "      <th>M4_M2</th>\n",
       "      <th>M6_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>3417</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>166</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>7922</td>\n",
       "      <td>303</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>9383</td>\n",
       "      <td>389</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "      <td>178</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>6991</td>\n",
       "      <td>466</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>282</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>9262</td>\n",
       "      <td>413</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>241</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>3577535</td>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>10855</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>108</td>\n",
       "      <td>132</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590536</td>\n",
       "      <td>3577536</td>\n",
       "      <td>0</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>390</td>\n",
       "      <td>124</td>\n",
       "      <td>42</td>\n",
       "      <td>106</td>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590537</td>\n",
       "      <td>3577537</td>\n",
       "      <td>0</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>1782</td>\n",
       "      <td>494</td>\n",
       "      <td>42</td>\n",
       "      <td>106</td>\n",
       "      <td>98</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590538</td>\n",
       "      <td>3577538</td>\n",
       "      <td>0</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>11847</td>\n",
       "      <td>380</td>\n",
       "      <td>42</td>\n",
       "      <td>106</td>\n",
       "      <td>219</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590539</td>\n",
       "      <td>3577539</td>\n",
       "      <td>0</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>4361</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt  card1  card2  \\\n",
       "0             2987000        0          86400           68.50   3417    500   \n",
       "1             2987001        0          86401           29.00   7922    303   \n",
       "2             2987002        0          86469           59.00   9383    389   \n",
       "3             2987003        0          86499           50.00   6991    466   \n",
       "4             2987004        0          86506           50.00   9262    413   \n",
       "...               ...      ...            ...             ...    ...    ...   \n",
       "590535        3577535        0       15811047           49.00  10855    500   \n",
       "590536        3577536        0       15811049           39.50    390    124   \n",
       "590537        3577537        0       15811079           30.95   1782    494   \n",
       "590538        3577538        0       15811088          117.00  11847    380   \n",
       "590539        3577539        0       15811131          279.95   4361     69   \n",
       "\n",
       "        card3  card5  addr1  addr2  ...  card4_visa  card6_credit  \\\n",
       "0          42     38    166     65  ...           0             1   \n",
       "1          42      2    173     65  ...           0             1   \n",
       "2          42     58    178     65  ...           1             0   \n",
       "3          42     14    282     65  ...           0             0   \n",
       "4          42      2    241     65  ...           0             1   \n",
       "...       ...    ...    ...    ...  ...         ...           ...   \n",
       "590535     42    108    132     65  ...           1             0   \n",
       "590536     42    106     78     65  ...           0             0   \n",
       "590537     42    106     98     65  ...           0             0   \n",
       "590538     42    106    219     65  ...           0             0   \n",
       "590539     42      2    151     65  ...           0             1   \n",
       "\n",
       "        card6_debit  card6_debit or credit  M1_T  M2_T  M3_T  M4_M1  M4_M2  \\\n",
       "0                 0                      0     1     1     1      0      1   \n",
       "1                 0                      0     1     1     1      0      0   \n",
       "2                 1                      0     1     1     1      0      0   \n",
       "3                 1                      0     1     1     1      0      0   \n",
       "4                 0                      0     1     1     1      0      0   \n",
       "...             ...                    ...   ...   ...   ...    ...    ...   \n",
       "590535            1                      0     1     1     1      0      0   \n",
       "590536            1                      0     1     0     0      0      0   \n",
       "590537            1                      0     1     0     0      0      0   \n",
       "590538            1                      0     1     1     1      0      0   \n",
       "590539            0                      0     1     0     0      0      0   \n",
       "\n",
       "        M6_T  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "590535     0  \n",
       "590536     1  \n",
       "590537     1  \n",
       "590538     1  \n",
       "590539     1  \n",
       "\n",
       "[590540 rows x 285 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = df_features.drop(['days_7', 'time_days_7', 'time_days_14', 'time_days_21', 'time_days_30', 'time_days_45', 'time_days_60', 'time_days_90', 'time_days_12', 'minutes_lapsed', 'hours_lapsed', 'seconds_lapsed'],axis=1)\n",
    "# print(list(df_features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feat_tested</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>time_elapsed (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>520</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>521</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>523</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>527</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>529</td>\n",
       "      <td>529</td>\n",
       "      <td>card5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533</td>\n",
       "      <td>533</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.829303</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>360</td>\n",
       "      <td>30387</td>\n",
       "      <td>26558</td>\n",
       "      <td>1749</td>\n",
       "      <td>5.365285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.712660</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>606</td>\n",
       "      <td>22920</td>\n",
       "      <td>34025</td>\n",
       "      <td>1503</td>\n",
       "      <td>2.486481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>608</td>\n",
       "      <td>16343</td>\n",
       "      <td>40602</td>\n",
       "      <td>1501</td>\n",
       "      <td>3.294828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>537</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.720247</td>\n",
       "      <td>0.070052</td>\n",
       "      <td>590</td>\n",
       "      <td>20165</td>\n",
       "      <td>36780</td>\n",
       "      <td>1519</td>\n",
       "      <td>3.457456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.060043</td>\n",
       "      <td>551</td>\n",
       "      <td>24390</td>\n",
       "      <td>32555</td>\n",
       "      <td>1558</td>\n",
       "      <td>3.500424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539</td>\n",
       "      <td>539</td>\n",
       "      <td>card5</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>551</td>\n",
       "      <td>24698</td>\n",
       "      <td>32247</td>\n",
       "      <td>1558</td>\n",
       "      <td>3.619894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.720247</td>\n",
       "      <td>0.070052</td>\n",
       "      <td>590</td>\n",
       "      <td>20165</td>\n",
       "      <td>36780</td>\n",
       "      <td>1519</td>\n",
       "      <td>4.987315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>C4</td>\n",
       "      <td>0.673779</td>\n",
       "      <td>0.069732</td>\n",
       "      <td>688</td>\n",
       "      <td>18957</td>\n",
       "      <td>37988</td>\n",
       "      <td>1421</td>\n",
       "      <td>3.560533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.738265</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>552</td>\n",
       "      <td>24037</td>\n",
       "      <td>32908</td>\n",
       "      <td>1557</td>\n",
       "      <td>3.325386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543</td>\n",
       "      <td>543</td>\n",
       "      <td>V317</td>\n",
       "      <td>0.729256</td>\n",
       "      <td>0.062325</td>\n",
       "      <td>571</td>\n",
       "      <td>23139</td>\n",
       "      <td>33806</td>\n",
       "      <td>1538</td>\n",
       "      <td>3.473626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>544</td>\n",
       "      <td>V294</td>\n",
       "      <td>0.717402</td>\n",
       "      <td>0.061223</td>\n",
       "      <td>596</td>\n",
       "      <td>23200</td>\n",
       "      <td>33745</td>\n",
       "      <td>1513</td>\n",
       "      <td>3.329275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>V279</td>\n",
       "      <td>0.732101</td>\n",
       "      <td>0.058992</td>\n",
       "      <td>565</td>\n",
       "      <td>24629</td>\n",
       "      <td>32316</td>\n",
       "      <td>1544</td>\n",
       "      <td>1.150144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>C14</td>\n",
       "      <td>0.757705</td>\n",
       "      <td>0.059956</td>\n",
       "      <td>511</td>\n",
       "      <td>25055</td>\n",
       "      <td>31890</td>\n",
       "      <td>1598</td>\n",
       "      <td>2.036437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>547</td>\n",
       "      <td>V306</td>\n",
       "      <td>0.732575</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>564</td>\n",
       "      <td>23486</td>\n",
       "      <td>33459</td>\n",
       "      <td>1545</td>\n",
       "      <td>3.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>V69</td>\n",
       "      <td>0.712186</td>\n",
       "      <td>0.061785</td>\n",
       "      <td>607</td>\n",
       "      <td>22808</td>\n",
       "      <td>34137</td>\n",
       "      <td>1502</td>\n",
       "      <td>3.744155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.709341</td>\n",
       "      <td>0.062113</td>\n",
       "      <td>613</td>\n",
       "      <td>22589</td>\n",
       "      <td>34356</td>\n",
       "      <td>1496</td>\n",
       "      <td>3.203725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.750119</td>\n",
       "      <td>0.059384</td>\n",
       "      <td>527</td>\n",
       "      <td>25058</td>\n",
       "      <td>31887</td>\n",
       "      <td>1582</td>\n",
       "      <td>3.429228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "      <td>D3</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>592</td>\n",
       "      <td>23194</td>\n",
       "      <td>33751</td>\n",
       "      <td>1517</td>\n",
       "      <td>1.187169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>D4</td>\n",
       "      <td>0.683736</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>667</td>\n",
       "      <td>19607</td>\n",
       "      <td>37338</td>\n",
       "      <td>1442</td>\n",
       "      <td>2.951713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>553</td>\n",
       "      <td>D10</td>\n",
       "      <td>0.728781</td>\n",
       "      <td>0.060579</td>\n",
       "      <td>572</td>\n",
       "      <td>23835</td>\n",
       "      <td>33110</td>\n",
       "      <td>1537</td>\n",
       "      <td>4.441769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>D11</td>\n",
       "      <td>0.700332</td>\n",
       "      <td>0.062077</td>\n",
       "      <td>632</td>\n",
       "      <td>22316</td>\n",
       "      <td>34629</td>\n",
       "      <td>1477</td>\n",
       "      <td>3.142613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>D15</td>\n",
       "      <td>0.710289</td>\n",
       "      <td>0.061573</td>\n",
       "      <td>611</td>\n",
       "      <td>22831</td>\n",
       "      <td>34114</td>\n",
       "      <td>1498</td>\n",
       "      <td>3.267297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
       "516         516       addr2  0.000000   0.000000    0     13     87     0   \n",
       "517         517       card1  0.000000   0.000000    0     13     87     0   \n",
       "518         518       card2  0.000000   0.000000    0     13     87     0   \n",
       "519         519       card3  0.000000   0.000000    0     13     87     0   \n",
       "520         520       addr1  0.000000   0.000000    0     12     88     0   \n",
       "521         521       addr2  0.000000   0.000000    0     11     89     0   \n",
       "522         522       addr1  0.000000   0.000000    0     12     88     0   \n",
       "523         523       addr2  0.000000   0.000000    0     11     89     0   \n",
       "524         524       addr1  0.000000   0.000000    0     11     89     0   \n",
       "525         525       addr2  0.000000   0.000000    0     15     85     0   \n",
       "526         526       card1  0.000000   0.000000    0      8     92     0   \n",
       "527         527       card2  0.000000   0.000000    0      9     91     0   \n",
       "528         528       card3  0.000000   0.000000    0     13     87     0   \n",
       "529         529       card5  0.000000   0.000000    0     10     90     0   \n",
       "530         530       addr1  0.000000   0.000000    0      9     91     0   \n",
       "531         531       addr2  0.000000   0.000000    0     12     88     0   \n",
       "532         532       addr1  0.000000   0.000000    0      9     91     0   \n",
       "533         533       addr2  0.000000   0.000000    0     12     88     0   \n",
       "534         534       addr1  0.829303   0.054425  360  30387  26558  1749   \n",
       "535         535       addr2  0.712660   0.061540  606  22920  34025  1503   \n",
       "536         536       card1  0.711712   0.084118  608  16343  40602  1501   \n",
       "537         537       card2  0.720247   0.070052  590  20165  36780  1519   \n",
       "538         538       card3  0.738739   0.060043  551  24390  32555  1558   \n",
       "539         539       card5  0.738739   0.059339  551  24698  32247  1558   \n",
       "540         540       card2  0.720247   0.070052  590  20165  36780  1519   \n",
       "541         541          C4  0.673779   0.069732  688  18957  37988  1421   \n",
       "542         542          C1  0.738265   0.060835  552  24037  32908  1557   \n",
       "543         543        V317  0.729256   0.062325  571  23139  33806  1538   \n",
       "544         544        V294  0.717402   0.061223  596  23200  33745  1513   \n",
       "545         545        V279  0.732101   0.058992  565  24629  32316  1544   \n",
       "546         546         C14  0.757705   0.059956  511  25055  31890  1598   \n",
       "547         547        V306  0.732575   0.061723  564  23486  33459  1545   \n",
       "548         548         V69  0.712186   0.061785  607  22808  34137  1502   \n",
       "549         549          D1  0.709341   0.062113  613  22589  34356  1496   \n",
       "550         550          D2  0.750119   0.059384  527  25058  31887  1582   \n",
       "551         551          D3  0.719298   0.061390  592  23194  33751  1517   \n",
       "552         552          D4  0.683736   0.068507  667  19607  37338  1442   \n",
       "553         553         D10  0.728781   0.060579  572  23835  33110  1537   \n",
       "554         554         D11  0.700332   0.062077  632  22316  34629  1477   \n",
       "555           0         D15  0.710289   0.061573  611  22831  34114  1498   \n",
       "\n",
       "     time_elapsed (min)  \n",
       "516            0.008696  \n",
       "517            0.008569  \n",
       "518            0.008856  \n",
       "519            0.014285  \n",
       "520            0.008619  \n",
       "521            0.008338  \n",
       "522            0.014601  \n",
       "523            0.009156  \n",
       "524            0.008065  \n",
       "525            0.013202  \n",
       "526            0.009618  \n",
       "527            0.010425  \n",
       "528            0.010262  \n",
       "529            0.009558  \n",
       "530            0.012434  \n",
       "531            0.017342  \n",
       "532            0.019874  \n",
       "533            0.014937  \n",
       "534            5.365285  \n",
       "535            2.486481  \n",
       "536            3.294828  \n",
       "537            3.457456  \n",
       "538            3.500424  \n",
       "539            3.619894  \n",
       "540            4.987315  \n",
       "541            3.560533  \n",
       "542            3.325386  \n",
       "543            3.473626  \n",
       "544            3.329275  \n",
       "545            1.150144  \n",
       "546            2.036437  \n",
       "547            3.428800  \n",
       "548            3.744155  \n",
       "549            3.203725  \n",
       "550            3.429228  \n",
       "551            1.187169  \n",
       "552            2.951713  \n",
       "553            4.441769  \n",
       "554            3.142613  \n",
       "555            3.267297  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_read = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "df_temp_read[len(df_temp_read)-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feat_tested</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>time_elapsed (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.824087</td>\n",
       "      <td>0.055005</td>\n",
       "      <td>371</td>\n",
       "      <td>29859</td>\n",
       "      <td>27086</td>\n",
       "      <td>1738</td>\n",
       "      <td>2.093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.060584</td>\n",
       "      <td>589</td>\n",
       "      <td>23569</td>\n",
       "      <td>33376</td>\n",
       "      <td>1520</td>\n",
       "      <td>2.786479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>608</td>\n",
       "      <td>16343</td>\n",
       "      <td>40602</td>\n",
       "      <td>1501</td>\n",
       "      <td>2.437131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.749170</td>\n",
       "      <td>0.060321</td>\n",
       "      <td>529</td>\n",
       "      <td>24613</td>\n",
       "      <td>32332</td>\n",
       "      <td>1580</td>\n",
       "      <td>3.112451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.060043</td>\n",
       "      <td>551</td>\n",
       "      <td>24390</td>\n",
       "      <td>32555</td>\n",
       "      <td>1558</td>\n",
       "      <td>2.850517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>card5</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>551</td>\n",
       "      <td>24698</td>\n",
       "      <td>32247</td>\n",
       "      <td>1558</td>\n",
       "      <td>2.149401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>addr1</td>\n",
       "      <td>0.829303</td>\n",
       "      <td>0.054369</td>\n",
       "      <td>360</td>\n",
       "      <td>30420</td>\n",
       "      <td>26525</td>\n",
       "      <td>1749</td>\n",
       "      <td>4.120784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>addr2</td>\n",
       "      <td>0.692271</td>\n",
       "      <td>0.066697</td>\n",
       "      <td>649</td>\n",
       "      <td>20430</td>\n",
       "      <td>36515</td>\n",
       "      <td>1460</td>\n",
       "      <td>3.072066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>card1</td>\n",
       "      <td>0.738265</td>\n",
       "      <td>0.059543</td>\n",
       "      <td>552</td>\n",
       "      <td>24592</td>\n",
       "      <td>32353</td>\n",
       "      <td>1557</td>\n",
       "      <td>3.182654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.730204</td>\n",
       "      <td>0.062014</td>\n",
       "      <td>569</td>\n",
       "      <td>23293</td>\n",
       "      <td>33652</td>\n",
       "      <td>1540</td>\n",
       "      <td>2.796247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>card3</td>\n",
       "      <td>0.748222</td>\n",
       "      <td>0.059782</td>\n",
       "      <td>531</td>\n",
       "      <td>24818</td>\n",
       "      <td>32127</td>\n",
       "      <td>1578</td>\n",
       "      <td>2.825807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>card5</td>\n",
       "      <td>0.733997</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>561</td>\n",
       "      <td>24430</td>\n",
       "      <td>32515</td>\n",
       "      <td>1548</td>\n",
       "      <td>2.867370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>card2</td>\n",
       "      <td>0.730204</td>\n",
       "      <td>0.062014</td>\n",
       "      <td>569</td>\n",
       "      <td>23293</td>\n",
       "      <td>33652</td>\n",
       "      <td>1540</td>\n",
       "      <td>2.423249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>C4</td>\n",
       "      <td>0.737790</td>\n",
       "      <td>0.060273</td>\n",
       "      <td>553</td>\n",
       "      <td>24260</td>\n",
       "      <td>32685</td>\n",
       "      <td>1556</td>\n",
       "      <td>3.114199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.755334</td>\n",
       "      <td>0.059367</td>\n",
       "      <td>516</td>\n",
       "      <td>25240</td>\n",
       "      <td>31705</td>\n",
       "      <td>1593</td>\n",
       "      <td>5.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>V317</td>\n",
       "      <td>0.739213</td>\n",
       "      <td>0.059987</td>\n",
       "      <td>550</td>\n",
       "      <td>24430</td>\n",
       "      <td>32515</td>\n",
       "      <td>1559</td>\n",
       "      <td>4.039214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>V294</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.060869</td>\n",
       "      <td>570</td>\n",
       "      <td>23745</td>\n",
       "      <td>33200</td>\n",
       "      <td>1539</td>\n",
       "      <td>4.619494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>V279</td>\n",
       "      <td>0.722143</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>586</td>\n",
       "      <td>23438</td>\n",
       "      <td>33507</td>\n",
       "      <td>1523</td>\n",
       "      <td>3.088019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>C14</td>\n",
       "      <td>0.722617</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>585</td>\n",
       "      <td>23699</td>\n",
       "      <td>33246</td>\n",
       "      <td>1524</td>\n",
       "      <td>3.543967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>V306</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.059468</td>\n",
       "      <td>525</td>\n",
       "      <td>25052</td>\n",
       "      <td>31893</td>\n",
       "      <td>1584</td>\n",
       "      <td>2.789090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>V69</td>\n",
       "      <td>0.737790</td>\n",
       "      <td>0.060249</td>\n",
       "      <td>553</td>\n",
       "      <td>24270</td>\n",
       "      <td>32675</td>\n",
       "      <td>1556</td>\n",
       "      <td>3.103081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.712660</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>606</td>\n",
       "      <td>22490</td>\n",
       "      <td>34455</td>\n",
       "      <td>1503</td>\n",
       "      <td>3.414212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.747274</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>533</td>\n",
       "      <td>25041</td>\n",
       "      <td>31904</td>\n",
       "      <td>1576</td>\n",
       "      <td>3.809483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>D3</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>0.060429</td>\n",
       "      <td>568</td>\n",
       "      <td>23960</td>\n",
       "      <td>32985</td>\n",
       "      <td>1541</td>\n",
       "      <td>3.635742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>D4</td>\n",
       "      <td>0.703177</td>\n",
       "      <td>0.064610</td>\n",
       "      <td>626</td>\n",
       "      <td>21470</td>\n",
       "      <td>35475</td>\n",
       "      <td>1483</td>\n",
       "      <td>2.233171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>D10</td>\n",
       "      <td>0.733049</td>\n",
       "      <td>0.060123</td>\n",
       "      <td>563</td>\n",
       "      <td>24168</td>\n",
       "      <td>32777</td>\n",
       "      <td>1546</td>\n",
       "      <td>4.159321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>D11</td>\n",
       "      <td>0.721669</td>\n",
       "      <td>0.060021</td>\n",
       "      <td>587</td>\n",
       "      <td>23836</td>\n",
       "      <td>33109</td>\n",
       "      <td>1522</td>\n",
       "      <td>2.682218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>D15</td>\n",
       "      <td>0.713134</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>605</td>\n",
       "      <td>22898</td>\n",
       "      <td>34047</td>\n",
       "      <td>1504</td>\n",
       "      <td>3.480535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>days_7</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>608</td>\n",
       "      <td>22685</td>\n",
       "      <td>34260</td>\n",
       "      <td>1501</td>\n",
       "      <td>2.835668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>time_days_7</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>608</td>\n",
       "      <td>22685</td>\n",
       "      <td>34260</td>\n",
       "      <td>1501</td>\n",
       "      <td>2.702341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>time_days_14</td>\n",
       "      <td>0.724514</td>\n",
       "      <td>0.060436</td>\n",
       "      <td>581</td>\n",
       "      <td>23755</td>\n",
       "      <td>33190</td>\n",
       "      <td>1528</td>\n",
       "      <td>2.902399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>time_days_21</td>\n",
       "      <td>0.715505</td>\n",
       "      <td>0.061509</td>\n",
       "      <td>600</td>\n",
       "      <td>23024</td>\n",
       "      <td>33921</td>\n",
       "      <td>1509</td>\n",
       "      <td>2.779859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>time_days_30</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.059486</td>\n",
       "      <td>525</td>\n",
       "      <td>25044</td>\n",
       "      <td>31901</td>\n",
       "      <td>1584</td>\n",
       "      <td>2.755484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>time_days_45</td>\n",
       "      <td>0.719772</td>\n",
       "      <td>0.061141</td>\n",
       "      <td>591</td>\n",
       "      <td>23310</td>\n",
       "      <td>33635</td>\n",
       "      <td>1518</td>\n",
       "      <td>2.186103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>time_days_60</td>\n",
       "      <td>0.755334</td>\n",
       "      <td>0.059363</td>\n",
       "      <td>516</td>\n",
       "      <td>25242</td>\n",
       "      <td>31703</td>\n",
       "      <td>1593</td>\n",
       "      <td>2.130250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>time_days_90</td>\n",
       "      <td>0.729256</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>571</td>\n",
       "      <td>23836</td>\n",
       "      <td>33109</td>\n",
       "      <td>1538</td>\n",
       "      <td>4.247158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>time_days_12</td>\n",
       "      <td>0.743480</td>\n",
       "      <td>0.059509</td>\n",
       "      <td>541</td>\n",
       "      <td>24781</td>\n",
       "      <td>32164</td>\n",
       "      <td>1568</td>\n",
       "      <td>3.261772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>minutes_lapsed</td>\n",
       "      <td>0.740635</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>547</td>\n",
       "      <td>24713</td>\n",
       "      <td>32232</td>\n",
       "      <td>1562</td>\n",
       "      <td>1.725005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>hours_lapsed</td>\n",
       "      <td>0.735894</td>\n",
       "      <td>0.060220</td>\n",
       "      <td>557</td>\n",
       "      <td>24220</td>\n",
       "      <td>32725</td>\n",
       "      <td>1552</td>\n",
       "      <td>2.276066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>seconds_lapsed</td>\n",
       "      <td>0.718824</td>\n",
       "      <td>0.061603</td>\n",
       "      <td>593</td>\n",
       "      <td>23093</td>\n",
       "      <td>33852</td>\n",
       "      <td>1516</td>\n",
       "      <td>3.340665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     feat_tested    recall  precision   fn     fp     tp    tn  \\\n",
       "0            0           addr1  0.824087   0.055005  371  29859  27086  1738   \n",
       "1            1           addr2  0.720721   0.060584  589  23569  33376  1520   \n",
       "2            2           card1  0.711712   0.084118  608  16343  40602  1501   \n",
       "3            3           card2  0.749170   0.060321  529  24613  32332  1580   \n",
       "4            4           card3  0.738739   0.060043  551  24390  32555  1558   \n",
       "5            5           card5  0.738739   0.059339  551  24698  32247  1558   \n",
       "6            6           addr1  0.000000   0.000000    0      7     93     0   \n",
       "7            7           addr1  0.000000   0.000000    0      7     93     0   \n",
       "8            8           addr1  0.000000   0.000000    0      7     93     0   \n",
       "9            9           addr1  0.000000   0.000000    0     12     88     0   \n",
       "10          10           addr2  0.000000   0.000000    0     10     90     0   \n",
       "11          11           card1  0.000000   0.000000    0      9     91     0   \n",
       "12          12           card2  0.000000   0.000000    0      7     93     0   \n",
       "13          13           card3  0.000000   0.000000    0     12     88     0   \n",
       "14          14           addr1  0.829303   0.054369  360  30420  26525  1749   \n",
       "15          15           addr2  0.692271   0.066697  649  20430  36515  1460   \n",
       "16          16           card1  0.738265   0.059543  552  24592  32353  1557   \n",
       "17          17           card2  0.730204   0.062014  569  23293  33652  1540   \n",
       "18          18           card3  0.748222   0.059782  531  24818  32127  1578   \n",
       "19          19           card5  0.733997   0.059589  561  24430  32515  1548   \n",
       "20          20           card2  0.730204   0.062014  569  23293  33652  1540   \n",
       "21          21              C4  0.737790   0.060273  553  24260  32685  1556   \n",
       "22          22              C1  0.755334   0.059367  516  25240  31705  1593   \n",
       "23          23            V317  0.739213   0.059987  550  24430  32515  1559   \n",
       "24          24            V294  0.729730   0.060869  570  23745  33200  1539   \n",
       "25          25            V279  0.722143   0.061015  586  23438  33507  1523   \n",
       "26          26             C14  0.722617   0.060421  585  23699  33246  1524   \n",
       "27          27            V306  0.751067   0.059468  525  25052  31893  1584   \n",
       "28          28             V69  0.737790   0.060249  553  24270  32675  1556   \n",
       "29          29              D1  0.712660   0.062643  606  22490  34455  1503   \n",
       "30          30              D2  0.747274   0.059210  533  25041  31904  1576   \n",
       "31          31              D3  0.730678   0.060429  568  23960  32985  1541   \n",
       "32          32              D4  0.703177   0.064610  626  21470  35475  1483   \n",
       "33          33             D10  0.733049   0.060123  563  24168  32777  1546   \n",
       "34          34             D11  0.721669   0.060021  587  23836  33109  1522   \n",
       "35          35             D15  0.713134   0.061634  605  22898  34047  1504   \n",
       "36          36          days_7  0.711712   0.062061  608  22685  34260  1501   \n",
       "37          37     time_days_7  0.711712   0.062061  608  22685  34260  1501   \n",
       "38          38    time_days_14  0.724514   0.060436  581  23755  33190  1528   \n",
       "39          39    time_days_21  0.715505   0.061509  600  23024  33921  1509   \n",
       "40          40    time_days_30  0.751067   0.059486  525  25044  31901  1584   \n",
       "41          41    time_days_45  0.719772   0.061141  591  23310  33635  1518   \n",
       "42          42    time_days_60  0.755334   0.059363  516  25242  31703  1593   \n",
       "43          43    time_days_90  0.729256   0.060613  571  23836  33109  1538   \n",
       "44          44    time_days_12  0.743480   0.059509  541  24781  32164  1568   \n",
       "45          45  minutes_lapsed  0.740635   0.059448  547  24713  32232  1562   \n",
       "46          46    hours_lapsed  0.735894   0.060220  557  24220  32725  1552   \n",
       "47           0  seconds_lapsed  0.718824   0.061603  593  23093  33852  1516   \n",
       "\n",
       "    time_elapsed (min)  \n",
       "0             2.093689  \n",
       "1             2.786479  \n",
       "2             2.437131  \n",
       "3             3.112451  \n",
       "4             2.850517  \n",
       "5             2.149401  \n",
       "6             0.008121  \n",
       "7             0.007413  \n",
       "8             0.010607  \n",
       "9             0.018702  \n",
       "10            0.010056  \n",
       "11            0.012550  \n",
       "12            0.010178  \n",
       "13            0.013545  \n",
       "14            4.120784  \n",
       "15            3.072066  \n",
       "16            3.182654  \n",
       "17            2.796247  \n",
       "18            2.825807  \n",
       "19            2.867370  \n",
       "20            2.423249  \n",
       "21            3.114199  \n",
       "22            5.098421  \n",
       "23            4.039214  \n",
       "24            4.619494  \n",
       "25            3.088019  \n",
       "26            3.543967  \n",
       "27            2.789090  \n",
       "28            3.103081  \n",
       "29            3.414212  \n",
       "30            3.809483  \n",
       "31            3.635742  \n",
       "32            2.233171  \n",
       "33            4.159321  \n",
       "34            2.682218  \n",
       "35            3.480535  \n",
       "36            2.835668  \n",
       "37            2.702341  \n",
       "38            2.902399  \n",
       "39            2.779859  \n",
       "40            2.755484  \n",
       "41            2.186103  \n",
       "42            2.130250  \n",
       "43            4.247158  \n",
       "44            3.261772  \n",
       "45            1.725005  \n",
       "46            2.276066  \n",
       "47            3.340665  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            86400\n",
       "1            86401\n",
       "2            86469\n",
       "3            86499\n",
       "4            86506\n",
       "            ...   \n",
       "590535    15811047\n",
       "590536    15811049\n",
       "590537    15811079\n",
       "590538    15811088\n",
       "590539    15811131\n",
       "Name: TransactionDT, Length: 590540, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "\n",
    "\n",
    "# for val in \n",
    "\n",
    "df_temp = fe.df_feat[['TransactionDT']]\n",
    "df_temp['time_delta'] = 0\n",
    "len_df_temp = df_temp.shape[0]\n",
    "for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "    val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "    val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "    val_time_delta = val_time_2 - val_time_1\n",
    "    df_temp.loc[i, 'time_delta'] = val_time_delta\n",
    "    \n",
    "df_temp['days_lapsed_7'] = df_temp['time_delta']/7\n",
    "df_temp['days_lapsed_14'] = df_temp['time_delta']/14\n",
    "df_temp['days_lapsed_21'] = df_temp['time_delta']/21\n",
    "df_temp['days_lapsed_30'] = df_temp['time_delta']/30\n",
    "df_temp['days_lapsed_45'] = df_temp['time_delta']/45\n",
    "df_temp['days_lapsed_60'] = df_temp['time_delta']/60\n",
    "df_temp['days_lapsed_90'] = df_temp['time_delta']/90\n",
    "df_temp['days_lapsed_365'] = df_temp['time_delta']/365\n",
    "\n",
    "# we need to test these additional columns...\n",
    "df_temp['minutes_lapsed'] = df_temp['time_delta']/60\n",
    "df_temp['hours_lapsed'] = df_temp['time_delta']/3600\n",
    "df_temp['days_lapsed_1'] = df_temp['time_delta']/86400\n",
    "df_temp['days_lapsed_7'] = df_temp['time_delta']/604800\n",
    "\n",
    "# we need to add each feature one by one. \n",
    "\n",
    "\n",
    "\n",
    "# we need to add the feature one by one, then drop it....\n",
    "# this will need to be created it and added prior to the fe.create_feature method.. \n",
    "\n",
    "# we need to create this feature in feature engineering... \n",
    "# we need a way to build the system such that it automatically calculates and tests \n",
    "# the number of days lapsed, and creates a counter, then calculates 7,14,21,30,60,90,120.\n",
    "# from that point we need to test each of these new features individually.\n",
    "# we then determine the bbest new features to keep, then determine whether to include the \n",
    "# date of the transaction... It should really be tested as an obbject type. We will need to \n",
    "# apply one hot encoding, or label encoding.. we can't do labbel because one date isn't better than the next..\n",
    "# we also want to avoid creating high dimensionality... so we can drop the TransactionDT all together.\n",
    "\n",
    "#so here we go, we must create these new features, test them, then eventually drop the original date time feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop(['TransactionDT','time_delta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.concat([df_features,df_temp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['days_7',\n",
       " 'time_days_7',\n",
       " 'time_days_14',\n",
       " 'time_days_21',\n",
       " 'time_days_30',\n",
       " 'time_days_45',\n",
       " 'time_days_60',\n",
       " 'time_days_90',\n",
       " 'time_days_12',\n",
       " 'minutes_lapsed',\n",
       " 'hours_lapsed',\n",
       " 'seconds_lapsed']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_temp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1e97e8d0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "4138/60\n",
    "sns.boxplot(df_temp.time_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179171    4138\n",
       "36456     3490\n",
       "535796    3250\n",
       "496378    2757\n",
       "281346    2727\n",
       "193529    2621\n",
       "523979    2408\n",
       "578678    2304\n",
       "179173    2290\n",
       "457016    2265\n",
       "438114    2258\n",
       "219055    2243\n",
       "520917    2235\n",
       "576355    2210\n",
       "482860    2195\n",
       "547564    2181\n",
       "576363    2155\n",
       "518490    2135\n",
       "283789    2101\n",
       "131992    2087\n",
       "459306    2052\n",
       "491193    1996\n",
       "234978    1989\n",
       "588374    1976\n",
       "260528    1973\n",
       "216593    1932\n",
       "556630    1892\n",
       "140560    1891\n",
       "199493    1888\n",
       "420875    1884\n",
       "Name: time_delta, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.time_delta.sort_values(ascending=False)[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     30804\n",
       "2     29435\n",
       "3     26993\n",
       "4     25624\n",
       "5     23981\n",
       "6     22184\n",
       "7     21459\n",
       "8     19488\n",
       "9     18731\n",
       "10    17281\n",
       "0     17192\n",
       "11    16252\n",
       "12    15530\n",
       "13    14382\n",
       "14    13706\n",
       "15    12926\n",
       "16    12118\n",
       "17    11319\n",
       "18    10853\n",
       "19    10363\n",
       "20     9763\n",
       "21     9127\n",
       "22     8912\n",
       "23     8246\n",
       "24     7928\n",
       "25     7256\n",
       "26     7006\n",
       "27     6625\n",
       "28     6273\n",
       "29     6048\n",
       "30     5654\n",
       "31     5339\n",
       "32     5123\n",
       "33     4808\n",
       "34     4642\n",
       "35     4459\n",
       "36     4200\n",
       "37     3975\n",
       "38     3779\n",
       "39     3661\n",
       "40     3465\n",
       "41     3331\n",
       "42     3187\n",
       "43     3005\n",
       "45     2817\n",
       "44     2809\n",
       "47     2504\n",
       "46     2498\n",
       "48     2407\n",
       "49     2289\n",
       "Name: time_delta, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.time_delta.value_counts()[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30804, 11)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp[df_temp.time_delta==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>days_7</th>\n",
       "      <th>time_days_7</th>\n",
       "      <th>time_days_14</th>\n",
       "      <th>time_days_21</th>\n",
       "      <th>time_days_30</th>\n",
       "      <th>time_days_45</th>\n",
       "      <th>time_days_60</th>\n",
       "      <th>time_days_90</th>\n",
       "      <th>time_days_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7.372311e+06</td>\n",
       "      <td>26.627715</td>\n",
       "      <td>3.803959</td>\n",
       "      <td>3.803959</td>\n",
       "      <td>1.901980</td>\n",
       "      <td>1.267986</td>\n",
       "      <td>0.887591</td>\n",
       "      <td>0.591727</td>\n",
       "      <td>0.443795</td>\n",
       "      <td>0.295864</td>\n",
       "      <td>0.072953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.617224e+06</td>\n",
       "      <td>59.299048</td>\n",
       "      <td>8.471293</td>\n",
       "      <td>8.471293</td>\n",
       "      <td>4.235646</td>\n",
       "      <td>2.823764</td>\n",
       "      <td>1.976635</td>\n",
       "      <td>1.317757</td>\n",
       "      <td>0.988317</td>\n",
       "      <td>0.658878</td>\n",
       "      <td>0.162463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.027058e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.013699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.306528e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.035616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.124662e+07</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.581113e+07</td>\n",
       "      <td>4138.000000</td>\n",
       "      <td>591.142857</td>\n",
       "      <td>591.142857</td>\n",
       "      <td>295.571429</td>\n",
       "      <td>197.047619</td>\n",
       "      <td>137.933333</td>\n",
       "      <td>91.955556</td>\n",
       "      <td>68.966667</td>\n",
       "      <td>45.977778</td>\n",
       "      <td>11.336986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionDT     time_delta         days_7    time_days_7  \\\n",
       "count   5.905400e+05  590540.000000  590540.000000  590540.000000   \n",
       "mean    7.372311e+06      26.627715       3.803959       3.803959   \n",
       "std     4.617224e+06      59.299048       8.471293       8.471293   \n",
       "min     8.640000e+04       0.000000       0.000000       0.000000   \n",
       "25%     3.027058e+06       5.000000       0.714286       0.714286   \n",
       "50%     7.306528e+06      13.000000       1.857143       1.857143   \n",
       "75%     1.124662e+07      29.000000       4.142857       4.142857   \n",
       "max     1.581113e+07    4138.000000     591.142857     591.142857   \n",
       "\n",
       "        time_days_14   time_days_21   time_days_30   time_days_45  \\\n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000   \n",
       "mean        1.901980       1.267986       0.887591       0.591727   \n",
       "std         4.235646       2.823764       1.976635       1.317757   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.357143       0.238095       0.166667       0.111111   \n",
       "50%         0.928571       0.619048       0.433333       0.288889   \n",
       "75%         2.071429       1.380952       0.966667       0.644444   \n",
       "max       295.571429     197.047619     137.933333      91.955556   \n",
       "\n",
       "        time_days_60   time_days_90   time_days_12  \n",
       "count  590540.000000  590540.000000  590540.000000  \n",
       "mean        0.443795       0.295864       0.072953  \n",
       "std         0.988317       0.658878       0.162463  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.083333       0.055556       0.013699  \n",
       "50%         0.216667       0.144444       0.035616  \n",
       "75%         0.483333       0.322222       0.079452  \n",
       "max        68.966667      45.977778      11.336986  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.336986301369864 years\n",
      "172.41666666666666 days\n",
      "68.96666666666667 minutes\n",
      "1.1494444444444445 hours\n"
     ]
    }
   ],
   "source": [
    "print(4138.000000/365, 'years')\n",
    "print(4138.000000/24, 'days')\n",
    "# print(4138.000000/1, 'hour')\n",
    "print(4138.000000/60, 'minutes')\n",
    "print(4138.000000/3600, 'hours')\n",
    "\n",
    "# print(4138.000000/3600, 'hours')\n",
    "# print(4138.000000/60, 'minutes')\n",
    "# Looking at the max value... \n",
    "# there is no way to discern who is what credit card holder. We know each transaction is unique and has some\n",
    "# kind of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv') # comment out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it reads the csv, creates a dataframe, then appends the results, then saves over the old version and keeps\n",
    "# # a record of all columns in the tested dataframe.\n",
    "\n",
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# # we want to test a feature for feature engineering... we must \n",
    "\n",
    "# for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "#     print(col_original, col_new)\n",
    "#     X[col_new] = fe.df_feat[col_new]\n",
    "#     X = X.drop(col_original, axis=1)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    \n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "# #     X = X.drop(col, axis=1)\n",
    "#     print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = fe.df_feat[['TransactionDT']]\n",
    "# df_temp['time_delta'] = 0\n",
    "# len_df_temp = df_temp.shape[0]\n",
    "# for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "#     val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "#     val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "#     val_time_delta = val_time_2 - val_time_1\n",
    "#     df_temp.loc[i, 'time_delta'] = val_time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe'],axis=1)\n",
    "# df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['time_delta'] = df_temp['time_delta']\n",
    "# fe.df_feat['time_delta_week'] = df_temp['time_delta']/7\n",
    "# fe.df_feat['time_delta_month'] = df_temp['time_delta']/30\n",
    "# fe.df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe','time_delta_fe_week'],axis=1)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['TransactionAmt'] = df_features['TransactionAmt']\n",
    "# list(fe.df_feat)\n",
    "# fe.list_new_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat = fe.df_feat.drop(['time_delta_fe','addr1_fe'],axis=1)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# val_aggreg = 'TransactionAmt'\n",
    "# list_col = ['card2', 'C4', 'C1', 'V317', 'ProductCD', 'V294', 'V279', 'C14', 'card6', 'V306', 'V69']\n",
    "# fe.aggregate_features(list_col, val_aggreg)\n",
    "# list(fe.df_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### implement into feature engineering class. days lapsed\n",
    "df_temp = fe.df_feat[['TransactionDT']]\n",
    "df_temp['time_delta'] = 0\n",
    "len_df_temp = df_temp.shape[0]\n",
    "for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "    val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "    val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "    val_time_delta = val_time_2 - val_time_1\n",
    "    df_temp.loc[i, 'time_delta'] = val_time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we created the method to \n",
    "# test keeping the old feature then scoring... run this twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_temp.time_delta.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp[df_temp.time_delta==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp[(df_temp.time_delta==1) & (df_temp.isFraud==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp[(df_temp.time_delta==1) & (df_temp.isFraud==1)].shape[0]/df_temp[(df_temp.time_delta==1) & (df_temp.isFraud==0)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp\n",
    "# we need to figure out how to bin transactions based \n",
    "# Is there a relationship between isFraud and time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp['TransactionAmt'] = fe.df_feat['TransactionAmt']\n",
    "# df_temp['isFraud'] = fe.df_feat['isFraud']\n",
    "# df_temp[df_temp.isFraud==1][0:60] # how do we bin these? \n",
    "# df_temp2 = fe.df_feat.copy()\n",
    "# df_temp2['time_delta'] = df_temp['time_delta']\n",
    "# df_temp2.groupby('isFraud').mean()\n",
    "# # we can do based on transactionamt and time delta as well as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the aggregation of date, every 7 days, calculate the possibility of fraud for the average week\n",
    "# then do the average month\n",
    "# this would mean that we need to order the dataset dates in some kind of order of 7\n",
    "# create column that expresses days lapsed... just focus on that for a bit. Days lapsed between each transaction\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list_timedelta_isfraud = ['D1','D2','D3','D4','D10','D11','D15','isFraud']#, 'TransactionAmt']\n",
    "# df_temp = fe.df_feat[list_timedelta_isfraud].groupby('isFraud').mean()\n",
    "# df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into this strategy \n",
    "# so we take each D and aggregate it to C4 for only columns that have fraud, then for columns that dont have\n",
    "# fraud, then we map those values to each that dont have fraud and those that do... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # append D1 value based on if its fraud or not. Create a dictionary for each column, then map it\n",
    "# for col in ['D1']:\n",
    "#     df_temp = fe.df_feat[[col, 'isFraud']].groupby('isFraud').mean()\n",
    "#     dict_col = df_temp.to_dict()\n",
    "#     fe.df_feat[col + '_fe'] = \n",
    "#     # this might not work because we cant assign some random value that has a row that is fraud and expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_test = ['C2', 'D1',\n",
    "#  'D2',\n",
    "#  'D3',\n",
    "#  'D4',\n",
    "#  'D10',\n",
    "#  'D11',\n",
    "#  'D15', 'isFraud']\n",
    "# df_not_fraud = fe.df_feat[fe.df_feat.isFraud==0]\n",
    "# df_fraud = fe.df_feat[fe.df_feat.isFraud==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate based on D1 and isFraud\n",
    "# df_test = fe.df_feat[['C2', 'isFraud']].groupby('C2').mean()\n",
    "# # df_test = fraud_summ.mean() \n",
    "# # df_test.isFraud.value_counts()\n",
    "# dict_c2_isfraud = df_test.to_dict()['isFraud']\n",
    "# fe.df_feat['C2_fe'] = fe.df_feat['C2'].map(dict_c2_isfraud)\n",
    "# ###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# ### PCA + SMOTE testing algorithm ###\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# # applying PCA\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "# # pca = PCA(n_components=250)\n",
    "# pca = PCA()\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)\n",
    "\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # applying SMOTE\n",
    "# sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "\n",
    "# # fit logistic regression\n",
    "# model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# # predict\n",
    "# y_pred = model_lr_pca_sm.predict(X_train2)\n",
    "# # time\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print('\\nTime elapsed:', elapsed_time / 60)\n",
    "# print(confusion_matrix(y_train2, y_pred))\n",
    "# print(classification_report(y_train2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns[275:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columnsa[275:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NEXT, get our score working properly again... What did we do to score \n",
    "# LogisticRegression Base\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "# fit logistic regression\n",
    "model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# predict\n",
    "y_pred = model_lr_pca_sm.predict(X_test)\n",
    "# time\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# BASE SCORE\n",
    "# Time elapsed: 4.251827295621236\n",
    "# [[33985 22960]\n",
    "#  [  601  1508]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.60      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# RESULT: addr1_fe only\n",
    "\n",
    "# RESULT: time_delta_fe, addr1\n",
    "# Time elapsed: 5.163579479853312\n",
    "# [[26551 30394]\n",
    "#  [  363  1746]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.47      0.63     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.48     59054\n",
    "#    macro avg       0.52      0.65      0.37     59054\n",
    "# weighted avg       0.95      0.48      0.61     59054\n",
    "\n",
    "# RESULT: time_delta_fe, time_delta_week_fe\n",
    "# Time elapsed: 3.142271514733632\n",
    "# [[32540 24405]\n",
    "#  [  560  1549]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.57      0.72     56945\n",
    "#            1       0.06      0.73      0.11      2109\n",
    "\n",
    "#     accuracy                           0.58     59054\n",
    "#    macro avg       0.52      0.65      0.42     59054\n",
    "# weighted avg       0.95      0.58      0.70     59054\n",
    "\n",
    "\n",
    "# RESULT: created time_delta_fe\n",
    "# Time elapsed: 3.1532896359761557\n",
    "# [[26260 30685]\n",
    "#  [  359  1750]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.46      0.63     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.47     59054\n",
    "#    macro avg       0.52      0.65      0.36     59054\n",
    "# weighted avg       0.95      0.47      0.61     59054\n",
    "\n",
    "# RESULT: time_delta_fe only. dropping addr1_fe\n",
    "# Time elapsed: 6.11533077955246\n",
    "# [[26893 30052]\n",
    "#  [  365  1744]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.47      0.64     56945\n",
    "#            1       0.05      0.83      0.10      2109\n",
    "\n",
    "#     accuracy                           0.48     59054\n",
    "#    macro avg       0.52      0.65      0.37     59054\n",
    "# weighted avg       0.95      0.48      0.62     59054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.list_new_feat\n",
    "'TransactionAmt_fe', 'card1_fe', 'card2_fe','card3_fe', 'card5_fe', 'addr1_fe', 'addr2_fe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression feature testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.drop(col_target, axis=1)\n",
    "X = X.drop(col_id, axis=1)\n",
    "y = df_features[col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 'TransactionAmt_fe', 'card1_fe', 'card2_fe','card3_fe', 'card5_fe', 'addr1_fe', 'addr2_fe'\n",
    "# Good: addr2_fe, \n",
    "# Bad: TransactionAmt_fe, card1_fe, card2_fe, card3_fe, card5_fe\n",
    "# build a function that after a feature is created, you then have it test the feature and provide you results.. \n",
    "\n",
    "for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "    print(col_original, col_new)\n",
    "    X[col_new] = fe.df_feat[col_new]\n",
    "    X = X.drop(col_original, axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "    model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "#     X = X.drop(col, axis=1)\n",
    "    print(list(X.columns))\n",
    "# RESULTS: Base: 601\n",
    "\n",
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # NEXT, TESTING groupby on C2 and isFraud...test other columns too.. specifically, D1, D2, etc. \n",
    "# # consider creating a rolling 7 day period for time between transactions and aggregating isFraud to estimate\n",
    "# # the amount spent that week against the probability that fraud happened.\n",
    "\n",
    "# # good fe: C2_fe, card2_fe, V294_fe, V317_fe, V279_fe, V306_fe\n",
    "# # bad fe: C1_fe, ProductCD_fe, V294_fe, C14_fe, card6_fe, V69_fe\n",
    "# for col in list_col_fe:\n",
    "#     X[col] = fe.df_feat[col]    \n",
    "#     print(col)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     X = X.drop(col, axis=1)\n",
    "    \n",
    "# # good: C2_fe, \n",
    "# # not good: card2_fe, C4_fe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior information \n",
    "# C2_fe\n",
    "\n",
    "# Time elapsed: 6.717598664760589\n",
    "# [[33735 23210]\n",
    "#  [  595  1514]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.59      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# card2_fe\n",
    "\n",
    "# Time elapsed: 7.546754765510559\n",
    "# [[35200 21745]\n",
    "#  [  649  1460]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.62      0.76     56945\n",
    "#            1       0.06      0.69      0.12      2109\n",
    "\n",
    "#     accuracy                           0.62     59054\n",
    "#    macro avg       0.52      0.66      0.44     59054\n",
    "# weighted avg       0.95      0.62      0.74     59054\n",
    "\n",
    "# C4_fe\n",
    "\n",
    "# Time elapsed: 5.034457282225291\n",
    "# [[36521 20424]\n",
    "#  [  602  1507]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.64      0.78     56945\n",
    "#            1       0.07      0.71      0.13      2109\n",
    "\n",
    "#     accuracy                           0.64     59054\n",
    "#    macro avg       0.53      0.68      0.45     59054\n",
    "# weighted avg       0.95      0.64      0.75     59054\n",
    "\n",
    "# C1_fe\n",
    "\n",
    "# Time elapsed: 5.847904968261719\n",
    "# [[40085 16860]\n",
    "#  [  701  1408]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.70      0.82     56945\n",
    "#            1       0.08      0.67      0.14      2109\n",
    "\n",
    "#     accuracy                           0.70     59054\n",
    "#    macro avg       0.53      0.69      0.48     59054\n",
    "# weighted avg       0.95      0.70      0.80     59054\n",
    "\n",
    "# V317_fe\n",
    "\n",
    "# Time elapsed: 4.49170538187027\n",
    "# [[33842 23103]\n",
    "#  [  583  1526]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.59      0.74     56945\n",
    "#            1       0.06      0.72      0.11      2109\n",
    "\n",
    "#     accuracy                           0.60     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.60      0.72     59054\n",
    "\n",
    "# ProductCD_fe\n",
    "\n",
    "# Time elapsed: 5.576840949058533\n",
    "# [[41354 15591]\n",
    "#  [  737  1372]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.73      0.84     56945\n",
    "#            1       0.08      0.65      0.14      2109\n",
    "\n",
    "#     accuracy                           0.72     59054\n",
    "#    macro avg       0.53      0.69      0.49     59054\n",
    "# weighted avg       0.95      0.72      0.81     59054\n",
    "\n",
    "# V294_fe\n",
    "\n",
    "# Time elapsed: 4.640570282936096\n",
    "# [[37922 19023]\n",
    "#  [  698  1411]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.67      0.79     56945\n",
    "#            1       0.07      0.67      0.13      2109\n",
    "\n",
    "#     accuracy                           0.67     59054\n",
    "#    macro avg       0.53      0.67      0.46     59054\n",
    "# weighted avg       0.95      0.67      0.77     59054\n",
    "\n",
    "# V279_fe\n",
    "\n",
    "# Time elapsed: 3.3400171319643657\n",
    "# [[33443 23502]\n",
    "#  [  577  1532]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.59      0.74     56945\n",
    "#            1       0.06      0.73      0.11      2109\n",
    "\n",
    "#     accuracy                           0.59     59054\n",
    "#    macro avg       0.52      0.66      0.42     59054\n",
    "# weighted avg       0.95      0.59      0.71     59054\n",
    "\n",
    "# C14_fe\n",
    "\n",
    "# Time elapsed: 6.974740914503733\n",
    "# [[35823 21122]\n",
    "#  [  599  1510]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.63      0.77     56945\n",
    "#            1       0.07      0.72      0.12      2109\n",
    "\n",
    "#     accuracy                           0.63     59054\n",
    "#    macro avg       0.53      0.67      0.44     59054\n",
    "# weighted avg       0.95      0.63      0.74     59054\n",
    "\n",
    "# card6_fe\n",
    "\n",
    "# Time elapsed: 3.6439321478207907\n",
    "# [[36705 20240]\n",
    "#  [  640  1469]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.64      0.78     56945\n",
    "#            1       0.07      0.70      0.12      2109\n",
    "\n",
    "#     accuracy                           0.65     59054\n",
    "#    macro avg       0.53      0.67      0.45     59054\n",
    "# weighted avg       0.95      0.65      0.76     59054\n",
    "\n",
    "# V306_fe\n",
    "\n",
    "# Time elapsed: 2.792719868818919\n",
    "# [[34359 22586]\n",
    "#  [  592  1517]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.60      0.75     56945\n",
    "#            1       0.06      0.72      0.12      2109\n",
    "\n",
    "#     accuracy                           0.61     59054\n",
    "#    macro avg       0.52      0.66      0.43     59054\n",
    "# weighted avg       0.95      0.61      0.73     59054\n",
    "\n",
    "# V69_fe\n",
    "\n",
    "# Time elapsed: 5.5301028688748675\n",
    "# [[39833 17112]\n",
    "#  [  694  1415]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.70      0.82     56945\n",
    "#            1       0.08      0.67      0.14      2109\n",
    "\n",
    "#     accuracy                           0.70     59054\n",
    "#    macro avg       0.53      0.69      0.48     59054\n",
    "# weighted avg       0.95      0.70      0.79     59054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop('card2_fe',axis=1)\n",
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "for col in list_col_fe:\n",
    "    X[col] = fe.df_feat[col]    \n",
    "    print(col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    # SMOTE\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    # fit decision tree\n",
    "    model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "    model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "    # predict\n",
    "    y_pred = model_dt_pca_smote.predict(X_train)\n",
    "    # time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    X = X.drop(col, axis=1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decision tree\n",
    "for col in list_col_fe:\n",
    "    X[col] = fe.df_feat[col]    \n",
    "    print(col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    start_time = time.time()\n",
    "    # applying SMOTE\n",
    "    sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    # fit decision tree\n",
    "    model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "    model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "    # predict\n",
    "    y_pred = model_dt_pca_smote.predict(X_test)\n",
    "    # time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    X = X.drop(col, axis=1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('\\nTime elapsed:', elapsed_time / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree Base\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "# fit decision tree\n",
    "model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "# predict\n",
    "y_pred = model_dt_pca_smote.predict(X_test)\n",
    "# time\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "\n",
    "# [[55791  1154]\n",
    "#  [  941  1168]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.98      0.98      0.98     56945\n",
    "#            1       0.50      0.55      0.53      2109\n",
    "\n",
    "#     accuracy                           0.96     59054\n",
    "#    macro avg       0.74      0.77      0.75     59054\n",
    "# weighted avg       0.97      0.96      0.97     59054\n",
    "\n",
    "\n",
    "# Time elapsed: 8.485406096776327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit logistic regression\n",
    "# model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "# # predict\n",
    "# y_pred = model_lr_pca_sm.predict(X_train2)\n",
    "# # time\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print('\\nTime elapsed:', elapsed_time / 60)\n",
    "# print(confusion_matrix(y_train2, y_pred))\n",
    "# print(classification_report(y_train2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULT: C4_fe with TransactionAmt\n",
    "\n",
    "# RESULT: Base Score, smote only, no pca\n",
    "# [[245073 267859]\n",
    "#  [  3447  15107]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.48      0.64    512932\n",
    "#            1       0.05      0.81      0.10     18554\n",
    "\n",
    "#     accuracy                           0.49    531486\n",
    "#    macro avg       0.52      0.65      0.37    531486\n",
    "# weighted avg       0.95      0.49      0.62    531486\n",
    "\n",
    "# Scores below reflect _fe's\n",
    "# RESULTS: drop card6_fe\n",
    "# Time elapsed: 3.520830734570821\n",
    "# [[361114 151818]\n",
    "#  [  4823  13731]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.70      0.82    512932\n",
    "#            1       0.08      0.74      0.15     18554\n",
    "\n",
    "#     accuracy                           0.71    531486\n",
    "#    macro avg       0.53      0.72      0.49    531486\n",
    "# weighted avg       0.96      0.71      0.80    531486\n",
    "\n",
    "# RESULTS: card6_fe \n",
    "# Time elapsed: 3.569287049770355\n",
    "# [[362083 150849]\n",
    "#  [  4745  13809]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.71      0.82    512932\n",
    "#            1       0.08      0.74      0.15     18554\n",
    "\n",
    "#     accuracy                           0.71    531486\n",
    "#    macro avg       0.54      0.73      0.49    531486\n",
    "# weighted avg       0.96      0.71      0.80    531486\n",
    "\n",
    "# RESULTS: dropped features and used PCA, worstened score\n",
    "# [[413977  98955]\n",
    "#  [  4747  13807]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.81      0.89    512932\n",
    "#            1       0.12      0.74      0.21     18554\n",
    "\n",
    "#     accuracy                           0.80    531486\n",
    "#    macro avg       0.56      0.78      0.55    531486\n",
    "# weighted avg       0.96      0.80      0.87    531486\n",
    "\n",
    "# RESULTS: drop low ranking features found in decision tree\n",
    "# [[329812 183120]\n",
    "#  [  4810  13744]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.64      0.78    512932\n",
    "#            1       0.07      0.74      0.13     18554\n",
    "\n",
    "#     accuracy                           0.65    531486\n",
    "#    macro avg       0.53      0.69      0.45    531486\n",
    "# weighted avg       0.95      0.65      0.76    531486\n",
    "\n",
    "# RESULTS: without PCA\n",
    "# [[298715 214217]\n",
    "#  [  3509  15045]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.58      0.73    512932\n",
    "#            1       0.07      0.81      0.12     18554\n",
    "\n",
    "#     accuracy                           0.59    531486\n",
    "#    macro avg       0.53      0.70      0.43    531486\n",
    "# weighted avg       0.96      0.59      0.71    531486\n",
    "\n",
    "# RESULTS: keep ohe for email and create p email feature calculate email domain fraud feature\n",
    "# [[434421  78511]\n",
    "#  [  4429  14125]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.84    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.84      0.89    531486\n",
    "\n",
    "# RESULTS: with new feature, try dropping ohe p_email and test\n",
    "# [[435499  77433]\n",
    "#  [  4539  14015]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.85    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.85      0.89    531486\n",
    "\n",
    "# RESULTS: cut FP rate quite a bit. fixing fraud perc calculation by doing fraud/non fraud for each value in each column\n",
    "# [[434423  78509]\n",
    "#  [  4430  14124]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.85      0.91    512932\n",
    "#            1       0.15      0.76      0.25     18554\n",
    "\n",
    "#     accuracy                           0.84    531486\n",
    "#    macro avg       0.57      0.80      0.58    531486\n",
    "# weighted avg       0.96      0.84      0.89    531486\n",
    "\n",
    "\n",
    "# RESULTS: adding 60 for one hot encoding\n",
    "# [[403339 109593]\n",
    "#  [  4393  14161]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.79      0.88    512932\n",
    "#            1       0.11      0.76      0.20     18554\n",
    "\n",
    "#     accuracy                           0.79    531486\n",
    "#    macro avg       0.55      0.77      0.54    531486\n",
    "# weighted avg       0.96      0.79      0.85    531486\n",
    "\n",
    "# RESULTS: fe for 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card5'\n",
    "# [[397116 115816]\n",
    "#  [  4490  14064]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.77      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: only addr6. Creating ratio ranking of higher risk areas for fraud. \n",
    "# [[396866 116066]\n",
    "#  [  4534  14020]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# NEXT, test creating iqr range instead of percentage values, instead of what we did\n",
    "# with addr5, then create one for addr2, then create an addr7 based on interaction with addr2. \n",
    "\n",
    "\n",
    "\n",
    "# RESULTS: only addr5. testing mapping percentage values transformed..\n",
    "# [[396898 116034]\n",
    "#  [  4535  14019]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with only addr3, addr4\n",
    "# [[396868 116064]\n",
    "#  [  4544  14010]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: w/o addr1, addr2, addr3, addr4\n",
    "# [[396629 116303]\n",
    "#  [  4545  14009]]\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.76      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with only addr1, addr2\n",
    "# [[396803 116129]\n",
    "#  [  4555  13999]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.75      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486\n",
    "\n",
    "# RESULTS: with addr1, addf2, addr3, addr4\n",
    "# [[396877 116055]\n",
    "#  [  4549  14005]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.77      0.87    512932\n",
    "#            1       0.11      0.75      0.19     18554\n",
    "\n",
    "#     accuracy                           0.77    531486\n",
    "#    macro avg       0.55      0.76      0.53    531486\n",
    "# weighted avg       0.96      0.77      0.84    531486"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - SMOTE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = fe.df_feat.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree smote only (pca commented out)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # applying PCA\n",
    "# scaled_X = StandardScaler().fit_transform(X)\n",
    "# # pca = PCA(n_components=250)\n",
    "# pca = PCA()\n",
    "# pcomponents = pca.fit_transform(scaled_X)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.1, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "# applying SMOTE\n",
    "sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train2, y_train2)\n",
    "\n",
    "model_dt_pca_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_pca_smote.fit(X_train_res, y_train_res)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('\\nTime elapsed:', elapsed_time / 60)\n",
    "\n",
    "# Feature importance\n",
    "col_name = pd.Series(X.columns, name='col')\n",
    "col_feat_rank = pd.Series(model_dt_pca_smote.feature_importances_, name='feat_rank')\n",
    "df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1).sort_values('feat_rank', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "sns.barplot(df_feat_rank.feat_rank[0:10], df_feat_rank.col[0:10], palette='Blues_d')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "df_feat_rank[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EDA on C4 and TransactionAmt\n",
    "# df_temp = fe.df_feat\n",
    "\n",
    "# sns.lineplot(x='C4', y='TransactionAmt', data=df_temp)\n",
    "# plt.title('C4 versus Transaction Amount')\n",
    "# plt.show()\n",
    "\n",
    "# sns.scatterplot(x='C4', y='TransactionAmt', hue='isFraud', data=df_temp)\n",
    "# plt.title('C4 versus Transaction Amount')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the type of card is highly correllated with debit, credit, etc. figure out which feature to create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_lr_pca_sm.predict(X_pca)\n",
    "\n",
    "# cross validation\n",
    "# result = cross_val_score(model_lr_pca_sm, X_train2, y_train2, cv=10, n_jobs=-1, scoring='recall_score')\n",
    "# result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes, do we need to visualize our results?? We need to look at our confusion matrix\n",
    "# and decide how to improve our results from here... Test and see what happens if we \n",
    "# increase our principal components... test removing columns, adding columns, imputing\n",
    "# certain columns all together. \n",
    "\n",
    "# test imputing 500 or less for ohe. Then test dropping card1 due to its number\n",
    "# of unique values that would make our data very high dimensional. We can try only ohe for\n",
    "# the entire dataset to see how our model performs over all... Though.. it will likely run \n",
    "# out of memory and crash. \n",
    "\n",
    "# ALSO test probabilities on logisticregression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# plt.hist(y_pred_prob[:,1], bins=8)\n",
    "# plt.xlim(0,1)\n",
    "# plt.title(\"Histogram of Probability of Fraud\")\n",
    "# plt.xlabel(\"Predicted probability of Fraud\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# y_pred_class = binarize(y_pred_prob, 0.5)[:,1]\n",
    "\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.title(\"ROC curve for fraud detection classifier\")\n",
    "# plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "# plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_threshold(threshold):\n",
    "#     print(\"Sensitivity:\", tpr[thresholds > threshold][-1])\n",
    "#     print(\"Specificity:\", 1 - fpr[thresholds > threshold][-1],'\\n')\n",
    "    \n",
    "# evaluate_threshold(.5)\n",
    "# evaluate_threshold(.2)\n",
    "# evaluate_threshold(.1)\n",
    "\n",
    "# print(roc_auc_score(y, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_test2) # actual prediction test data set\n",
    "# print('y_pred_actual on test set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_actual))\n",
    "# print(classification_report(y_test2, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_test2)\n",
    "# y_pred_class = binarize(y_pred_proba, 0.5)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_class))\n",
    "# print(classification_report(y_test2, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_pca) # actual full data set\n",
    "# print('Logistic Regression')\n",
    "# print('y_pred_actual full data set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y, y_pred_actual))\n",
    "# print(classification_report(y, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba full data set\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_pca)#[:,1]#[0:10]\n",
    "# y_pred_class = binarize(y_pred_proba, 0.2)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using Logistic Regression, PCA, SMOTE\\n\")\n",
    "# y_pred_pca_sm = model_lr_pca.predict(X_test2)\n",
    "# # y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_lr_pca.score(X_test2, y_test2))\n",
    "# print(recall_score(y_test2, y_pred_pca_sm))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test2, y_pred_pca_sm))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test2, y_pred_pca_sm))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred_pca_sm_whole = model_lr_pca.predict(X_pca)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_lr_pca.score(X_pca, y))\n",
    "# print(recall_score(y, y_pred_pca_sm_whole))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred_pca_sm_whole))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred_pca_sm_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('dataframe length: ' + str(df_features.shape[0]))\n",
    "# print('TransactionDT unique: ' + str(len(df_features.TransactionDT.unique())))\n",
    "# print('is not fraud: ' + str(df_features[df_features.isFraud==0].shape[0]))\n",
    "# print('is fraud: ' + str(df_features[df_features.isFraud==1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # KEEP\n",
    "# fig = plt.figure(figsize=(15,4))\n",
    "# df_temp = df_features\n",
    "# sns.kdeplot(df_temp.loc[(df_temp.isFraud==0), 'TransactionDT'], color='b', shade=True, label='Not Fraud')\n",
    "# sns.kdeplot(df_temp.loc[(df_temp.isFraud==1), 'TransactionDT'], color='r', shade=True, label='Fraud')\n",
    "# plt.title('Transaction Date Versus Fraud')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='TransactionDT', y='TransactionDT', hue='isFraud', data=df_features)\n",
    "# plt.title(\"Transaction Date Versus Fraud\")\n",
    "# plt.show()\n",
    "\n",
    "# we want to figure out how to create more features from TransactionDT.. \n",
    "# are certain transactions more likely. in general, to be fraudualant around a certain day? \n",
    "# we have transactionID yet we dont have the specific card of who it belongs to.. \n",
    "# if card1 is the unique identifier... and we did a groupby on fraud.. \n",
    "# we have average spent per day as an option... \n",
    "# create a feature that is average spent per day for non fraud versus average spent per day for fraud.. \n",
    "# what would the describe method reveal for us? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction date is the most highly correllated.. another correlation is transaction amount..\n",
    "# our goal is to create another feature that is highly correllated almost or more than TransactionDT. \n",
    "# we want to increase the strength.. What feature can we create that would boost the accuracy...\n",
    "# what feature can we create that exposes more truth in transactionDT? Would it be a specific date?\n",
    "# would it be the average amount over each week or month... ? what about a specific dates transaction\n",
    "# would help us...? We know taking average amounts spent can help us... So if we take monthly spending..\n",
    "# we can tell the algorithm that during certain months the transaction likelihood of fraud is higher.. \n",
    "# we must think up a solution before implementing it, we want to think out the best use of our time.. \n",
    "# We might perform EDA to see if specific time chunks do in fact have higher fraud counts.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_drop_col_1 = list(df_feat_rank[df_feat_rank.feat_rank < .0015]['col'])\n",
    "# list_drop_col_2 = list(df_feat_rank[df_feat_rank.feat_rank < .0015]['col'])\n",
    "# list_drop_col_3 = list(df_feat_rank[df_feat_rank.feat_rank < .01]['col'])\n",
    "\n",
    "# print(len(list_drop_col_1))\n",
    "# print(len(list_drop_col_2))\n",
    "# print(len(list_drop_col_3))\n",
    "\n",
    "# list_drop_col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicting on test set w/o PCA\n",
    "# print(\"Predicting using PCA\\n\")\n",
    "# y_pred_pca = model_dt_pca_smote.predict(X_test2)\n",
    "# # y_pred_test1 = model_lr.predict(X_test1)\n",
    "# print(\"Test set:\")\n",
    "# print(\"Validation results\")\n",
    "# print(model_dt_pca_smote.score(X_test2, y_test2))\n",
    "# print(recall_score(y_test2, y_pred_pca))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test2, y_pred_pca))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test2, y_pred_pca))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# print(\"Whole dataset:\")\n",
    "# y_pred_pca = model_dt_pca_smote.predict(X_pca)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(model_dt_pca_smote.score(X_pca, y))\n",
    "# print(recall_score(y, y_pred_pca))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred_pca))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Variance ratio:\")\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(\"\\nPrincipal components explained:\")\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # explaining variance\n",
    "# print('Variance ratio:')\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# # interpreting principal components\n",
    "# print('\\nPrincipal components explained:')\n",
    "# pd.DataFrame(pca.components_, columns=list(X.columns), index=('PC1', 'PC2'))\n",
    "\n",
    "# # # predicting on original dataset\n",
    "# # y_pred = clf_lr.predict(X)\n",
    "# # print(\"\\nTest Results\")\n",
    "# # print(clf_lr.score(X, y))\n",
    "# # print(recall_score(y, y_pred))\n",
    "# # print(\"\\nConfusion Matrix\")\n",
    "# # print(confusion_matrix(y, y_pred))\n",
    "# # print('\\nClassification Report:\\n')\n",
    "# # print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X2 = StandardScaler().fit_transform(X)\n",
    "# pca3 = PCA(n_components=275)\n",
    "# pcomponents = pca3.fit_transform(scaled_X2)\n",
    "# X_pca = pd.DataFrame(data=pcomponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # applying SMOTE to train set to correct class imbalance\n",
    "# sm = SMOTE(random_state=42, ratio = 1.0, n_jobs=-1)\n",
    "# X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# # fitting to residuals created by SMOTE\n",
    "# clf_lr = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "# clf_lr.fit(X_train_res, y_train_res);\n",
    "\n",
    "# # predicting on test set\n",
    "# y_test_pred = clf_lr.predict(X_test)\n",
    "# print(\"Validation results\")\n",
    "# print(clf_lr.score(X_test, y_test))\n",
    "# print(recall_score(y_test, y_test_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y_test, y_test_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# # predicting on original dataset\n",
    "# y_pred = clf_lr.predict(X)\n",
    "# print(\"\\nTest Results\")\n",
    "# print(clf_lr.score(X, y))\n",
    "# print(recall_score(y, y_pred))\n",
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nConfusion Matrix\")\n",
    "# print(confusion_matrix(y, y_pred))\n",
    "# print('\\nClassification Report:\\n')\n",
    "# print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
