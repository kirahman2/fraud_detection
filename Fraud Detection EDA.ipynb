{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_train = train_transaction.merge(train_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transaction.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_transaction_sum = train_transaction.duplicated().sum()\n",
    "# train_identity_sum = train_identity.duplicated().sum()\n",
    "# columns = train_transaction.columns\n",
    "# print('Train transaction duplicates: {}\\nTrain identity duplicates: {} \\n'.format(train_transaction_sum, train_identity_sum))\n",
    "# # print('Train feature columns:\\n', list(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 200 columns with null values.\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "                \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            if len(df_temp[val].unique()) < 10:\n",
    "                print('dummies encoded: ' + str(val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()\n",
    "# df_null_info\n",
    "\n",
    "# determine what to do with columns that have too many unique values... obviously.. types of solutions\n",
    "# would be to put \"MISSING\" for those that dont have an email address... but you will need to evaluate \n",
    "# and make instead a counter of unique values, then append that and look at the CSV via google sheets. use \n",
    "# something like the code below \n",
    "\n",
    "# Planning - our preprocessing method must automatically drop missing values, but we can't do that because\n",
    "# we need to see about filling them in first, then decide if we need to drop them. Right now, we need to\n",
    "# create a dataframe that shows unique values for each column with missing values. \n",
    "\n",
    "# we need to look at each variable and see if it's unique or categorical. We need to use possibly PCA...? How do\n",
    "# we handle so many variables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoded: addr1\n",
      "label encoded: addr2\n",
      "dummies encoded: ProductCD\n",
      "label encoded: P_emaildomain\n",
      "label encoded: card1\n",
      "label encoded: card2\n",
      "label encoded: card3\n",
      "dummies encoded: card4\n",
      "label encoded: card5\n",
      "dummies encoded: card6\n",
      "dummies encoded: M1\n",
      "dummies encoded: M2\n",
      "dummies encoded: M3\n",
      "dummies encoded: M4\n",
      "dummies encoded: M6\n",
      "new dataframe shape:(590540, 244)\n"
     ]
    }
   ],
   "source": [
    "pp.df_train = pp.impute_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID       int64\n",
       "isFraud             int64\n",
       "TransactionDT       int64\n",
       "TransactionAmt    float64\n",
       "ProductCD          object\n",
       "card1               int64\n",
       "card2               int64\n",
       "card3               int64\n",
       "card4              object\n",
       "card5               int64\n",
       "card6              object\n",
       "addr1               int64\n",
       "addr2               int64\n",
       "P_emaildomain       int64\n",
       "C1                float64\n",
       "C2                float64\n",
       "C3                float64\n",
       "C4                float64\n",
       "C5                float64\n",
       "C6                float64\n",
       "C7                float64\n",
       "C8                float64\n",
       "C9                float64\n",
       "C10               float64\n",
       "C11               float64\n",
       "C12               float64\n",
       "C13               float64\n",
       "C14               float64\n",
       "D1                float64\n",
       "D2                float64\n",
       "D3                float64\n",
       "D4                float64\n",
       "D10               float64\n",
       "D11               float64\n",
       "D15               float64\n",
       "M1                 object\n",
       "M2                 object\n",
       "M3                 object\n",
       "M4                 object\n",
       "M6                 object\n",
       "V1                float64\n",
       "V2                float64\n",
       "V3                float64\n",
       "V4                float64\n",
       "V5                float64\n",
       "V6                float64\n",
       "V7                float64\n",
       "V8                float64\n",
       "V9                float64\n",
       "V10               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.df_train.dtypes.head(50)\n",
    "# NEXT, dummies encoding is not encoding or saving properly, fix this before moving onto PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we decide on label encode, or impute, we will need to eventually use PCA. \n",
    "# how do we approach this? We have categorical columns with lots of numbers.. it doesnt make sense to \n",
    "# label encode at hte same time we risk having high cardinality... which means we must just label \n",
    "# encoding anything below 10 for now, then switch to 59, see how that performs, apply, PCA, \n",
    "# test again.. run the model.. So here are our steps \n",
    "\n",
    "# NEXT, 1. dummies encode anything less than 10, 2. label encode the rest 3. apply PCA 3. run the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# D = time elapsed between each transaction, card = card information, C = counting, ie how many addresses \n",
    "# associated with card, M=True/False, V created features on ranking, counting, etc. \n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = ['isFraud']\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# boolean columns. convert via dummy variable. We dont know if true/false is better than one or the other. \n",
    "# col_bool = col_m\n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i + col_target)))\n",
    "\n",
    "# col_all = col_cat + col_num + col_date + col_bool + col_id + col_target\n",
    "# columns removed dist1, dist2, R_emaildomain, DeviceInfo, DeviceType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>321.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ...   V312 V313 V314 V315  V316    V317  \\\n",
       "0  321.0  150.0    discover  142.0  ...    0.0  0.0  0.0  0.0   0.0   117.0   \n",
       "1  404.0  150.0  mastercard  102.0  ...    0.0  0.0  0.0  0.0   0.0     0.0   \n",
       "2  490.0  150.0        visa  166.0  ...    0.0  0.0  0.0  0.0   0.0     0.0   \n",
       "3  567.0  150.0  mastercard  117.0  ...  135.0  0.0  0.0  0.0  50.0  1404.0   \n",
       "4  514.0  150.0  mastercard  102.0  ...    0.0  0.0  0.0  0.0   0.0     0.0   \n",
       "\n",
       "    V318  V319  V320  V321  \n",
       "0    0.0   0.0   0.0   0.0  \n",
       "1    0.0   0.0   0.0   0.0  \n",
       "2    0.0   0.0   0.0   0.0  \n",
       "3  790.0   0.0   0.0   0.0  \n",
       "4    0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clean the data before thinking about applying PCA. \n",
    "\n",
    "\n",
    "# 1. impute all objects columns with one hot encoding\n",
    "# 1.1 What's a categorical? \n",
    "# We know the V's are ranking.. we need to discern meaning, \n",
    "# \n",
    "\n",
    "# 2. figure out if we should do pca next. we should do that next..\n",
    "# 3. use decision trees to determine important features. We don't need to do label encoding for this. If \n",
    "#    our training model is too slow... we need to implement PCA before further EDA via decision trees. \n",
    "# 4. Once we finish decision trees, we can continue EDA. \n",
    "# 5. If dt is too slow, we will need to impute our data for PCA. Let's impute now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in pp.df_train.columns:\n",
    "    if (pp.df_train[pp.df_train[val]=='nan'].shape[0]) > 0:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M2</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>outlook.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>W</td>\n",
       "      <td>6550</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>272.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590536</td>\n",
       "      <td>W</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>204.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>M0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590537</td>\n",
       "      <td>W</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>231.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>M0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590538</td>\n",
       "      <td>W</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>387.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>aol.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590539</td>\n",
       "      <td>W</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>299.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>M0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProductCD  card1  card2  card3       card4  card5   card6  addr1 addr2  \\\n",
       "0              W  13926    nan  150.0    discover  142.0  credit  315.0  87.0   \n",
       "1              W   2755  404.0  150.0  mastercard  102.0  credit  325.0  87.0   \n",
       "2              W   4663  490.0  150.0        visa  166.0   debit  330.0  87.0   \n",
       "3              W  18132  567.0  150.0  mastercard  117.0   debit  476.0  87.0   \n",
       "4              H   4497  514.0  150.0  mastercard  102.0  credit  420.0  87.0   \n",
       "...          ...    ...    ...    ...         ...    ...     ...    ...   ...   \n",
       "590535         W   6550    nan  150.0        visa  226.0   debit  272.0  87.0   \n",
       "590536         W  10444  225.0  150.0  mastercard  224.0   debit  204.0  87.0   \n",
       "590537         W  12037  595.0  150.0  mastercard  224.0   debit  231.0  87.0   \n",
       "590538         W   7826  481.0  150.0  mastercard  224.0   debit  387.0  87.0   \n",
       "590539         W  15066  170.0  150.0  mastercard  102.0  credit  299.0  87.0   \n",
       "\n",
       "       P_emaildomain M1 M2 M3  M4 M6  \n",
       "0          gmail.com  T  T  T  M2  T  \n",
       "1          gmail.com  T  T  T  M0  T  \n",
       "2        outlook.com  T  T  T  M0  F  \n",
       "3          yahoo.com  T  T  T  M0  F  \n",
       "4          gmail.com  T  T  T  M0  F  \n",
       "...              ... .. .. ..  .. ..  \n",
       "590535     gmail.com  T  T  T  M0  F  \n",
       "590536     gmail.com  T  F  F  M0  T  \n",
       "590537     gmail.com  T  F  F  M0  T  \n",
       "590538       aol.com  T  T  T  M0  T  \n",
       "590539     gmail.com  T  F  F  M0  T  \n",
       "\n",
       "[590540 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pp.df_train\n",
    "# lets find out which columns are object... \n",
    "list_col_object = []\n",
    "for val in pp.df_train.columns:\n",
    "    if pp.df_train[val].dtype=='O':\n",
    "        list_col_object.append(val)\n",
    "        \n",
    "pp.df_train[list_col_object]\n",
    "# for card2, nan was the most commonly seen value... so it imputed that...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in pp.df_train.columns:\n",
    "#     if pp.df_train[pp.df_train[val]=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_object = []\n",
    "for val in pp.df_train.columns:\n",
    "    if pp.df_train[val]:\n",
    "        list_col_object.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>2987123</td>\n",
       "      <td>0</td>\n",
       "      <td>88549</td>\n",
       "      <td>59.00</td>\n",
       "      <td>W</td>\n",
       "      <td>6550</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2987135</td>\n",
       "      <td>0</td>\n",
       "      <td>88671</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>W</td>\n",
       "      <td>2616</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>2987213</td>\n",
       "      <td>0</td>\n",
       "      <td>89867</td>\n",
       "      <td>499.95</td>\n",
       "      <td>W</td>\n",
       "      <td>6957</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>2987223</td>\n",
       "      <td>0</td>\n",
       "      <td>89948</td>\n",
       "      <td>54.00</td>\n",
       "      <td>W</td>\n",
       "      <td>2616</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589755</td>\n",
       "      <td>3576755</td>\n",
       "      <td>0</td>\n",
       "      <td>15794787</td>\n",
       "      <td>661.92</td>\n",
       "      <td>W</td>\n",
       "      <td>10476</td>\n",
       "      <td>nan</td>\n",
       "      <td>143.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589889</td>\n",
       "      <td>3576889</td>\n",
       "      <td>0</td>\n",
       "      <td>15797613</td>\n",
       "      <td>39.00</td>\n",
       "      <td>W</td>\n",
       "      <td>12219</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590005</td>\n",
       "      <td>3577005</td>\n",
       "      <td>0</td>\n",
       "      <td>15799999</td>\n",
       "      <td>40.00</td>\n",
       "      <td>S</td>\n",
       "      <td>14823</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590068</td>\n",
       "      <td>3577068</td>\n",
       "      <td>0</td>\n",
       "      <td>15801472</td>\n",
       "      <td>34.50</td>\n",
       "      <td>W</td>\n",
       "      <td>8187</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>3577535</td>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>W</td>\n",
       "      <td>6550</td>\n",
       "      <td>nan</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8933 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
       "0             2987000        0          86400           68.50         W   \n",
       "123           2987123        0          88549           59.00         W   \n",
       "135           2987135        0          88671         3000.00         W   \n",
       "213           2987213        0          89867          499.95         W   \n",
       "223           2987223        0          89948           54.00         W   \n",
       "...               ...      ...            ...             ...       ...   \n",
       "589755        3576755        0       15794787          661.92         W   \n",
       "589889        3576889        0       15797613           39.00         W   \n",
       "590005        3577005        0       15799999           40.00         S   \n",
       "590068        3577068        0       15801472           34.50         W   \n",
       "590535        3577535        0       15811047           49.00         W   \n",
       "\n",
       "        card1 card2  card3     card4  card5  ... V312       V313       V314  \\\n",
       "0       13926   nan  150.0  discover  142.0  ...  0.0   0.000000   0.000000   \n",
       "123      6550   nan  150.0      visa  226.0  ...  0.0   0.000000   0.000000   \n",
       "135      2616   nan  150.0  discover  102.0  ...  0.0   0.000000   0.000000   \n",
       "213      6957   nan  150.0      visa  166.0  ...  0.0   0.000000   0.000000   \n",
       "223      2616   nan  150.0  discover  102.0  ...  0.0   0.000000   0.000000   \n",
       "...       ...   ...    ...       ...    ...  ...  ...        ...        ...   \n",
       "589755  10476   nan  143.0      visa  226.0  ...  0.0   0.000000   0.000000   \n",
       "589889  12219   nan  150.0      visa  166.0  ...  0.0   0.000000   0.000000   \n",
       "590005  14823   nan  150.0      visa  166.0  ...  0.0   0.000000   0.000000   \n",
       "590068   8187   nan  150.0      visa  166.0  ...  0.0   0.000000   0.000000   \n",
       "590535   6550   nan  150.0      visa  226.0  ...  0.0  47.950001  47.950001   \n",
       "\n",
       "             V315  V316   V317  V318  V319  V320  V321  \n",
       "0        0.000000   0.0  117.0   0.0   0.0   0.0   0.0  \n",
       "123      0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "135      0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "213      0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "223      0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "...           ...   ...    ...   ...   ...   ...   ...  \n",
       "589755   0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "589889   0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "590005   0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "590068   0.000000   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "590535  47.950001   0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[8933 rows x 220 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pp.df_train[list_col_object].isnull())\n",
    "pp.df_train['card2'].unique()\n",
    "pp.df_train[df_train['card2']=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.sum(pp.df_train.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clean the data before thinking about applying PCA. \n",
    "# 1. Determine which columns are continuous, which are ranking.\n",
    "# 2. Determine which columns are bool (easy)\n",
    "# 3. Determine which columns are categorical, then impute with pandas (we dont know which columns means what\n",
    "#    so we cant assume True or better than False, etc.)\n",
    "# 4. After \n",
    "\n",
    "# 1. impute all objects columns with one hot encoding\n",
    "# 1.1 What's a categorical? \n",
    "# We know the V's are ranking.. we need to discern meaning, \n",
    "\n",
    "# 2. figure out if we should do pca next. we should do that next..\n",
    "# 3. then stand up the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(df_train['V14'])\n",
    "# sns.barplot(df_train['V196'])\n",
    "# we need to imput the mode here.. \n",
    "# df_train['V14'].mode()\n",
    "# df_train['V22'].unique()\n",
    "# for val in col_v:\n",
    "#     print(val)\n",
    "#     print(df_train[val].unique())\n",
    "# we ned to descern what is a 0 1 outcome then impute.\n",
    "\n",
    "# col = 'V290'\n",
    "# series_temp = df_train[col].fillna(df_train[col].mode()[0])\n",
    "# plt.hist(series_temp);\n",
    "# missing_val = np.sum(df_train[col].isnull())\n",
    "# print('Missing values: ' + str(missing_val))\n",
    "# print(\"REAL VALUE COUNTS: \")\n",
    "# df_train[col].value_counts().head()\n",
    "\n",
    "# col = 'card4'\n",
    "# series_temp = df_train[col].fillna(df_train[col].mode()[0])\n",
    "# plt.hist(series_temp);\n",
    "# df_train[col].value_counts()\n",
    "\n",
    "# col = 'D1'\n",
    "# series_temp = df_train[col].fillna(df_train[col].mean())\n",
    "# plt.hist(series_temp);\n",
    "# df_train['D1'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
