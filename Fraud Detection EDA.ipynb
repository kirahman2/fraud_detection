{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_raw = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 195 columns with null values.\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train.copy()\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                if (val == 'P_emaildomain'): # testing\n",
    "                    self.df_train[val] = self.df_train[val].fillna('missing')\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "    \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoded: addr1 unique 333\n",
      "label encoded: addr2 unique 75\n",
      "dummies encoded: ProductCD unique 5\n",
      "label encoded: P_emaildomain unique 60\n",
      "label encoded: card1 unique 13553\n",
      "label encoded: card2 unique 501\n",
      "label encoded: card3 unique 115\n",
      "dummies encoded: card4 unique 4\n",
      "label encoded: card5 unique 120\n",
      "dummies encoded: card6 unique 4\n",
      "dummies encoded: M1 unique 2\n",
      "dummies encoded: M2 unique 2\n",
      "dummies encoded: M3 unique 2\n",
      "dummies encoded: M4 unique 3\n",
      "dummies encoded: M6 unique 2\n",
      "new dataframe shape:(590540, 228)\n"
     ]
    }
   ],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FeatureEngineering():\n",
    "    '''create new features for columns without ordinal values'''\n",
    "    def __init__(self):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.df_raw = df_raw.copy()\n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        self.col = []\n",
    "        self.col_fe = []\n",
    "        self.df_new_feat = pd.DataFrame()\n",
    "        self.list_drop_col = []\n",
    "        self.str_list_col_fe = []\n",
    "        self.list_feat = []\n",
    "\n",
    "    def feature_testing(self, bool_drop_col, list_feat):\n",
    "        '''testing and scoring new potential features'''\n",
    "        print(\"While running feature_testing, do not run final_features.\")            \n",
    "        if list_feat:\n",
    "            for col in list_feat:\n",
    "                self.col_fe = col\n",
    "                bool_predict_proba = False\n",
    "                if col in df_features.columns:\n",
    "                    df_feat = self.create_test_feature(bool_drop_col, col)\n",
    "                    if df_feat_1000:\n",
    "                        df_feat = df_feat[0:1000]\n",
    "                    df_feat = df_feat.drop(self.list_drop_col[-1], axis=1)\n",
    "                    self._apply_df_transform(df_feat)\n",
    "                    model_lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "                    self._convert_list_to_string(list_feat)\n",
    "                    mod.create_df_score_model(model_lr)\n",
    "                else:\n",
    "                    print(\"\\nColumn\", col, \"does not exist in dataframe.\\n\")\n",
    "            self.col_fe = []\n",
    "        self.list_drop_col = []\n",
    "            \n",
    "    def final_features(self, bool_drop_col, list_feat):\n",
    "        '''creates final new features'''\n",
    "        print('after running final_features, run create_final_df.')\n",
    "        self.list_feat = list_feat\n",
    "        df_feat = self.create_feature(bool_drop_col, list_feat)  \n",
    "        if df_feat_1000:\n",
    "            df_feat = df_feat[0:1000]\n",
    "        for col in list_feat:\n",
    "            col_fe = self._append_col_lists(col)\n",
    "            df_feat[col] = self._fill_na(df_feat, col_fe)\n",
    "            self._concat_df_new_feat(df_feat, col_fe)\n",
    "        self._convert_list_to_string(list_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def _append_col_lists(self, col):\n",
    "        '''appending columns and new feature column names'''\n",
    "        col_fe = col + '_fe'\n",
    "        self.col.append(col)\n",
    "        self.col_fe.append(col_fe)\n",
    "        return col_fe\n",
    "\n",
    "    def _fill_na(self, df_feat, col_fe):\n",
    "        '''fill na values for new features'''\n",
    "        col_mode = df_feat[col_fe].mode()[0]\n",
    "        return df_feat[col_fe].fillna(col_mode)\n",
    "        \n",
    "    def _concat_df_new_feat(self, df_feat, col_fe):\n",
    "        '''adding new feauture columns to one dataframe'''  \n",
    "        df_temp = df_feat[col_fe]\n",
    "        self.df_new_feat = pd.concat([self.df_new_feat, df_temp], axis=1)\n",
    "    \n",
    "    def _convert_list_to_string(self, list_feat):\n",
    "        '''convert list to string to print later'''\n",
    "        str_temp = ''\n",
    "        for val in list_feat:\n",
    "            str_temp = str_temp + val + ' '\n",
    "        self.str_list_col_fe = str_temp\n",
    "\n",
    "    def create_final_df(self):\n",
    "        '''creates final dataframe after creating final_features'''\n",
    "        df_feat = pd.concat([df_features, self.df_new_feat], axis=1)\n",
    "        if df_feat_1000:\n",
    "            df_feat = pd.concat([df_features[0:1000], self.df_new_feat], axis=1)\n",
    "        print('dropping columns: ', self.list_drop_col)\n",
    "        df_feat = df_feat.drop(self.list_drop_col, axis=1)\n",
    "        self._apply_df_transform(df_feat)\n",
    "        self._create_tuning_df(df_feat)\n",
    "        self.list_drop_col = []\n",
    "        self._final_df_summary()\n",
    "        \n",
    "    def _shuffle_df(self, X, y):\n",
    "        '''shuffle dataframe'''\n",
    "        y = pd.Series(y)\n",
    "        X = pd.DataFrame(X)\n",
    "        df_temp = pd.concat([X, y], keys=['features','target'], axis=1)\n",
    "        df_temp = shuffle(df_temp).reset_index(drop=True)\n",
    "        X = df_temp.features\n",
    "        y = df_temp.target\n",
    "        return X, y\n",
    "        \n",
    "    def _final_df_summary(self):\n",
    "        print(\"final dataframe created.\")\n",
    "        print(\"To test a model use the mod.create_df_score_model(model_current)\")\n",
    "        print(\"method where, for example, model_current = LogisticRegression().\")\n",
    "\n",
    "    def _apply_df_transform(self, df_feat):\n",
    "        '''create dataframe, apply pca, apply smote'''\n",
    "        self.df_feat = df_feat\n",
    "        X, y = self._drop_col_id_target(df_feat)\n",
    "        X_train, X_test, y_train, y_test = self._split_dataframe(X, y)\n",
    "        X_train, y_train = self._sampling_techniques(X_train, y_train)\n",
    "        mod.X_train, mod.y_train = self._apply_pca(X_train, y_train)          # apply to train set\n",
    "        mod.X_test , mod.y_test = self._apply_pca(X_test, y_test) \n",
    "        \n",
    "    def _sampling_techniques(self, X_train, y_train):\n",
    "        '''applying resampling techniques and shuffle'''\n",
    "        X_train, y_train = self._apply_downsampling(X_train, y_train) # apply only train set\n",
    "        X_train, y_train = self._apply_smote(X_train, y_train)\n",
    "        X_train, y_train = self._shuffle_df(X_train, y_train)\n",
    "        return X_train, y_train\n",
    "    \n",
    "    def _create_tuning_df(self, df_feat):\n",
    "        '''whole dataframe used for model tuning'''\n",
    "        if bool_create_tuning_df:\n",
    "            print(\"creating tuning dataframe...\")\n",
    "            X, y = self._drop_col_id_target(df_feat)\n",
    "            X, y = self._apply_downsampling(X, y)\n",
    "            X, y = self._apply_smote(X, y)\n",
    "            mod.X_features, mod.y_target = self._shuffle_df(X, y)\n",
    "        else:\n",
    "            print('bool_create_tuning_df set to false.')\n",
    "\n",
    "    def _split_dataframe(self, X, y):\n",
    "        '''splitting dataframe into training and test set'''\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                            y, \n",
    "                                                            test_size=0.1, \n",
    "                                                            random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def _drop_col_id_target(self, df_feat):\n",
    "        '''dropping col id and target from features and creating target dataframe'''\n",
    "        X = df_feat.drop(col_target, axis=1)\n",
    "        X = X.drop(col_id, axis=1)\n",
    "        y = df_feat[col_target]\n",
    "        return X, y\n",
    "    \n",
    "    def _apply_downsampling(self, X, y):\n",
    "        '''down sampling majority class'''\n",
    "        if bool_apply_downsampling:\n",
    "            len_y_one = len(y[y==1])\n",
    "            X_col_names = X.columns\n",
    "            sampler = RandomUnderSampler(random_state=42, ratio={0:95000, 1:len_y_one})\n",
    "            X, y = sampler.fit_sample(X, y)\n",
    "            X = self._apply_col_names(X, X_col_names)\n",
    "            print(\"downsampling applied.\")\n",
    "            return X, y\n",
    "        else:\n",
    "            print(\"bool_apply_downsampling set to false.\")\n",
    "            return X, y\n",
    "            \n",
    "    def _apply_smote(self, X, y):\n",
    "        '''applying smote to split training set'''\n",
    "        if bool_apply_smote:\n",
    "            X_col_names = X.columns\n",
    "            sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "            X, y = sm.fit_sample(X, y)\n",
    "            X = self._apply_col_names(X, X_col_names)\n",
    "            print(\"smote applied.\")\n",
    "            return X, y\n",
    "        else:\n",
    "            print(\"bool_apply_smote set to false.\")\n",
    "            return X, y\n",
    "        \n",
    "    def _apply_col_names(self, X, X_col_names):\n",
    "        '''adding column names back to dataset'''\n",
    "        X = pd.DataFrame(X, columns=X_col_names)\n",
    "        return X\n",
    "    \n",
    "    def _apply_pca(self, X, y):\n",
    "        '''applying PCA and creating train and test set'''\n",
    "        if bool_apply_pca:\n",
    "            X = self._pca(X)\n",
    "            print('pca applied to training set, then test set.')\n",
    "            return X, y\n",
    "        else:\n",
    "            print(\"bool_apply_pca set to false.\")\n",
    "            return X, y\n",
    "\n",
    "    def _pca(self, X):\n",
    "        '''applying pca features dataframe'''\n",
    "        scaled_X = StandardScaler().fit_transform(X)\n",
    "        pca = PCA(n_components=250) #set value\n",
    "        pcomponents = pca.fit_transform(scaled_X)\n",
    "        X_pca = pd.DataFrame(data=pcomponents)\n",
    "        return X_pca\n",
    "        \n",
    "    def _convert_to_matrix(self):\n",
    "        '''converting X_test to matrix so columns match X_train'''\n",
    "        if bool_apply_downsampling or bool_apply_smote:\n",
    "            mod.X_test = pd.DataFrame(mod.X_test.values)\n",
    "            \n",
    "    def create_test_feature(self, bool_drop_col, col):\n",
    "        '''creates correllated ratio to target column'''\n",
    "        df_feat = df_features.copy()        \n",
    "        df_feat = self._calculate_target_perc(col, df_feat) \n",
    "        df_feat = self._map_col(col, df_feat)\n",
    "        df_feat = self._create_ratio(df_feat)\n",
    "        df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def create_feature(self, bool_drop_col, list_col):\n",
    "        '''creating new feature'''\n",
    "        df_feat = self.df_feat       \n",
    "        for col in list_col:\n",
    "            df_feat = self._check_col_exist(col, df_feat)\n",
    "            df_feat = self._calculate_target_perc(col, df_feat) \n",
    "            df_feat = self._map_col(col, df_feat)\n",
    "            df_feat = self._create_ratio(df_feat)\n",
    "            df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat \n",
    "    \n",
    "    def _check_col_exist(self, col, df_feat):\n",
    "        '''recreates original column from original dataframe'''\n",
    "        if col not in df_feat.columns:\n",
    "            df_feat[col] = df_raw[col]\n",
    "            df_feat[col] = self._fill_na(df_feat, col)\n",
    "            df_feat[col] = self._label_encode(df_feat, col)\n",
    "        return df_feat\n",
    "    \n",
    "    def _label_encode(self, df_feat, col):\n",
    "        '''label encoding columns pulled from original df_raw'''\n",
    "        le = LabelEncoder()\n",
    "        df_feat[col] = le.fit_transform(df_feat[col])\n",
    "        return df_feat[col]\n",
    "    \n",
    "    def _drop_column(self, bool_drop_col, col, df_feat):\n",
    "        '''dropping or keeping columns'''\n",
    "        if bool_drop_col:\n",
    "            if (col in df_features.columns):    \n",
    "                self.list_drop_col.append(col) \n",
    "        else:\n",
    "            print(\"keeping original feature\", col)\n",
    "        return df_feat\n",
    "\n",
    "    def aggregate_features(self, list_col, val_aggreg):\n",
    "        #del this method?\n",
    "        for col in list_col:\n",
    "            df_groupby = self.df_raw.groupby(col).mean()\n",
    "            dict_aggreg_col = df_groupby[[val_aggreg]].to_dict()\n",
    "            self.df_feat[col + '_fe'] = self.df_raw[col].map(dict_aggreg_col['TransactionAmt'])\n",
    "            col_mode = self.df_feat[col + '_fe'].mode()[0]\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col + '_fe'].fillna(col_mode)\n",
    "\n",
    "    def _calculate_target_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage for each column'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            list_perc = self._append_fraud_percentage(df_feat, col_val, val, list_perc)    \n",
    "        self._create_dict(col_val, list_perc, unique_col_values)\n",
    "        return df_feat\n",
    "    \n",
    "    def _append_fraud_percentage(self, df_feat, col_val, val, list_perc):\n",
    "        '''calculating fraud percentage and adding to list'''\n",
    "        fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                            & (df_feat[col_target]==1)].shape[0]\n",
    "        non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "        if (non_fraud_total==0):\n",
    "            list_perc.append(0)\n",
    "        else: \n",
    "            list_perc.append(fraud_total/non_fraud_total)\n",
    "        return list_perc\n",
    "\n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self, col, df_feat):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for val in dict_keys:\n",
    "            df_feat[col + '_fe'] = df_feat[col].map(self.dict_all_feat[val])\n",
    "            self.new_col.append(col + '_fe')\n",
    "        return df_feat\n",
    "            \n",
    "    def _create_ratio(self, df_feat):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "            col_min_val = df_feat[df_feat[val] > 0][val].min()\n",
    "            df_feat[val] = df_feat[val]/col_min_val\n",
    "        self.new_col = []\n",
    "        return df_feat\n",
    "    \n",
    "mod = Model()\n",
    "fe = FeatureEngineering()\n",
    "\n",
    "bool_predict_proba = False\n",
    "bool_thres_cost = False\n",
    "bool_apply_pca = False\n",
    "bool_apply_smote = True\n",
    "bool_apply_downsampling = True\n",
    "\n",
    "bool_create_tuning_df = True\n",
    "bool_drop_col = True\n",
    "df_feat_1000 = False\n",
    "fe.final_features(bool_drop_col, list_feat=['addr1','addr2','card2','card3','C1','P_emaildomain', \n",
    "                                            'card6', 'V294','V279','C14','V306','D2','D10'])\n",
    "bool_drop_col = False\n",
    "fe.final_features(bool_drop_col, list_feat=['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "fe.list_drop_col.append('C4')\n",
    "fe.create_final_df()\n",
    "\n",
    "\n",
    "# testing - lines below are for testing\n",
    "# df_feat_1000 = False\n",
    "# fe.final_features(bool_drop_col, list_feat=['addr1'])\n",
    "# fe.create_final_df()\n",
    "? \n",
    "# fe.feature_testing(bool_drop_col, list_feat=['addr1'])\n",
    "\n",
    "# NEXT, we need to fix our tuning dataframe. method, decide how we are going to tune our model, then \n",
    "# we also need to decide how this effects our results. Should we tune on the hold outset? If we applied\n",
    "# smote and undersampling, etc. how does this effect our outcome?\n",
    "# pca did not work properly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(df_features.columns)) #del\n",
    "# print(list(mod.X_features.columns))\n",
    "# print(list(mod.X_features.columns.shape))\n",
    "mod.X_features.P_emaildomain_fe.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_predict_proba = False\n",
    "model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "mod.X_train = pd.DataFrame(mod.X_train)\n",
    "mod.y_train = pd.DataFrame(mod.y_train)\n",
    "mod.X_test = pd.DataFrame(mod.X_test)\n",
    "mod.y_test = pd.DataFrame(mod.y_test)\n",
    "mod.X_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv')\n",
    "mod.y_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv')\n",
    "mod.X_test.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv')\n",
    "mod.y_test.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv')\n",
    "mod.X_features = pd.DataFrame(mod.X_features)\n",
    "mod.y_target = pd.DataFrame(mod.y_target)\n",
    "mod.X_features.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv')\n",
    "mod.y_target.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "mod.X_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.y_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.X_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.y_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "# mod.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0', axis=1)\n",
    "# mod.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0', axis=1)\n",
    "# mod.X_features.info(memory_usage='deep')\n",
    "# mod.y_target.info(memory_usage='deep')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = True\n",
    "# model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing LogisticRegression\n",
    "# bool_predict_proba = False\n",
    "# model_current =  LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=False,\n",
    "#                                    intercept_scaling=0.1, l1_ratio=1e-06, max_iter=150,\n",
    "#                                    multi_class='multinomial', n_jobs=-1, penalty='none',\n",
    "#                                    random_state=42, solver='lbfgs', tol=1e-05, verbose=0,\n",
    "#                                    warm_start=False)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing LogisticRegression\n",
    "bool_predict_proba = True\n",
    "model_current =  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                                   intercept_scaling=0.1, l1_ratio=0.01, max_iter=100,\n",
    "                                   multi_class='auto', n_jobs=-1, penalty='none',\n",
    "                                   random_state=42, solver='newton-cg', tol=1e-06, verbose=0,\n",
    "                                   warm_start=False)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TESTING XGBClassifier n_estimators=150\n",
    "bool_predict_proba = False\n",
    "model_current = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
    "                              colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
    "                              learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
    "                              min_child_weight=1, missing=None, n_estimators=150, n_jobs=-1,\n",
    "                              nthread=None, objective='binary:logistic', random_state=42,\n",
    "                              reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
    "                              silent=None, subsample=0.5, verbosity=1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing XGBClassifier 200 n_estimators\n",
    "model_current = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
    "                              colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
    "                              learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
    "                              min_child_weight=1, missing=None, n_estimators=200, n_jobs=-1,\n",
    "                              nthread=None, objective='binary:logistic', random_state=42,\n",
    "                              reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
    "                              silent=None, subsample=0.5, verbosity=1)\n",
    "mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RETUNE testing RandomForestClassifier\n",
    "model_current = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                                       criterion='gini', max_depth=5, max_features='auto',\n",
    "                                       max_leaf_nodes=9,\n",
    "                                       min_impurity_decrease=0.1, min_impurity_split=None,\n",
    "                                       min_samples_leaf=4, min_samples_split=3,\n",
    "                                       min_weight_fraction_leaf=0.3, n_estimators=100,\n",
    "                                       n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
    "                                       warm_start=False)\n",
    "mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing RandomForestClassifier n_estimators=150\n",
    "model_current = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                                       criterion='gini', max_depth=5, max_features='auto',\n",
    "                                       max_leaf_nodes=9,\n",
    "                                       min_impurity_decrease=0.1, min_impurity_split=None,\n",
    "                                       min_samples_leaf=4, min_samples_split=3,\n",
    "                                       min_weight_fraction_leaf=0.3, n_estimators=150,\n",
    "                                       n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
    "                                       warm_start=False)\n",
    "mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing DecisionTreeClassifier max_depth=11\n",
    "model_current = DecisionTreeClassifier(class_weight='balanced',\n",
    "                                       criterion='entropy', max_depth=11, max_features=None,\n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                       min_impurity_split=None, min_samples_leaf=9,\n",
    "                                       min_samples_split=5, min_weight_fraction_leaf=0,\n",
    "                                       presort='auto', random_state=42, splitter='best')\n",
    "\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testing DecisionTreeClassifier max_depth=13\n",
    "model_current = DecisionTreeClassifier(class_weight='balanced',\n",
    "                                       criterion='entropy', max_depth=13, max_features=None,\n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                       min_impurity_split=None, min_samples_leaf=9,\n",
    "                                       min_samples_split=5, min_weight_fraction_leaf=0,\n",
    "                                       presort='auto', random_state=42, splitter='best')\n",
    "\n",
    "mod.create_df_score_model(model_current)\n",
    "\n",
    "# NEXT, Create read me and presentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base score LogisticRegression threshold\n",
    "bool_predict_proba = True\n",
    "model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)\n",
    "bool_predict_proba = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model LogisticRegression\n",
    "model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base DecisionTreeClassifier\n",
    "bool_predict_proba = False\n",
    "model_current = DecisionTreeClassifier(random_state=42)\n",
    "mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE RandomForestClassifier - tuned\n",
    "bool_predict_proba = True\n",
    "model_current = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                       n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
    "                       warm_start=False)\n",
    "mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE RandomForestClassifier - base\n",
    "bool_predict_proba = True\n",
    "model_current = RandomForestClassifier(n_jobs=-1, random_state=42, verbose=1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base XGBClassifier threshold\n",
    "bool_predict_proba = True\n",
    "model_current = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base XGBClassifier\n",
    "bool_predict_proba = False\n",
    "model_current = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba CatBoostClassifier\n",
    "bool_predict_proba = True\n",
    "model_current = CatBoostClassifier(random_state=42, verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.X_train = pd.DataFrame()\n",
    "        self.y_train = pd.DataFrame()\n",
    "        self.X_test = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.X_features = pd.DataFrame()\n",
    "        self.y_target = pd.DataFrame()\n",
    "        self.dict_results = {'index':[0], 'threshold':[], 'roc_auc_score':[], \n",
    "                             'total_cost':[], 'fn':[], 'fp':[]}\n",
    "        self.X_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.y_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.X_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.y_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0',axis=1)\n",
    "        \n",
    "    def create_df_score_model(self, model):\n",
    "        '''scores model'''\n",
    "        print(\"Fitting model:\\n\", model)\n",
    "        y_pred, elapsed_time, model = self.add_model(model) \n",
    "        df_scores, df_temp, y_pred = self._score_model(y_pred, elapsed_time)\n",
    "        self._save_results(df_scores, df_temp, y_pred)\n",
    "        self._feature_importance(model)\n",
    "        fe.col_fe = []\n",
    "        \n",
    "    def add_model(self, model):        \n",
    "        '''fitting model and calculating time elapsed'''\n",
    "        start_time = time.time()\n",
    "        model.fit(mod.X_train, mod.y_train)\n",
    "        y_pred, model = self._predict(model)\n",
    "        bool_predict_proba = False\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        return y_pred, elapsed_time, model\n",
    "    \n",
    "    def _predict(self, model):\n",
    "        '''make prediction'''\n",
    "        if bool_predict_proba:\n",
    "            print(model)\n",
    "            y_pred, model = self._predict_proba(model)\n",
    "            y_pred = self._predict_proba_threshold(y_pred)\n",
    "            return y_pred, model\n",
    "        else:\n",
    "            y_pred = model.predict(mod.X_test)\n",
    "            return y_pred, model\n",
    "        \n",
    "    def _predict_proba(self, model):\n",
    "        try:\n",
    "            y_pred_prob = model.predict_proba(mod.X_test)\n",
    "            return y_pred_prob, model\n",
    "        except:\n",
    "            print(\"Model does not have predict_proba attribute.\")\n",
    "\n",
    "    def _predict_proba_threshold(self, y_pred):\n",
    "        '''create prediction for each threshold'''\n",
    "        df_results = pd.DataFrame()\n",
    "        list_threshold = [.05, .1, .15, .2, .25, .3, \n",
    "                          .35, .4, .45, .5, .55, .6]\n",
    "        for threshold in list_threshold:\n",
    "            df_temp = self._compute_thres_df(y_pred, threshold)\n",
    "            df_results = pd.concat([df_results, df_temp], axis=0)\n",
    "        df_results = df_results.drop('index', axis=1).reset_index(drop=True)\n",
    "        val_thres_cost, val_thres_auc = self._calc_and_plot_results(df_results)\n",
    "        y_pred_class = self._y_pred_class(y_pred, val_thres_cost, val_thres_auc)\n",
    "        print('threshold results dataframe:\\n', df_results)\n",
    "        return y_pred_class\n",
    "        \n",
    "    def _compute_thres_df(self, y_pred_prob, threshold):\n",
    "        '''compute the values for each threshold'''\n",
    "        y_pred_class = binarize(y_pred_prob, threshold)[:,1]\n",
    "        df_conf_matrix = self._compute_conf_matrix(y_pred_class)\n",
    "        df_dict_results = self._compute_results(df_conf_matrix, y_pred_class, threshold)\n",
    "        return df_dict_results\n",
    "    \n",
    "    def _compute_conf_matrix(self, y_pred_class):\n",
    "        '''compute the confusion matrix for the current threshold'''\n",
    "        conf_matr = confusion_matrix(self.y_test, y_pred_class)\n",
    "        df_conf_matrix = pd.DataFrame(conf_matr)\n",
    "        return df_conf_matrix\n",
    "    \n",
    "    def _compute_results(self, df_conf_matrix, y_pred_class, threshold):\n",
    "        '''compute results for each threshold and save to dictionary'''\n",
    "        val_fn = df_conf_matrix[0][1]\n",
    "        val_fp = df_conf_matrix[1][0]\n",
    "        val_cost = 3000*val_fn + 20*val_fp\n",
    "        val_score = roc_auc_score(self.y_test, y_pred_class)\n",
    "        self.dict_results.update([('threshold', threshold)])\n",
    "        self.dict_results.update([('roc_auc_score', val_score)])\n",
    "        self.dict_results.update([('total_cost', val_cost)])\n",
    "        self.dict_results.update([('fn', val_fn)])\n",
    "        self.dict_results.update([('fp', val_fp)])\n",
    "        df_dict_results = pd.DataFrame.from_dict(self.dict_results)\n",
    "        return df_dict_results\n",
    "    \n",
    "    def _calc_and_plot_results(self, df_results):\n",
    "        '''plot results and calculate best threshold for auc and cost'''\n",
    "        self._plot_thres_auc(df_results)\n",
    "        self._plot_thres_score(df_results)\n",
    "        val_thres_cost = self._calc_best_thres_cost(df_results)\n",
    "        val_thres_auc = self._calc_best_thres_auc(df_results)\n",
    "        return val_thres_cost, val_thres_auc\n",
    "        \n",
    "    def _plot_thres_auc(self, df_results):\n",
    "        '''plot auc roc score by threshold'''\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.title(\"Threshold by Auc Roc Score\", fontsize=14)\n",
    "        plt.xlabel('Threshold', fontsize=13)\n",
    "        plt.ylabel(\"Auc Roc Score\", fontsize=13)\n",
    "        plt.plot('threshold', 'roc_auc_score', data=df_results)\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_thres_score(self, df_results):\n",
    "        '''plot cost by threshold'''\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.title(\"Threshold by Cost\", fontsize=14)\n",
    "        plt.xlabel('Threshold', fontsize=13)\n",
    "        plt.ylabel(\"Cost in Dollars\", fontsize=13)\n",
    "        plt.plot('threshold', 'total_cost', data=df_results)\n",
    "        plt.show()\n",
    "    \n",
    "    def _calc_best_thres_cost(self, df_results):\n",
    "        '''calculate the best threshold by cost'''\n",
    "        val_min_cost = df_results.total_cost.min()\n",
    "        index_min_cost = df_results[df_results.total_cost==val_min_cost].index[0]\n",
    "        val_threshold_min_cost = df_results.loc[index_min_cost,:].threshold.item()\n",
    "        print(\"Best threshold by cost:\", val_threshold_min_cost)\n",
    "        return val_threshold_min_cost\n",
    "\n",
    "    def _calc_best_thres_auc(self, df_results):\n",
    "        '''calculate the best threshold by highest auc roc score'''\n",
    "        val_max_roc_auc = df_results.roc_auc_score.max()\n",
    "        index_max_roc_auc = df_results[df_results.roc_auc_score==val_max_roc_auc].index[0]\n",
    "        val_threshold_roc_auc = df_results.loc[index_max_roc_auc,:].threshold.item()\n",
    "        print(\"Best threshold by roc auc score:\", val_threshold_roc_auc, '\\n')\n",
    "        return val_threshold_roc_auc\n",
    "    \n",
    "    def _y_pred_class(self, y_pred_prob, val_thres_cost, val_thres_auc):\n",
    "        '''calculate y_pred_class depending on if we want cost or auc threshold'''\n",
    "        if bool_thres_cost:\n",
    "            y_pred_class = binarize(y_pred_prob, val_thres_cost)[:,1]\n",
    "            return y_pred_class\n",
    "        else:\n",
    "            y_pred_class = binarize(y_pred_prob, val_thres_auc)[:,1]\n",
    "            return y_pred_class\n",
    "\n",
    "    def _score_model(self, y_pred, elapsed_time):      \n",
    "        '''creating dataframe with score results'''\n",
    "        col_recall, col_precision, col_time, col_auc = self._calc_scores(y_pred, \n",
    "                                                                         elapsed_time) \n",
    "        df_conf_matrix = self._confusion_matrix(y_pred)\n",
    "        df_temp = pd.concat([col_auc, col_recall, col_precision, \n",
    "                             df_conf_matrix, col_time], axis=1)\n",
    "        if fe.col_fe:\n",
    "            df_temp = self._concat_new_feat(df_temp)\n",
    "        df_scores = self._read_create_score_file(df_temp)\n",
    "        return df_scores, df_temp, y_pred\n",
    "\n",
    "    def _calc_scores(self, y_pred, elapsed_time):\n",
    "        '''calculating recall, precision and elapsed time'''\n",
    "        col_auc = pd.Series(roc_auc_score(mod.y_test, y_pred), name='roc_auc_score')\n",
    "        col_recall = pd.Series(recall_score(mod.y_test, y_pred), name='recall')\n",
    "        col_precision = pd.Series(precision_score(mod.y_test, y_pred), name='precision')\n",
    "        col_time = pd.Series(elapsed_time, name='time_elapsed (min)')\n",
    "        print('\\nroc auc score:', roc_auc_score(mod.y_test, y_pred), '\\n')\n",
    "        return col_recall, col_precision, col_time, col_auc\n",
    "    \n",
    "    def _confusion_matrix(self, y_pred):\n",
    "        '''creating confusion matrix dataframe'''\n",
    "        df_conf_matrix = pd.DataFrame(confusion_matrix(mod.y_test, y_pred))\n",
    "        val_tp = pd.Series(df_conf_matrix[0][0], name='tp')\n",
    "        val_fn = pd.Series(df_conf_matrix[0][1], name='fn')\n",
    "        val_fp = pd.Series(df_conf_matrix[1][0], name='fp')\n",
    "        val_tn = pd.Series(df_conf_matrix[1][1], name='tn')\n",
    "        return pd.concat([val_fn, val_fp, val_tp, val_tn], axis=1)\n",
    "\n",
    "    def _concat_new_feat(self, df_temp):\n",
    "        '''concatenate scoring results'''        \n",
    "        print(\"\\nThe following new features have been created:\", fe.col_fe, '\\n')\n",
    "        if len(fe.col_fe) > 1: \n",
    "            fe.col_fe = \"model score\"\n",
    "        col_fe = pd.Series(fe.col_fe, name='feat_tested')\n",
    "        return pd.concat([col_fe, df_temp], axis=1)\n",
    "    \n",
    "    def _read_create_score_file(self, df_temp):\n",
    "        '''reading or creating df_scores file'''\n",
    "        try: \n",
    "            df_scores = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "            df_scores = df_scores.drop('Unnamed: 0', axis=1)\n",
    "        except:\n",
    "            print(\"\\nCreating df_scores.csv file.\") \n",
    "            df_scores = df_temp\n",
    "        return df_scores\n",
    "            \n",
    "    def _save_results(self, df_scores, df_temp, y_pred):\n",
    "        '''printing scores for new features'''            \n",
    "        df_scores = pd.concat([df_scores, df_temp], axis=0)\n",
    "        df_scores.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "        classif_report = classification_report(mod.y_test, y_pred)\n",
    "        self._print_summary(classif_report, df_scores)\n",
    "        self._save_summary(classif_report)\n",
    "\n",
    "    def _print_summary(self, classif_report, df_scores):\n",
    "        '''print last 5 rows of previous score results'''\n",
    "        print(classif_report)\n",
    "        print('\\ndf_scores:\\n\\n', df_scores.tail(5))\n",
    "    \n",
    "    def _save_summary(self, classif_report):\n",
    "        '''save score result summary to text file'''\n",
    "        file_summary = open('/Users/krahman/work/fraud_detection/saved_files/df_scores_summary.txt', \"a\")\n",
    "        file_summary.write('New features created from: ' \n",
    "                           + fe.str_list_col_fe \n",
    "                           + '\\n')\n",
    "        file_summary.write(classif_report)\n",
    "        file_summary.close()\n",
    "        \n",
    "    def _feature_importance(self, model):\n",
    "        '''create feature importance dataframe and bar plot'''\n",
    "        try:\n",
    "            self._feat_import_method(model)\n",
    "        except:\n",
    "            print(\"\\nmodel does not have _feature_importance attribute.\")\n",
    "    \n",
    "    def _feat_import_method(self, model):\n",
    "        '''run feature importance methods'''\n",
    "        df_feat_rank = self._feat_import_create_df(model)\n",
    "        df_feat_rank = self._feat_import_create_plot(df_feat_rank)\n",
    "        \n",
    "    def _feat_import_create_df(self, model):\n",
    "        '''creating dataframe of important features'''\n",
    "        col_name = pd.Series(mod.X_train.columns, name='col')\n",
    "        col_feat_rank = pd.Series(model.feature_importances_, \n",
    "                                  name='feat_rank')\n",
    "        df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1)\n",
    "        df_feat_rank = df_feat_rank.sort_values('feat_rank', ascending=False)\n",
    "        return df_feat_rank.reset_index(drop=True)\n",
    "    \n",
    "    def _feat_import_create_plot(self, df_feat_rank):\n",
    "        '''create feature importance bar plot'''\n",
    "        plt.figure(figsize=(5,6))\n",
    "        sns.barplot(df_feat_rank.feat_rank[0:10],\n",
    "                    df_feat_rank.col[0:10],\n",
    "                    palette='Blues_d')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "        print(df_feat_rank[0:20])\n",
    "        \n",
    "mod = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations=300\n",
    "iterations = [100,200,300]\n",
    "for val in iterations:\n",
    "    model_current = CatBoostClassifier(random_state=42, iterations=val, verbose=0, \n",
    "                                       max_depth=9)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging_temperature=1e-3, 0.8849\n",
    "# bagging_temperature, n_estimators,  \n",
    "bagging_temperature = [1e-1,1e-2,1e-3]\n",
    "for val in iterations:\n",
    "    model_current = CatBoostClassifier(random_state=42, bagging_temperature=val, verbose=0)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap_type = 'Bernoulli' 0.886326\n",
    "bootstrap_type = ['Bayesian', 'Bernoulli', 'MVS', None]\n",
    "for val in bootstrap_type:\n",
    "#     print(val+'\\n')\n",
    "    model_current = CatBoostClassifier(random_state=42, bootstrap_type=val, verbose=0)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting_type = 'Plain' 0.884913\n",
    "boosting_type = ['Ordered', 'Plain']\n",
    "for val in boosting_type:\n",
    "    print(val+'\\n')\n",
    "    model_current = CatBoostClassifier(random_state=42, boosting_type=val, verbose=0)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grow_policy = ['SymmetricTree', 'Depthwise']\n",
    "# for val in grow_policy:\n",
    "#     print(val+'\\n')\n",
    "#     model_current = CatBoostClassifier(random_state=42, grow_policy=val, verbose=0)\n",
    "#     mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_child_samples = [2,3,4]\n",
    "# for val in min_child_samples:\n",
    "#     print(val)\n",
    "#     model_current = CatBoostClassifier(random_state=42, min_child_samples=val, verbose=0)\n",
    "#     mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_leaves = [2,3,4]\n",
    "# for val in max_leaves:\n",
    "#     print(val)\n",
    "#     model_current = CatBoostClassifier(random_state=42, max_leaves=val, verbose=0)\n",
    "#     mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsample_bylevel = .1 best? 0.884395\n",
    "colsample_bylevel = [1e-1,1e-2,1e-3,.2,.5,.9]\n",
    "colsample_bylevel = [.1,.2,.3]\n",
    "for val in colsample_bylevel:\n",
    "    print(val)\n",
    "    model_current = CatBoostClassifier(random_state=42, colsample_bylevel=val, verbose=0)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RERUN when you have a moment. \n",
    "# subsample = .4\n",
    "# subsample = [1e-1,1e-2,1e-3]\n",
    "# subsample = [.1,.2,.3,.4]\n",
    "subsample = [.1,.2,.3,.4,.5,.6,.7,.8,.9,.99]\n",
    "for val in subsample:\n",
    "    print(val)\n",
    "    model_current = CatBoostClassifier(random_state=42, subsample=val, verbose=0)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 10\n",
    "max_depth = [9,10,11,12,13]\n",
    "for val in max_depth:\n",
    "    model_current = CatBoostClassifier(random_state=42, max_depth=val, verbose=0)\n",
    "    mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base CatBoostClassifier\n",
    "bool_predict_proba = True\n",
    "model_current = CatBoostClassifier(\n",
    "                                   iterations=300, \n",
    "                                   bagging_temperature=1e-3, \n",
    "                                   bootstrap_type='Bayesian', \n",
    "                                   boosting_type='Plain',\n",
    "                                   colsample_bylevel=.1, \n",
    "                                   subsample=.4,  \n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "                                   boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.3, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "                                   boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.4, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "                                   boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.5, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "                                   boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.99, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "                                   boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.9, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostClassifier not tuned\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "#                                    boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "#                                    colsample_bylevel=.6, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "#                                    max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostClassifier TUNED\n",
    "model_current = CatBoostClassifier(\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)\n",
    "\n",
    "# Does plain cut training time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "#                                    boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.7, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no bagging, baysian\n",
    "\n",
    "model_current = CatBoostClassifier(\n",
    "#                                    bootstrap_type='Bernoulli', R: 0.904748\n",
    "    \n",
    "                                   boosting_type='Plain', #R:0.904748, 5.98min, \n",
    "                                   colsample_bylevel=.8, #keep, reduces training time\n",
    "#                                    subsample=.4, #0.905090 7.49\n",
    "                                   max_depth=10,\n",
    "                                   random_state=42, \n",
    "                                   verbose=0)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Tuning XGBClassifier READY ###\n",
    "print('tuning xgbc')\n",
    "xgbc = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "# learning_rate = [0,.1,.3,.5,.7,.9]\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "subsample = [.1,.3,.5,.7]\n",
    "colsample_bytree = [.1,.3,.5,.7]\n",
    "colsample_bylevel = [0,.1,.3,.5,.7,.9,1]\n",
    "colsample_bynode = [.1,.3,.5,.7]\n",
    "reg_alpha = [0,1,3,5,7]\n",
    "reg_lambda = [1,3,5,7]\n",
    "scale_pos_weight = [1,3,5,7]\n",
    "base_score = [.1,.2,.3,.4,.5]\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, \n",
    "#                        learning_rate=learning_rate, \n",
    "                       booster=booster, \n",
    "                       subsample=subsample, \n",
    "                       colsample_bytree=colsample_bytree, colsample_bylevel=colsample_bylevel, \n",
    "                       colsample_bynode=colsample_bynode, reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "                       scale_pos_weight=scale_pos_weight,\n",
    "                       base_score=base_score\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(xgbc, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best booster:', best_model.best_estimator_.get_params()['booster'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print('Best colsample_bytree:', best_model.best_estimator_.get_params()['colsample_bytree'])\n",
    "print('Best colsample_bylevel:', best_model.best_estimator_.get_params()['colsample_bylevel'])\n",
    "print('Best colsample_bynode:', best_model.best_estimator_.get_params()['colsample_bynode'])\n",
    "print('Best reg_alpha:', best_model.best_estimator_.get_params()['reg_alpha'])\n",
    "print('Best reg_lambda:', best_model.best_estimator_.get_params()['reg_lambda'])\n",
    "print('Best scale_pos_weight:', best_model.best_estimator_.get_params()['scale_pos_weight'])\n",
    "print('Best base_score:', best_model.best_estimator_.get_params()['base_score'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### testing manual tuning ######\n",
    "### manual xbgc tuning\n",
    "max_depth = [3,5,7,9,11,13,15]\n",
    "# max_depth = [1,3,5]\n",
    "list_time_elapsed = []\n",
    "list_roc_auc_score = []\n",
    "for val in max_depth:\n",
    "    model_xgbc = XGBClassifier(max_depth=val, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_xgbc.fit(mod.X_train_test, mod.y_train)\n",
    "    y_pred_xgbc = model_xgbc.predict(mod.X_test)\n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    \n",
    "    score_roc_auc = roc_auc_score(mod.y_test, y_pred_xgbc)\n",
    "\n",
    "    list_time_elapsed.append(elapsed_time)\n",
    "    list_roc_auc_score.append(score_roc_auc)\n",
    "    print('max depth: ', val)\n",
    "    print(confusion_matrix(mod.y_test, y_pred_xgbc))\n",
    "\n",
    "col_time_elapsed = pd.Series(list_time_elapsed)\n",
    "col_roc_score = pd.Series(list_roc_auc_score)\n",
    "col_max_depth = pd.Series(max_depth)\n",
    "df_results_xgbc = pd.concat([col_max_depth, col_roc_score,col_time_elapsed], \n",
    "                            keys=['max_depth', 'roc_auc_score', 'time_elap'], \n",
    "                            axis=1)\n",
    "print(df_results_xgbc)\n",
    "\n",
    "sns.lineplot(x='max_depth', y='roc_auc_score', data=df_results_xgbc)\n",
    "plt.title(\"XGBC manual tuning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Tuning RandomForestClassifier READY ####\n",
    "rfc = RandomForestClassifier(oob_score=False, n_jobs=1, random_state=42, verbose=1)\n",
    "\n",
    "n_estimators = [50,75,100,125,150,200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [3,5,7,9,11,13,15]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8,10]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_leaf_nodes = [2,3,5,7,9,None]\n",
    "min_impurity_decrease = [0,.1,.3,.5,.7,.9]\n",
    "\n",
    "hyperparameters = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split,\n",
    "                       min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, max_leaf_nodes=max_leaf_nodes,\n",
    "                       min_impurity_decrease=min_impurity_decrease\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(rfc, hyperparameters, random_state=42, cv=5, verbose=5, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best max_leaf_nodes:', best_model.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print('Best min_impurity_decrease:', best_model.best_estimator_.get_params()['min_impurity_decrease'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### LR Tuning ####\n",
    "lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet','none']\n",
    "tol = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "C = [1e-1,.2,.3,.5,.7,1]\n",
    "fit_intercept = [True,False]\n",
    "intercept_scaling = [1,.1,.01,.001]\n",
    "class_weight = ['balanced', None]\n",
    "solver = ['newton-cg', 'lbfgs', 'sag']#, 'liblinear','saga']\n",
    "max_iter = [50,75,100,150,200]\n",
    "multi_class = ['auto', 'ovr', 'multinomial']\n",
    "l1_ratio = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "\n",
    "\n",
    "hyperparameters = dict(penalty=penalty, \n",
    "#                        tol=tol, \n",
    "#                        C=C, \n",
    "#                        fit_intercept=fit_intercept,\n",
    "                       intercept_scaling=intercept_scaling, \n",
    "                       class_weight=class_weight,\n",
    "                       solver=solver, \n",
    "#                        max_iter=max_iter\n",
    "                       multi_class=multi_class, \n",
    "                       l1_ratio=l1_ratio\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(lr, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "# best_model = clf.fit(mod.X_features_test, mod.y_target_test) #testing\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best tol:', best_model.best_estimator_.get_params()['tol'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best fit_intercept:', best_model.best_estimator_.get_params()['fit_intercept'])\n",
    "print('Best intercept_scaling:', best_model.best_estimator_.get_params()['intercept_scaling'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best solver:', best_model.best_estimator_.get_params()['solver'])\n",
    "print('Best max_iter:', best_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best multi_class:', best_model.best_estimator_.get_params()['multi_class'])\n",
    "print('Best l1_ratio:', best_model.best_estimator_.get_params()['l1_ratio'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Tuning DTC READY ####\n",
    "dt = DecisionTreeClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [3,5,7,9,11]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,3,5,7,9]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "class_weight = ['balanced', None]\n",
    "\n",
    "hyperparameters = dict(criterion=criterion, splitter=splitter, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                       min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, class_weight=class_weight\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(dt, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "# best_model = clf.fit(mod.X_features_test, mod.y_target_test) #testing\n",
    " \n",
    "# best hyper parameters\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best splitter:', best_model.best_estimator_.get_params()['splitter'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning CatBoost READY ###\n",
    "# Tune learning rate manually.\n",
    "cbc = CatBoostClassifier(random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "learning_rate = [.1,.3,.5,.7,.9]\n",
    "# bagging_temperature = []\n",
    "subsample = [1,3,5,7]\n",
    "n_estimators = [50,75,100,150]\n",
    "depth = [2,4,6,8,10]\n",
    "grow_policy = ['SymmetricTree', 'Depthwise', 'Lossguide']\n",
    "\n",
    "\n",
    "hyperparameters = dict(\n",
    "#                         max_depth=max_depth, \n",
    "#                        learning_rate=learning_rate, \n",
    "#                        n_estimators=n_estimators,\n",
    "                       subsample=subsample,\n",
    "#                        depth=depth,\n",
    "                       grow_policy=grow_policy\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(cbc, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_read = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "df_temp_read = df_temp_read.drop('Unnamed: 0', axis=1)\n",
    "# df_temp_read[len(df_temp_read)-40:]\n",
    "df_temp_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
