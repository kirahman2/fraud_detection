{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/Users/krahman/work/fraud_detection/data/train_identity.csv')\n",
    "# merging dataframes \n",
    "df_raw = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning columns to specific lists (cat, num, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 220\n"
     ]
    }
   ],
   "source": [
    "# dropping columns with more than 50% missing data\n",
    "length_df = df_train.shape[0]/2\n",
    "list_temp = []\n",
    "for val in df_train.columns:\n",
    "    if np.sum(df_train[val].isnull()) > length_df:\n",
    "        list_temp.append(val)   \n",
    "df_train = df_train.drop(list_temp, axis=1)\n",
    "\n",
    "###################################\n",
    "# c is num, ex, how many addresses associated with card\n",
    "col_c = [c for c in df_train.columns if c.startswith('C') and (len(c)==2 or len(c)==3)]\n",
    "# d is num, time/days between transactions\n",
    "col_d = [d for d in df_train.columns if d.startswith('D') and (len(d)==2 or len(d)==3)]\n",
    "# m is date of transaction\n",
    "col_m = [m for m in df_train.columns if m.startswith('M') and (len(m)==2 or len(m)==3)]\n",
    "# v is num, features created by vesta such as ranking, counting. entity relationships, etc. \n",
    "col_v = [v for v in df_train.columns if v.startswith('V') and (len(v)==2 or len(v)==3 or len(v)==4)]\n",
    "# i is identity information like network and digital signature associated with transaction\n",
    "col_i = [i for i in df_train.columns if i.startswith('id_') and len(i)==5]\n",
    "# ca is cat, card information such as card type, etc. \n",
    "col_card = [ca for ca in df_train.columns if ca.startswith('card')]\n",
    "\n",
    "# column id and target\n",
    "col_id = ['TransactionID']\n",
    "col_target = 'isFraud'\n",
    "\n",
    "# converting categorical columns with numerical values to string types.\n",
    "col_cat_to_obj = ['addr1','addr2','card1','card2', 'card3', 'card5']\n",
    "for val in col_cat_to_obj:\n",
    "    df_train[val] = df_train[val].astype(str)\n",
    "\n",
    "# categorical columns\n",
    "col_cat = ['addr1','addr2','ProductCD',\"P_emaildomain\"] + col_card + col_m\n",
    "\n",
    "# C counter, D is time elapsed between transactions, V feature engineered variables by firm\n",
    "col_num = ['TransactionAmt'] + col_c + col_d + col_v \n",
    "col_num.append(col_target)\n",
    "\n",
    "# figure out how to handle this. What do these dates mean? Do certain dates have more fraud occurences?\n",
    "col_date = ['TransactionDT'] \n",
    "\n",
    "# confirming all columns are accounted for\n",
    "print('Total columns: ' + str(len(col_cat + col_num + col_date + col_id + col_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        '''initialize variables and column names for null dataframe'''\n",
    "        self.df_train = df_train.copy()\n",
    "        self.list_col = []\n",
    "        self.list_total = []\n",
    "        self.dict_unique = {}\n",
    "        self.list_datatype = []\n",
    "        self.list_unique_val = []\n",
    "        self.list_mode_count = []\n",
    "        self.list_mode_value = []\n",
    "        self.list_mode_count_perc = []\n",
    "        self.list_unique_total = []\n",
    "        self.list_unique_first_10 = []\n",
    "        self.column_names = ['col_name', 'total_null', 'datatype', 'total_unique',\n",
    "                             'mode_value', 'mode_count', 'mode_percentage']\n",
    "\n",
    "    def missing_values(self):\n",
    "        '''check for null values and add to null dataframe if more than 0 nulls exist'''\n",
    "        for val in df_train.columns:\n",
    "            total_null = np.sum(df_train[val].isnull())\n",
    "            if total_null > 0:\n",
    "                self.list_col.append(val)\n",
    "                self.list_total.append(total_null)\n",
    "                self.list_datatype.append(df_train[val].dtype)\n",
    "                self.list_unique_total.append(len(df_train[val].unique()))\n",
    "                self.list_unique_val.append(df_train[val].unique())\n",
    "                self.list_mode_value.append(df_train[val].mode()[0])\n",
    "                val_counts = max(df_train[val].value_counts())\n",
    "                self.list_mode_count.append(val_counts)\n",
    "                self.list_mode_count_perc.append(val_counts/len(df_train))\n",
    "                val_unique = df_train[val].unique()\n",
    "                self._create_dict(val_unique, df_train, val)\n",
    "        df_null_info = self._create_dataframe()\n",
    "        df_null_info = self._create_df_unique(df_null_info)\n",
    "        self._summary(df_null_info)\n",
    "        self._fillna(df_null_info)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _create_dict(self, val_unique, df_train, val):\n",
    "        '''create dictionary of unique values for each column'''\n",
    "        if (len(val_unique) > 99) and isinstance(df_train[val], object):  \n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if (len(val_unique) > 99) and not isinstance(df_train[val], object):\n",
    "            self.dict_unique.update([(val,0)])\n",
    "        if len(val_unique) < 100:\n",
    "            self.dict_unique.update([(val, val_unique)])\n",
    "\n",
    "    def _create_dataframe(self):\n",
    "        '''create main dataframe'''\n",
    "        df_null_info = pd.DataFrame()\n",
    "        counter = -1\n",
    "        for list_val in [self.list_col, self.list_total, self.list_datatype, self.list_unique_total,\n",
    "                        self.list_mode_value, self.list_mode_count, self.list_mode_count_perc]:\n",
    "            counter = counter + 1\n",
    "            col_title = self.column_names[counter]\n",
    "            df = pd.DataFrame(list_val, columns=[col_title])\n",
    "            df_null_info = pd.concat([df_null_info, df], axis=1)\n",
    "        return df_null_info\n",
    "    \n",
    "    def _summary(self, df_null_info):\n",
    "        val = df_null_info.shape[0]\n",
    "        print('There were ' + str(val) + ' columns with null values.')\n",
    "    \n",
    "    def _create_df_unique(self, df_null_info):\n",
    "        '''create unique values dataframe'''\n",
    "        series_unique = pd.Series(self.dict_unique)\n",
    "        df_unique = pd.DataFrame(series_unique).reset_index()\n",
    "        df_unique = df_unique.rename(columns={'index':'col_name', 0:'unique'})\n",
    "        df_null_info = df_null_info.merge(df_unique, how='left', \n",
    "                                          left_on='col_name', right_on='col_name')\n",
    "        df_null_info.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_null_info.csv')\n",
    "        return df_null_info\n",
    "    \n",
    "    def _fillna(self, df_null_info):\n",
    "        '''fill null values of df_train with mode'''\n",
    "        total_null_columns = sum(np.sum(self.df_train.isnull()))\n",
    "        if total_null_columns > 0:\n",
    "            for val in df_null_info.col_name:\n",
    "                val_mode = self.df_train[val].mode()[0]\n",
    "                self.df_train[val] = self.df_train[val].fillna(val_mode)\n",
    "    \n",
    "    def impute_features(self):\n",
    "        df_temp = pp.df_train\n",
    "        for val in col_cat:\n",
    "            total_unique_val = pp.df_train[val].unique().shape[0]\n",
    "            if len(df_temp[val].unique()) < 60:\n",
    "                print('dummies encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "                df_dumm = pd.get_dummies(df_temp[val], prefix=val, drop_first=True)\n",
    "                df_temp = df_temp.drop(val,axis=1)\n",
    "                df_temp = pd.concat([df_temp, df_dumm], axis=1)\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                df_temp[val] = le.fit_transform(df_temp[val])\n",
    "                print('label encoded: ' + str(val) + ' unique ' + str(total_unique_val))\n",
    "        print('new dataframe shape:' + str(df_temp.shape))\n",
    "        return df_temp\n",
    "\n",
    "pp = Preprocessing()\n",
    "df_null_info = pp.missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp.df_train = pp.impute_features()\n",
    "pp.df_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_imputed.csv')\n",
    "df_features = df_features.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create features, target and split the dataframe\n",
    "# X = pp.df_train.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = pp.df_train[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after running final_features, run create_final_df.\n",
      "after running final_features, run create_final_df.\n",
      "keeping original feature card5\n",
      "keeping original feature V317\n",
      "keeping original feature V69\n",
      "keeping original feature D1\n",
      "keeping original feature D3\n",
      "keeping original feature D4\n",
      "keeping original feature D11\n",
      "dropping columns:  ['addr1', 'addr2', 'card2', 'card3', 'C1', 'V294', 'V279', 'C14', 'V306', 'D2', 'D10', 'C4']\n",
      "downsampling applied.\n",
      "smote applied.\n",
      "bool_apply_pca set to false.\n",
      "bool_apply_pca set to false.\n",
      "creating tuning dataframe...\n",
      "downsampling applied.\n",
      "smote applied.\n",
      "final dataframe created.\n",
      "To test a model use the mod.create_df_score_model(model_current)\n",
      "method where, for example, model_current=LogisticRegression().\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineering():\n",
    "    '''create new features for columns without ordinal values'''\n",
    "    def __init__(self):\n",
    "        self.list_fraud_perc = []\n",
    "        self.df_feat = df_features.copy()\n",
    "        self.df_raw = df_raw.copy()\n",
    "        \n",
    "        self.len_df_feat = self.df_feat.shape[0]\n",
    "        self.dict_all_feat = {}\n",
    "        self.new_col = []\n",
    "        \n",
    "        self.col = []\n",
    "        self.col_fe = []\n",
    "        self.df_new_feat = pd.DataFrame()\n",
    "        self.list_drop_col = []\n",
    "        self.str_list_col_fe = []\n",
    "        self.list_feat = []\n",
    "\n",
    "    def feature_testing(self, bool_drop_col, list_feat):\n",
    "        '''testing and scoring new potential features'''\n",
    "        print(\"While running feature_testing, do not run final_features.\")            \n",
    "        if list_feat:\n",
    "            for col in list_feat:\n",
    "                self.col_fe = col\n",
    "                bool_predict_proba = False\n",
    "                if col in df_features.columns:\n",
    "                    df_feat = self.create_test_feature(bool_drop_col, col)\n",
    "                    if df_feat_1000:\n",
    "                        df_feat = df_feat[0:1000]\n",
    "                    df_feat = df_feat.drop(self.list_drop_col[-1], axis=1)\n",
    "                    self._apply_df_transform(df_feat)\n",
    "                    model_lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "                    self._convert_list_to_string(list_feat)\n",
    "                    mod.create_df_score_model(model_lr)\n",
    "                else:\n",
    "                    print(\"\\nColumn\", col, \"does not exist in dataframe.\\n\")\n",
    "            self.col_fe = []\n",
    "        self.list_drop_col = []\n",
    "            \n",
    "    def final_features(self, bool_drop_col, list_feat):\n",
    "        '''creates final new features'''\n",
    "        print('after running final_features, run create_final_df.')\n",
    "        self.list_feat = list_feat\n",
    "        df_feat = self.create_feature(bool_drop_col, list_feat)  \n",
    "        if df_feat_1000:\n",
    "            df_feat = df_feat[0:1000]\n",
    "        for col in list_feat:\n",
    "            col_fe = self._append_col_lists(col)\n",
    "            df_feat[col] = self._fill_na(df_feat, col_fe)\n",
    "            self._concat_df_new_feat(df_feat, col_fe)\n",
    "        self._convert_list_to_string(list_feat)\n",
    "        return df_feat ### delete?\n",
    "    \n",
    "    def _append_col_lists(self, col):\n",
    "        '''appending columns and new feature column names'''\n",
    "        col_fe = col + '_fe'\n",
    "        self.col.append(col)\n",
    "        self.col_fe.append(col_fe)\n",
    "        return col_fe\n",
    "\n",
    "    def _fill_na(self, df_feat, col_fe):\n",
    "        '''fill na values for new features'''\n",
    "        col_mode = df_feat[col_fe].mode()[0]\n",
    "        return df_feat[col_fe].fillna(col_mode)\n",
    "        \n",
    "    def _concat_df_new_feat(self, df_feat, col_fe):\n",
    "        '''adding new feauture columns to one dataframe'''  \n",
    "        df_temp = df_feat[col_fe]\n",
    "        self.df_new_feat = pd.concat([self.df_new_feat, df_temp], axis=1)\n",
    "    \n",
    "    def _convert_list_to_string(self, list_feat):\n",
    "        '''convert list to string to print later'''\n",
    "        str_temp = ''\n",
    "        for val in list_feat:\n",
    "            str_temp = str_temp + val + ' '\n",
    "        self.str_list_col_fe = str_temp\n",
    "\n",
    "    def create_final_df(self):\n",
    "        '''creates final dataframe after creating final_features'''\n",
    "        df_feat = pd.concat([df_features, self.df_new_feat], axis=1)\n",
    "        if df_feat_1000:\n",
    "            df_feat = pd.concat([df_features[0:1000], self.df_new_feat], axis=1)\n",
    "        print('dropping columns: ', self.list_drop_col)\n",
    "        df_feat = df_feat.drop(self.list_drop_col, axis=1)\n",
    "        \n",
    "        self._apply_df_transform(df_feat)\n",
    "        \n",
    "        self._create_tuning_df(df_feat)\n",
    "        self.list_drop_col = []\n",
    "        self._final_df_summary()\n",
    "        \n",
    "    def _shuffle_df(self, X, y):\n",
    "        '''shuffle dataframe'''\n",
    "        y = pd.Series(y)\n",
    "        X = pd.DataFrame(X)\n",
    "        df_temp = pd.concat([X, y], keys=['features','target'], axis=1)\n",
    "        df_temp = shuffle(df_temp).reset_index(drop=True)\n",
    "        X = df_temp.features\n",
    "        y = df_temp.target\n",
    "        return X, y\n",
    "        \n",
    "    def _final_df_summary(self):\n",
    "        print(\"final dataframe created.\")\n",
    "        print(\"To test a model use the mod.create_df_score_model(model_current)\")\n",
    "        print(\"method where, for example, model_current=LogisticRegression().\")\n",
    "\n",
    "    def _apply_df_transform(self, df_feat):\n",
    "        '''create dataframe, apply pca, apply smote'''\n",
    "        self.df_feat = df_feat\n",
    "        X, y = self._drop_col_id_target(df_feat)\n",
    "        X_train, X_test, y_train, y_test = self._split_dataframe(X, y)\n",
    "        X_train, y_train = self._apply_downsampling(X_train, y_train) # apply only train set\n",
    "        X_train, y_train = self._apply_smote(X_train, y_train)        # apply only train set\n",
    "        X_train, y_train = self._shuffle_df(X_train, y_train)\n",
    "        \n",
    "        mod.X_train, mod.y_train = self._apply_pca(X_train, y_train)          # apply to train set\n",
    "        mod.X_test , mod.y_test = self._apply_pca(X_test, y_test) \n",
    "        self._convert_to_matrix()\n",
    "        \n",
    "    def _create_tuning_df(self, df_feat):\n",
    "        '''whole dataframe used for model tuning'''\n",
    "        if bool_create_tuning_df:\n",
    "            print(\"creating tuning dataframe...\")\n",
    "            X, y = self._drop_col_id_target(df_feat)\n",
    "            X, y = self._apply_downsampling(X, y)\n",
    "            X, y = self._apply_smote(X, y)\n",
    "            mod.X_features, mod.y_target = self._shuffle_df(X, y)\n",
    "        else:\n",
    "            print('bool_create_tuning_df set to false.')\n",
    "\n",
    "    def _split_dataframe(self, X, y):\n",
    "        '''splitting dataframe into training and test set'''\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                            y, \n",
    "                                                            test_size=0.1, \n",
    "                                                            random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def _drop_col_id_target(self, df_feat):\n",
    "        '''dropping col id and target from features and creating target dataframe'''\n",
    "        X = df_feat.drop(col_target, axis=1)\n",
    "        X = X.drop(col_id, axis=1)\n",
    "        y = df_feat[col_target]\n",
    "        return X, y\n",
    "    \n",
    "    def _apply_downsampling(self, X, y):\n",
    "        '''down sampling majority class'''\n",
    "        if bool_apply_downsampling:\n",
    "            len_y_one = len(y[y==1])\n",
    "            sampler = RandomUnderSampler(random_state=42, ratio={0:95000, 1:len_y_one})\n",
    "            X, y = sampler.fit_sample(X, y)\n",
    "            print(\"downsampling applied.\")\n",
    "            return X, y\n",
    "        else:\n",
    "            print(\"bool_apply_downsampling set to false.\")\n",
    "            return X, y\n",
    "            \n",
    "    def _apply_smote(self, X, y):\n",
    "        '''applying smote to split training set'''\n",
    "        if bool_apply_smote:\n",
    "            sm = SMOTE(random_state=42, n_jobs=-1)\n",
    "            X, y = sm.fit_sample(X, y)\n",
    "            print(\"smote applied.\")\n",
    "            return X, y\n",
    "        else:\n",
    "            print(\"bool_apply_smote set to false.\")\n",
    "            return X, y\n",
    "            \n",
    "    def _apply_pca(self, X, y):\n",
    "        '''applying PCA and creating train and test set'''\n",
    "        if bool_apply_pca:\n",
    "            X = self._pca(X)\n",
    "            print('pca applied to training set, then test set.')\n",
    "            return X, y\n",
    "        else:\n",
    "            print(\"bool_apply_pca set to false.\")\n",
    "            return X, y\n",
    "\n",
    "    def _pca(self, X):\n",
    "        '''applying pca features dataframe'''\n",
    "        scaled_X = StandardScaler().fit_transform(X)\n",
    "        pca = PCA(n_components=250) #set value\n",
    "        pcomponents = pca.fit_transform(scaled_X)\n",
    "        X_pca = pd.DataFrame(data=pcomponents)\n",
    "        return X_pca\n",
    "        \n",
    "    def _convert_to_matrix(self):\n",
    "        '''converting X_test to matrix so columns match X_train'''\n",
    "        if bool_apply_downsampling or bool_apply_smote:\n",
    "            mod.X_test = pd.DataFrame(mod.X_test.values)\n",
    "            \n",
    "    def create_test_feature(self, bool_drop_col, col):\n",
    "        '''creates correllated ratio to target column'''\n",
    "        df_feat = df_features.copy()        \n",
    "        df_feat = self._calculate_target_perc(col, df_feat) \n",
    "        df_feat = self._map_col(col, df_feat)\n",
    "        df_feat = self._create_ratio(df_feat)\n",
    "        df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat\n",
    "    \n",
    "    def create_feature(self, bool_drop_col, list_col):\n",
    "        '''creating new feature'''\n",
    "        df_feat = self.df_feat       \n",
    "        for col in list_col:\n",
    "            df_feat = self._check_col_exist(col, df_feat)\n",
    "            df_feat = self._calculate_target_perc(col, df_feat) \n",
    "            df_feat = self._map_col(col, df_feat)\n",
    "            df_feat = self._create_ratio(df_feat)\n",
    "            df_feat = self._drop_column(bool_drop_col, col, df_feat)\n",
    "        return df_feat \n",
    "    \n",
    "    def _check_col_exist(self, col, df_feat):\n",
    "        '''recreates original column from original dataframe'''\n",
    "        if col not in df_feat.columns:\n",
    "            df_feat[col] = df_raw[col]\n",
    "            df_feat[col] = self._fill_na(df_feat, col)\n",
    "            df_feat[col] = self._label_encode(df_feat, col)\n",
    "        return df_feat\n",
    "    \n",
    "    def _label_encode(self, df_feat, col):\n",
    "        '''label encoding columns pulled from original df_raw'''\n",
    "        le = LabelEncoder()\n",
    "        df_feat[col] = le.fit_transform(df_feat[col])\n",
    "        return df_feat[col]\n",
    "    \n",
    "    def _drop_column(self, bool_drop_col, col, df_feat):\n",
    "        '''dropping or keeping columns'''\n",
    "        if bool_drop_col:\n",
    "            if (col in df_features.columns):    \n",
    "                self.list_drop_col.append(col) \n",
    "        else:\n",
    "            print(\"keeping original feature\", col)\n",
    "        return df_feat\n",
    "\n",
    "    def aggregate_features(self, list_col, val_aggreg):\n",
    "        for col in list_col:\n",
    "            df_groupby = self.df_raw.groupby(col).mean()\n",
    "            dict_aggreg_col = df_groupby[[val_aggreg]].to_dict()\n",
    "            self.df_feat[col + '_fe'] = self.df_raw[col].map(dict_aggreg_col['TransactionAmt'])\n",
    "            col_mode = self.df_feat[col + '_fe'].mode()[0]\n",
    "            self.df_feat[col + '_fe'] = self.df_feat[col + '_fe'].fillna(col_mode)\n",
    "\n",
    "    def _calculate_target_perc(self, col_val, df_feat):\n",
    "        '''calculate fraud percentage for each column'''\n",
    "        list_perc = []\n",
    "        dict_feat = {}\n",
    "        unique_col_values = df_feat[col_val].unique()\n",
    "        for val in unique_col_values:\n",
    "            list_perc = self._append_fraud_percentage(df_feat, col_val, val, list_perc)    \n",
    "        self._create_dict(col_val, list_perc, unique_col_values)\n",
    "        return df_feat\n",
    "    \n",
    "    def _append_fraud_percentage(self, df_feat, col_val, val, list_perc):\n",
    "        '''calculating fraud percentage and adding to list'''\n",
    "        fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                            & (df_feat[col_target]==1)].shape[0]\n",
    "        non_fraud_total = df_feat[(df_feat[col_val]==val) \n",
    "                                & (df_feat[col_target]==0)].shape[0]\n",
    "        if (non_fraud_total==0):\n",
    "            list_perc.append(0)\n",
    "        else: \n",
    "            list_perc.append(fraud_total/non_fraud_total)\n",
    "        return list_perc\n",
    "\n",
    "    def _create_dict(self, col_val, list_perc, unique_col_values):\n",
    "        '''create dictionary for original values to new fraud percent values'''\n",
    "        col_name = col_val + '_fraud_perc'\n",
    "        series_perc = pd.Series(list_perc, name=col_name)\n",
    "        series_col = pd.Series(unique_col_values, name=col_val)\n",
    "        df_feat = pd.concat([series_col, series_perc], axis=1)\n",
    "        df_feat = df_feat.sort_values(col_name, ascending=False) \n",
    "        dict_feat = df_feat.set_index(col_val).to_dict()\n",
    "        self.dict_all_feat.update(dict_feat)\n",
    "\n",
    "    def _map_col(self, col, df_feat):\n",
    "        '''map dictionary values to new features'''\n",
    "        dict_keys = self.dict_all_feat.keys()\n",
    "        for val in dict_keys:\n",
    "            df_feat[col + '_fe'] = df_feat[col].map(self.dict_all_feat[val])\n",
    "            self.new_col.append(col + '_fe')\n",
    "        return df_feat\n",
    "            \n",
    "    def _create_ratio(self, df_feat):\n",
    "        '''finalize new features with ranking values'''\n",
    "        for val in self.new_col:\n",
    "            col_min_val = df_feat[df_feat[val] > 0][val].min()\n",
    "            df_feat[val] = df_feat[val]/col_min_val\n",
    "        self.new_col = []\n",
    "        return df_feat\n",
    "    \n",
    "mod = Model()\n",
    "fe = FeatureEngineering()\n",
    "\n",
    "bool_predict_proba = False\n",
    "bool_thres_cost = False\n",
    "bool_apply_pca = False\n",
    "bool_apply_smote = True\n",
    "bool_apply_downsampling = True\n",
    "\n",
    "bool_create_tuning_df = True\n",
    "bool_drop_col = True\n",
    "df_feat_1000 = False\n",
    "fe.final_features(bool_drop_col, list_feat=['addr1','addr2','card2','card3','C1','P_emaildomain', \n",
    "                                            'card6', 'V294','V279','C14','V306','D2','D10'])\n",
    "bool_drop_col = False\n",
    "fe.final_features(bool_drop_col, list_feat=['card5', 'V317', 'V69', 'D1','D3','D4','D11'])\n",
    "fe.list_drop_col.append('C4')\n",
    "fe.create_final_df()\n",
    "\n",
    "# fe.feature_testing(bool_drop_col, list_feat=['addr1'])\n",
    "\n",
    "# FN = 540, FP = 12598.0, pca, smote, downsampling\n",
    "# FN = 534.0, FP = 12535.0, pca, smote \n",
    "# FN = 577.0, FP = 22223.0, smote and downsampling only\n",
    "# FN = 360, FP = 30387.0, smote only\n",
    "# FN = 2103.0, FP = 36.0, undersampling only \n",
    "# FN = 508.0, FP = 8724.0, full, pca, smote\n",
    "# FN = 508, FP = 8745, full, pca, smote, undersample, 50,000 samples\n",
    "# FN = 510, FP = 8701, full, pca, smote, undersample, 25,000 samples\n",
    "# FN = 1093, FP = 734, full, pca, smote, undersample, 50,000 samples, correction\n",
    "# FN = 360, FP = 30387, smote\n",
    "# FN = 354, FP = 31090, smote, undersample\n",
    "# FN = 572, FP = 30741, smote, undersample, pca\n",
    "# FN = 485, FP = 30076, smote, undersample, pca, 100000\n",
    "# FN = , FP = , smote, undersample, pca, 95000, full\n",
    "# FN = 360, FP = 30387, no downsample, no pca, smote addr1\n",
    "# FN = 529, FP = 18023, smote, full\n",
    "# FN = 429, FP = 23106, smote, downsample, full\n",
    "# FN = 549, FP = 30123, smote, downsample, pca, full\n",
    "# FN = 545, FP = 30227, smote, downsample, pca, 290, full\n",
    "\n",
    "# NEXT, we need to fix our tuning dataframe. method, decide how we are going to tune our model, then \n",
    "# we also need to decide how this effects our results. Should we tune on the hold outset? If we applied\n",
    "# smote and undersampling, etc. how does this effect our outcome?\n",
    "\n",
    "# the tuning dataframe we define must upsample and downsample from whole dataset, we use that to \n",
    "# tune our data since during the process of tuning, we will have our hold out set in the CV. \n",
    "# Also, check time elap for non pca. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('X_train', mod.X_train.shape)\n",
    "# print('y_train', mod.y_train.shape)\n",
    "# print('X_test', mod.X_test.shape)\n",
    "# print('y_test', mod.y_test.shape)\n",
    "# print('y_train==1', np.sum(mod.y_train[mod.y_train==0].isnull()))\n",
    "# print('y_train==0', np.sum(mod.y_train[mod.y_train==1].isnull()))\n",
    "# we need to test tuning on the entire dataframe and also the split version we have created. \n",
    "# lets test using logisticregression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "mod.X_train = pd.DataFrame(mod.X_train)\n",
    "mod.y_train = pd.DataFrame(mod.y_train)\n",
    "mod.X_test = pd.DataFrame(mod.X_test)\n",
    "mod.y_test = pd.DataFrame(mod.y_test)\n",
    "mod.X_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv')\n",
    "mod.y_train.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv')\n",
    "mod.X_test.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv')\n",
    "mod.y_test.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv')\n",
    "mod.X_features = pd.DataFrame(mod.X_features)\n",
    "mod.y_target = pd.DataFrame(mod.y_target)\n",
    "mod.X_features.to_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv')\n",
    "mod.y_target.to_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "mod.X_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.y_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.X_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.y_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0',axis=1)\n",
    "mod.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "# mod.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0', axis=1)\n",
    "# mod.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0', axis=1)\n",
    "# mod.X_features.info(memory_usage='deep')\n",
    "# mod.y_target.info(memory_usage='deep')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = True\n",
    "# model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing LogisticRegression\n",
    "# model_current =  LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=False,\n",
    "#                                    intercept_scaling=0.1, l1_ratio=1e-06, max_iter=150,\n",
    "#                                    multi_class='multinomial', n_jobs=-1, penalty='none',\n",
    "#                                    random_state=42, solver='lbfgs', tol=1e-05, verbose=0,\n",
    "#                                    warm_start=False)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TESTING XGBClassifier n_estimators=150\n",
    "# bool_predict_proba = False\n",
    "# model_current = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
    "#                               colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
    "#                               learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
    "#                               min_child_weight=1, missing=None, n_estimators=150, n_jobs=-1,\n",
    "#                               nthread=None, objective='binary:logistic', random_state=42,\n",
    "#                               reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
    "#                               silent=None, subsample=0.5, verbosity=1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing XGBClassifier 200 n_estimators\n",
    "# model_current = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
    "#                               colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
    "#                               learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
    "#                               min_child_weight=1, missing=None, n_estimators=200, n_jobs=-1,\n",
    "#                               nthread=None, objective='binary:logistic', random_state=42,\n",
    "#                               reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
    "#                               silent=None, subsample=0.5, verbosity=1)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # testing RandomForestClassifier\n",
    "# model_current = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "#                                        criterion='gini', max_depth=5, max_features='auto',\n",
    "#                                        max_leaf_nodes=9,\n",
    "#                                        min_impurity_decrease=0.1, min_impurity_split=None,\n",
    "#                                        min_samples_leaf=4, min_samples_split=3,\n",
    "#                                        min_weight_fraction_leaf=0.3, n_estimators=100,\n",
    "#                                        n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
    "#                                        warm_start=False)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing RandomForestClassifier n_estimators=150\n",
    "# model_current = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "#                                        criterion='gini', max_depth=5, max_features='auto',\n",
    "#                                        max_leaf_nodes=9,\n",
    "#                                        min_impurity_decrease=0.1, min_impurity_split=None,\n",
    "#                                        min_samples_leaf=4, min_samples_split=3,\n",
    "#                                        min_weight_fraction_leaf=0.3, n_estimators=150,\n",
    "#                                        n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
    "#                                        warm_start=False)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing DecisionTreeClassifier max_depth=11\n",
    "# model_current = DecisionTreeClassifier(class_weight='balanced',\n",
    "#                                        criterion='entropy', max_depth=11, max_features=None,\n",
    "#                                        max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "#                                        min_impurity_split=None, min_samples_leaf=9,\n",
    "#                                        min_samples_split=5, min_weight_fraction_leaf=0,\n",
    "#                                        presort='auto', random_state=42, splitter='best')\n",
    "\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # testing DecisionTreeClassifier max_depth=13\n",
    "# model_current = DecisionTreeClassifier(class_weight='balanced',\n",
    "#                                        criterion='entropy', max_depth=13, max_features=None,\n",
    "#                                        max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "#                                        min_impurity_split=None, min_samples_leaf=9,\n",
    "#                                        min_samples_split=5, min_weight_fraction_leaf=0,\n",
    "#                                        presort='auto', random_state=42, splitter='best')\n",
    "\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # base score LogisticRegression threshold\n",
    "# bool_predict_proba = True\n",
    "# model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base model LogisticRegression\n",
    "# model_current = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # base DecisionTreeClassifier\n",
    "# bool_predict_proba = False\n",
    "# model_current = DecisionTreeClassifier(random_state=42)\n",
    "# mod.create_df_score_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base RandomForestClassifier\n",
    "# bool_predict_proba = False\n",
    "# model_current = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold by cost: 0.05\n",
      "Best threshold by roc auc score: 0.25 \n",
      "\n",
      "did not enter if bool_thres_cost\n",
      "Model does not have predict_proba attribute.\n",
      "test y_pred None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-117a56378f60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbool_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_df_score_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-1f79973e758e>\u001b[0m in \u001b[0;36mcreate_df_score_model\u001b[0;34m(self, model_current)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test y_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         df_scores, df_temp, y_pred = self._score_model(y_pred, \n\u001b[0;32m---> 24\u001b[0;31m                                                        elapsed_time)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-1f79973e758e>\u001b[0m in \u001b[0;36m_score_model\u001b[0;34m(self, y_pred, elapsed_time)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;34m'''creating dataframe with score results'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         col_recall, col_precision, col_time = self._calc_scores(y_pred, \n\u001b[0;32m--> 155\u001b[0;31m                                                                   elapsed_time)        \n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mdf_conf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_conf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-1f79973e758e>\u001b[0m in \u001b[0;36m_calc_scores\u001b[0;34m(self, y_pred, elapsed_time)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calc_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;34m'''calculating recall, precision and elapsed time'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mcol_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mcol_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mcol_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time_elapsed (min)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1673\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1676\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 241\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0msparseseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SparseSeries'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got None"
     ]
    }
   ],
   "source": [
    "# base XGBClassifier threshold\n",
    "bool_predict_proba = True\n",
    "model_current = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # base XGBClassifier\n",
    "# bool_predict_proba = False\n",
    "# model_current = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "# mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict_proba CatBoostClassifier\n",
    "# bool_predict_proba = True\n",
    "# model_current = CatBoostClassifier(random_state=42)\n",
    "# mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # base CatBoostClassifier\n",
    "# bool_predict_proba = True\n",
    "# model_current = CatBoostClassifier(random_state=42)\n",
    "# mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = True\n",
    "# model_current = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=False,\n",
    "#                    intercept_scaling=0.1, l1_ratio=1e-06, max_iter=150,\n",
    "#                    multi_class='multinomial', n_jobs=-1, penalty='none',\n",
    "#                    random_state=42, solver='lbfgs', tol=1e-05, verbose=0,\n",
    "#                    warm_start=False)\n",
    "# mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # newly tuned LR\n",
    "# bool_predict_proba = True\n",
    "# model_current = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
    "#               colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
    "#               learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
    "#               min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
    "#               nthread=None, objective='binary:logistic', random_state=42,\n",
    "#               reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
    "#               silent=None, subsample=0.5, verbosity=1)\n",
    "# mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_predict_proba = True\n",
    "# model_current = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
    "#               colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
    "#               learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
    "#               min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
    "#               nthread=None, objective='binary:logistic', random_state=42,\n",
    "#               reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
    "#               silent=None, subsample=0.5, verbosity=1)\n",
    "# mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.X_train = pd.DataFrame()\n",
    "        self.y_train = pd.DataFrame()\n",
    "        self.X_test = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.X_features = pd.DataFrame()\n",
    "        self.y_target = pd.DataFrame()\n",
    "\n",
    "        self.X_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.y_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.X_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.y_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0',axis=1)\n",
    "        self.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0',axis=1)\n",
    "#         self.place_holder = pd.DataFrame()\n",
    "        \n",
    "    def create_df_score_model(self, model_current):\n",
    "        '''scores model'''\n",
    "        print(\"Fitting model:\\n\", model_current)\n",
    "        y_pred, elapsed_time = self.add_model(model_current) \n",
    "#         print('test y_pred', y_pred) #del\n",
    "        df_scores, df_temp, y_pred = self._score_model(y_pred, \n",
    "                                                       elapsed_time)\n",
    "        self._save_results(df_scores, df_temp, y_pred)\n",
    "        self._feature_importance(model_current)\n",
    "        fe.col_fe = []\n",
    "        \n",
    "    def add_model(self, model):        \n",
    "        '''fitting model and calculating time elapsed'''\n",
    "        start_time = time.time()\n",
    "        model.fit(mod.X_train, mod.y_train)\n",
    "        \n",
    "        y_pred = self._predict(model)\n",
    "        \n",
    "        y_pred = self._predict_proba_threshold(y_pred)\n",
    "#         y_pred_class = self._predict_proba_threshold(y_pred_prob)\n",
    "#         print('y_pred_class', y_pred_class)\n",
    "#         return y_pred_class\n",
    "        \n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        return y_pred, elapsed_time\n",
    "    \n",
    "    def _predict(self, model):\n",
    "        '''make prediction'''\n",
    "        if bool_predict_proba:\n",
    "#             print('enter if bool_predict_proba') #del\n",
    "            y_pred = self._predict_proba(model)\n",
    "            return y_pred \n",
    "        else:\n",
    "            y_pred = model.predict(mod.X_test)\n",
    "            return y_pred\n",
    "        \n",
    "    def _predict_proba(self, model):\n",
    "        try:\n",
    "            y_pred_prob = model.predict_proba(mod.X_test)\n",
    "#             print('proba') #del\n",
    "            \n",
    "#             y_pred_class = self._predict_proba_threshold(y_pred_prob)\n",
    "#             print('y_pred_class', y_pred_class)\n",
    "#             return y_pred_class\n",
    "        \n",
    "            return y_pred_prob\n",
    "        except:\n",
    "            print(\"Model does not have predict_proba attribute.\")\n",
    "  \n",
    "#     def _predict_proba_threshold(self, y_pred_prob):\n",
    "#         for threshold in [.1, .15, .2, .25, .3, .35, .4, .45, .5, .55, .6]:\n",
    "#             print('threshold: ', threshold)\n",
    "#             y_pred_class = binarize(y_pred_prob, threshold)[:,1]\n",
    "#             print('roc auc score:', roc_auc_score(mod.y_test, y_pred_class))\n",
    "#             print('\\nconfusion matrix:\\n', confusion_matrix(mod.y_test, y_pred_class))\n",
    "#         return y_pred_class\n",
    "    \n",
    "\n",
    "############################\n",
    "\n",
    "    def _predict_proba_threshold(self, y_pred_prob):\n",
    "        '''create prediction based on threshold value'''\n",
    "        df_results = pd.DataFrame()\n",
    "        dict_results = {'index':[0], 'threshold':[], 'roc_auc_score':[], \n",
    "                        'total_cost':[], 'fn':[], 'fp':[]}\n",
    "        list_threshold = [.05, .1, .15, .2, .25, .3, \n",
    "                          .35, .4, .45, .5, .55, .6]\n",
    "        for threshold in list_threshold:\n",
    "            df_temp = self._compute_thres_df(y_pred_prob, dict_results, threshold)\n",
    "            df_results = pd.concat([df_results, df_temp], axis=0)\n",
    "        df_results = df_results.drop('index', axis=1).reset_index(drop=True)\n",
    "        \n",
    "        self._plot_thres_auc(df_results)\n",
    "        self._plot_thres_score(df_results)\n",
    "        val_thres_cost = self._calc_best_thres_cost(df_results)\n",
    "        val_thres_auc = self._calc_best_thres_auc(df_results)\n",
    "        \n",
    "        y_pred_class = self._y_pred_class(y_pred_prob, val_thres_cost, val_thres_auc)\n",
    "        \n",
    "        print(df_results)\n",
    "        return y_pred_class\n",
    "    \n",
    "    def _y_pred_class(self, y_pred_prob, val_thres_cost, val_thres_auc):\n",
    "        '''calculate y_pred_class depending on if we want cost or auc threshold'''\n",
    "        if bool_thres_cost:\n",
    "#             print('y_pred_prob:',y_pred_prob) #del\n",
    "#             print('val_thres_cost:',val_thres_cost) #del\n",
    "            y_pred_class = binarize(y_pred_prob, val_thres_cost)[:,1]\n",
    "            return y_pred_class\n",
    "        else:\n",
    "#             print('did not enter if bool_thres_cost') #del\n",
    "            y_pred_class = binarize(y_pred_prob, val_thres_auc)[:,1]\n",
    "#             print(\"print y_pred_class\", y_pred_class) #del\n",
    "            return y_pred_class\n",
    "        \n",
    "    def _compute_thres_df(self, y_pred_prob, dict_results, threshold):\n",
    "        '''compute the values for each threshold'''\n",
    "        y_pred_class = binarize(y_pred_prob, threshold)[:,1]\n",
    "        conf_matr = confusion_matrix(self.y_test, y_pred_class)\n",
    "        df_conf_matrix = pd.DataFrame(conf_matr)\n",
    "        \n",
    "        val_score = roc_auc_score(self.y_test, y_pred_class)\n",
    "        val_fn = df_conf_matrix[0][1]\n",
    "        val_fp = df_conf_matrix[1][0]\n",
    "        val_cost = 3000*val_fn + 20*val_fp\n",
    "\n",
    "        dict_results.update([('threshold', threshold)])\n",
    "        dict_results.update([('roc_auc_score', val_score)])\n",
    "        dict_results.update([('total_cost', val_cost)])\n",
    "        dict_results.update([('fn', val_fn)])\n",
    "        dict_results.update([('fp', val_fp)])\n",
    "        df_temp = pd.DataFrame.from_dict(dict_results)\n",
    "        return df_temp\n",
    "        \n",
    "    def _plot_thres_auc(self, df_results):\n",
    "        '''plot auc roc score by threshold'''\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.title(\"Threshold by Auc Roc Score\", fontsize=14)\n",
    "        plt.xlabel('Threshold', fontsize=13)\n",
    "        plt.ylabel(\"Auc Roc Score\", fontsize=13)\n",
    "        plt.plot('threshold', 'roc_auc_score', data=df_results)\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_thres_score(self, df_results):\n",
    "        '''plot cost by threshold'''\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.title(\"Threshold by Cost\", fontsize=14)\n",
    "        plt.xlabel('Threshold', fontsize=13)\n",
    "        plt.ylabel(\"Cost in Dollars\", fontsize=13)\n",
    "        plt.plot('threshold', 'total_cost', data=df_results)\n",
    "        plt.show()\n",
    "    \n",
    "    def _calc_best_thres_cost(self, df_results):\n",
    "        '''calculate the best threshold by cost'''\n",
    "        val_min_cost = df_results.total_cost.min()\n",
    "        index_min_cost = df_results[df_results.total_cost==val_min_cost].index\n",
    "        val_threshold_min_cost = df_results.loc[index_min_cost,:].threshold.item()\n",
    "        print(\"Best threshold by cost:\", val_threshold_min_cost)\n",
    "        return val_threshold_min_cost\n",
    "\n",
    "    def _calc_best_thres_auc(self, df_results):\n",
    "        '''calculate the best threshold by highest auc roc score'''\n",
    "        val_max_roc_auc = df_results.roc_auc_score.max()\n",
    "        index_best_roc_auc = df_results[df_results.roc_auc_score==val_max_roc_auc].index\n",
    "        val_threshold_roc_auc = df_results.loc[index_best_roc_auc,:].threshold.item()\n",
    "        print(\"Best threshold by roc auc score:\", val_threshold_roc_auc, '\\n')\n",
    "        return val_threshold_roc_auc\n",
    "\n",
    "    def _score_model(self, y_pred, elapsed_time):      \n",
    "        '''creating dataframe with score results'''\n",
    "        col_recall, col_precision, col_time = self._calc_scores(y_pred, \n",
    "                                                                  elapsed_time)        \n",
    "        df_conf_matrix = self._confusion_matrix(y_pred)\n",
    "        df_temp = pd.concat([col_recall, col_precision, df_conf_matrix, col_time], axis=1)\n",
    "        if fe.col_fe:\n",
    "            df_temp = self._concat_new_feat(df_temp)\n",
    "        df_scores = self._read_create_score_file(df_temp)\n",
    "        return df_scores, df_temp, y_pred\n",
    "\n",
    "    def _calc_scores(self, y_pred, elapsed_time):\n",
    "        '''calculating recall, precision and elapsed time'''\n",
    "        col_recall = pd.Series(recall_score(mod.y_test, y_pred), name='recall')\n",
    "        col_precision = pd.Series(precision_score(mod.y_test, y_pred), name='precision')\n",
    "        col_time = pd.Series(elapsed_time, name='time_elapsed (min)')\n",
    "        print(\"roc auc score:\", roc_auc_score(mod.y_test, y_pred))\n",
    "        return col_recall, col_precision, col_time\n",
    "    \n",
    "    def _confusion_matrix(self, y_pred):\n",
    "        '''creating confusion matrix dataframe'''\n",
    "        df_conf_matrix = pd.DataFrame(confusion_matrix(mod.y_test, y_pred))\n",
    "        val_tp = pd.Series(df_conf_matrix[0][0], name='tp')\n",
    "        val_fn = pd.Series(df_conf_matrix[0][1], name='fn')\n",
    "        val_fp = pd.Series(df_conf_matrix[1][0], name='fp')\n",
    "        val_tn = pd.Series(df_conf_matrix[1][1], name='tn')\n",
    "        return pd.concat([val_fn, val_fp, val_tp, val_tn], axis=1)\n",
    "\n",
    "    def _concat_new_feat(self, df_temp):\n",
    "        '''concatenate scoring results'''        \n",
    "        print(\"\\nThe following new features have been created:\", fe.col_fe, '\\n')\n",
    "        if len(fe.col_fe) > 1: \n",
    "            fe.col_fe = \"model score\"\n",
    "        col_fe = pd.Series(fe.col_fe, name='feat_tested')\n",
    "        return pd.concat([col_fe, df_temp], axis=1)\n",
    "    \n",
    "    def _read_create_score_file(self, df_temp):\n",
    "        '''reading or creating df_scores file'''\n",
    "        try: \n",
    "            df_scores = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "            df_scores = df_scores.drop('Unnamed: 0', axis=1)\n",
    "        except:\n",
    "            print(\"\\nCreating df_scores.csv file.\") \n",
    "            df_scores = df_temp\n",
    "        return df_scores\n",
    "            \n",
    "    def _save_results(self, df_scores, df_temp, y_pred):\n",
    "        '''printing scores for new features'''            \n",
    "        df_scores = pd.concat([df_scores, df_temp], axis=0)\n",
    "        df_scores.to_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "        classif_report = classification_report(mod.y_test, y_pred)\n",
    "        self._print_summary(classif_report, df_scores)\n",
    "        self._save_summary(classif_report)\n",
    "\n",
    "    def _print_summary(self, classif_report, df_scores):\n",
    "        '''print last 5 rows of previous score results'''\n",
    "        print(classif_report)\n",
    "        print('\\ndf_scores:\\n\\n', df_scores.tail(5))\n",
    "    \n",
    "    def _save_summary(self, classif_report):\n",
    "        '''save score result summary to text file'''\n",
    "        file_summary = open('/Users/krahman/work/fraud_detection/saved_files/df_scores_summary.txt', \"a\")\n",
    "        file_summary.write('New features created from: ' \n",
    "                           + fe.str_list_col_fe \n",
    "                           + '\\n')\n",
    "        file_summary.write(classif_report)\n",
    "        file_summary.close()\n",
    "        \n",
    "    def _feature_importance(self, model):\n",
    "        '''create feature importance dataframe and bar plot'''\n",
    "        try:\n",
    "            df_feat_rank = self._feat_import_create_df(model)\n",
    "            self._feat_import_create_plot(df_feat_rank)\n",
    "            print(df_feat_rank[0:10].reset_index(drop=True))\n",
    "        except:\n",
    "            print(\"\\nmodel does not have _feature_importance attribute.\")\n",
    "        \n",
    "    def _feat_import_create_df(self, model):\n",
    "        '''creating dataframe of important features'''\n",
    "        col_name = pd.Series(fe.df_feat.columns, name='col')\n",
    "        col_feat_rank = pd.Series(model.feature_importances_, \n",
    "                                  name='feat_rank')\n",
    "        df_feat_rank = pd.concat([col_name, col_feat_rank], axis=1)\n",
    "        df_feat_rank = df_feat_rank.sort_values('feat_rank', ascending=False)\n",
    "        return df_feat_rank\n",
    "    \n",
    "    def _feat_import_create_plot(self, df_feat_rank):\n",
    "        '''create feature importance bar plot'''\n",
    "        plt.figure(figsize=(5,6))\n",
    "        sns.barplot(df_feat_rank.feat_rank[0:10],\n",
    "                    df_feat_rank.col[0:10],\n",
    "                    palette='Blues_d')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "        \n",
    "mod = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "# mod.X_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_train.csv').drop('Unnamed: 0',axis=1)\n",
    "# mod.y_train = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_train.csv').drop('Unnamed: 0',axis=1)\n",
    "# mod.X_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_test.csv').drop('Unnamed: 0',axis=1)\n",
    "# mod.y_test = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_test.csv').drop('Unnamed: 0',axis=1)\n",
    "# mod.X_features = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/X_features.csv').drop('Unnamed: 0',axis=1)\n",
    "# mod.y_target = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/y_target.csv').drop('Unnamed: 0',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "enter if bool_predict_proba\n",
      "proba\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold by cost: 0.15\n",
      "Best threshold by roc auc score: 0.55 \n",
      "\n",
      "y_pred_prob: [[0.64229558 0.35770442]\n",
      " [0.71817671 0.28182329]\n",
      " [0.56581378 0.43418622]\n",
      " ...\n",
      " [0.6707659  0.3292341 ]\n",
      " [0.58263664 0.41736336]\n",
      " [0.52878833 0.47121167]]\n",
      "val_thres_cost: 0.15\n",
      "    threshold  roc_auc_score  total_cost    fn     fp\n",
      "0        0.05       0.503222     1134020     1  56551\n",
      "1        0.10       0.521117     1108020     7  54351\n",
      "2        0.15       0.543788     1088360    20  51418\n",
      "3        0.20       0.564149     1105940    46  48397\n",
      "4        0.25       0.584502     1118620    70  45431\n",
      "5        0.30       0.602027     1169720   107  42436\n",
      "6        0.35       0.620466     1231040   149  39202\n",
      "7        0.40       0.639115     1314020   200  35701\n",
      "8        0.45       0.654331     1476160   280  31808\n",
      "9        0.50       0.700883     1825220   465  21511\n",
      "10       0.55       0.723007     2677640   832   9082\n",
      "11       0.60       0.687839     3490820  1130   5041\n",
      "test y_pred [1. 1. 1. ... 1. 1. 1.]\n",
      "roc auc score: 0.5437876989521929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18     56945\n",
      "           1       0.04      0.99      0.08      2109\n",
      "\n",
      "    accuracy                           0.13     59054\n",
      "   macro avg       0.52      0.54      0.13     59054\n",
      "weighted avg       0.96      0.13      0.17     59054\n",
      "\n",
      "\n",
      "df_scores:\n",
      "\n",
      "      feat_tested     fn       fp  precision    recall  time_elapsed (min)  \\\n",
      "416          NaN  856.0   8597.0   0.127208  0.594120            0.960058   \n",
      "417          NaN  856.0   8597.0   0.127208  0.594120            0.819725   \n",
      "418          NaN  856.0   8597.0   0.127208  0.594120            0.911682   \n",
      "419  model score  832.0   9082.0   0.123274  0.605500            0.874910   \n",
      "0            NaN   20.0  51418.0   0.039042  0.990517            0.797138   \n",
      "\n",
      "         tn       tp  \n",
      "416  1253.0  48348.0  \n",
      "417  1253.0  48348.0  \n",
      "418  1253.0  48348.0  \n",
      "419  1277.0  47863.0  \n",
      "0    2089.0   5527.0  \n",
      "\n",
      "model does not have _feature_importance attribute.\n"
     ]
    }
   ],
   "source": [
    "bool_thres_cost = True\n",
    "bool_predict_proba = True\n",
    "model_current = LogisticRegression(random_state=42)\n",
    "mod.create_df_score_model(model_current)\n",
    "# bool_predict_proba = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(random_state=42)\n",
    "# model.fit(mod.X_train, mod.y_train)\n",
    "# y_pred = model.predict_proba(mod.X_test)\n",
    "# y_pred = binarize(y_pred, .5)[:,1]\n",
    "# roc_auc_score(mod.y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning xgbc\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.987, total= 7.5min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.986, total= 6.9min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.987, total= 6.9min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 21.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.985, total= 6.9min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 28.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.987, total= 6.0min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 34.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.988, total= 6.2min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 40.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.987, total= 6.3min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 46.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.987, total= 6.3min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 53.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.987, total= 6.4min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 59.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=5, max_depth=9, colsample_bytree=0.5, colsample_bynode=0.7, colsample_bylevel=0.9, booster=dart, base_score=0.3, score=0.988, total= 6.6min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.966, total= 2.6min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.964, total= 2.6min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.965, total= 2.8min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.963, total= 3.1min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.965, total= 3.0min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.967, total= 2.8min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.963, total= 2.8min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.966, total= 3.0min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.964, total= 2.6min\n",
      "[CV] subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4 \n",
      "[CV]  subsample=0.7, scale_pos_weight=1, reg_lambda=7, reg_alpha=7, max_depth=11, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0, booster=dart, base_score=0.4, score=0.967, total= 2.6min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.964, total= 1.9min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.961, total= 2.0min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.963, total= 2.0min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.962, total= 2.1min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.963, total= 2.2min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.966, total= 2.0min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.961, total= 1.9min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.963, total= 1.9min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.962, total= 1.9min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=3, reg_alpha=7, max_depth=2, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.964, total= 2.3min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.800, total= 1.8min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.796, total= 1.6min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.804, total= 1.6min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.802, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.799, total= 1.6min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.805, total= 1.6min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.802, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.804, total= 1.8min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.798, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=7, reg_lambda=1, reg_alpha=5, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.7, colsample_bylevel=1, booster=gblinear, base_score=0.5, score=0.807, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 3.2min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.988, total= 3.2min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 3.4min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.988, total= 3.4min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 3.2min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.990, total= 3.0min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 3.1min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 3.3min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 3.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4 \n",
      "[CV]  subsample=0.5, scale_pos_weight=5, reg_lambda=5, reg_alpha=3, max_depth=13, colsample_bytree=0.7, colsample_bynode=0.5, colsample_bylevel=0.3, booster=gbtree, base_score=0.4, score=0.989, total= 4.5min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.986, total= 2.5min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.985, total= 2.4min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.986, total= 2.5min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.984, total= 2.4min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.986, total=14.8min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.987, total= 2.6min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.985, total= 2.3min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.986, total= 2.3min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.985, total= 2.2min\n",
      "[CV] subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3 \n",
      "[CV]  subsample=0.7, scale_pos_weight=3, reg_lambda=1, reg_alpha=7, max_depth=9, colsample_bytree=0.7, colsample_bynode=0.1, colsample_bylevel=0.9, booster=gbtree, base_score=0.3, score=0.986, total= 2.3min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.962, total= 1.7min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.961, total= 1.8min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.962, total= 1.6min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.959, total= 1.8min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.961, total= 1.9min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.964, total= 1.6min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.960, total= 1.9min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.963, total= 1.6min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.960, total= 1.8min\n",
      "[CV] subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=7, reg_lambda=7, reg_alpha=3, max_depth=3, colsample_bytree=0.3, colsample_bynode=0.1, colsample_bylevel=0.5, booster=gbtree, base_score=0.1, score=0.962, total= 1.7min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.987, total= 5.6min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.985, total= 5.8min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.986, total= 5.8min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.985, total= 7.4min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.986, total= 4.3min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.987, total= 4.3min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.986, total= 4.4min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.987, total= 4.5min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.986, total= 4.4min\n",
      "[CV] subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1 \n",
      "[CV]  subsample=0.1, scale_pos_weight=3, reg_lambda=3, reg_alpha=0, max_depth=13, colsample_bytree=0.5, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.1, score=0.987, total= 4.5min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.984, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.982, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.984, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.982, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.983, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.985, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.983, total= 1.8min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.984, total= 1.8min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.983, total= 1.7min\n",
      "[CV] subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5 \n",
      "[CV]  subsample=0.5, scale_pos_weight=3, reg_lambda=5, reg_alpha=7, max_depth=11, colsample_bytree=0.1, colsample_bynode=0.3, colsample_bylevel=0.9, booster=gbtree, base_score=0.5, score=0.984, total= 1.7min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.984, total= 2.9min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.982, total= 2.9min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.984, total= 3.0min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.982, total= 3.1min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.983, total= 2.9min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.985, total= 2.9min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.982, total= 2.9min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.984, total= 2.8min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.983, total= 2.8min\n",
      "[CV] subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3 \n",
      "[CV]  subsample=0.3, scale_pos_weight=5, reg_lambda=7, reg_alpha=5, max_depth=7, colsample_bytree=0.3, colsample_bynode=0.3, colsample_bylevel=1, booster=dart, base_score=0.3, score=0.984, total= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 315.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 13\n",
      "Best learning_rate: 0.1\n",
      "Best booster: gbtree\n",
      "Best subsample: 0.5\n",
      "Best colsample_bytree: 0.7\n",
      "Best colsample_bylevel: 0.3\n",
      "Best colsample_bynode: 0.5\n",
      "Best reg_alpha: 3\n",
      "Best reg_lambda: 5\n",
      "Best scale_pos_weight: 5\n",
      "Best base_score: 0.4\n"
     ]
    }
   ],
   "source": [
    "### Tuning XGBClassifier READY ###\n",
    "print('tuning xgbc')\n",
    "xgbc = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "# learning_rate = [0,.1,.3,.5,.7,.9]\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "subsample = [.1,.3,.5,.7]\n",
    "colsample_bytree = [.1,.3,.5,.7]\n",
    "colsample_bylevel = [0,.1,.3,.5,.7,.9,1]\n",
    "colsample_bynode = [.1,.3,.5,.7]\n",
    "reg_alpha = [0,1,3,5,7]\n",
    "reg_lambda = [1,3,5,7]\n",
    "scale_pos_weight = [1,3,5,7]\n",
    "base_score = [.1,.2,.3,.4,.5]\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, \n",
    "#                        learning_rate=learning_rate, \n",
    "                       booster=booster, \n",
    "                       subsample=subsample, \n",
    "                       colsample_bytree=colsample_bytree, colsample_bylevel=colsample_bylevel, \n",
    "                       colsample_bynode=colsample_bynode, reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "                       scale_pos_weight=scale_pos_weight,\n",
    "                       base_score=base_score\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(xgbc, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best booster:', best_model.best_estimator_.get_params()['booster'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print('Best colsample_bytree:', best_model.best_estimator_.get_params()['colsample_bytree'])\n",
    "print('Best colsample_bylevel:', best_model.best_estimator_.get_params()['colsample_bylevel'])\n",
    "print('Best colsample_bynode:', best_model.best_estimator_.get_params()['colsample_bynode'])\n",
    "print('Best reg_alpha:', best_model.best_estimator_.get_params()['reg_alpha'])\n",
    "print('Best reg_lambda:', best_model.best_estimator_.get_params()['reg_lambda'])\n",
    "print('Best scale_pos_weight:', best_model.best_estimator_.get_params()['scale_pos_weight'])\n",
    "print('Best base_score:', best_model.best_estimator_.get_params()['base_score'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
      "              colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
      "              silent=None, subsample=0.5, verbosity=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>395.304133</td>\n",
       "      <td>25.412146</td>\n",
       "      <td>0.587299</td>\n",
       "      <td>0.052609</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985380</td>\n",
       "      <td>0.986789</td>\n",
       "      <td>0.987938</td>\n",
       "      <td>0.986694</td>\n",
       "      <td>0.987347</td>\n",
       "      <td>0.986711</td>\n",
       "      <td>0.987547</td>\n",
       "      <td>0.986829</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>167.217239</td>\n",
       "      <td>11.165350</td>\n",
       "      <td>0.489047</td>\n",
       "      <td>0.155241</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963229</td>\n",
       "      <td>0.964751</td>\n",
       "      <td>0.967276</td>\n",
       "      <td>0.963401</td>\n",
       "      <td>0.966066</td>\n",
       "      <td>0.964305</td>\n",
       "      <td>0.966658</td>\n",
       "      <td>0.965024</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>120.322799</td>\n",
       "      <td>8.478442</td>\n",
       "      <td>0.271042</td>\n",
       "      <td>0.108111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>0.962940</td>\n",
       "      <td>0.965645</td>\n",
       "      <td>0.961338</td>\n",
       "      <td>0.963113</td>\n",
       "      <td>0.962412</td>\n",
       "      <td>0.964037</td>\n",
       "      <td>0.963005</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99.684576</td>\n",
       "      <td>5.295310</td>\n",
       "      <td>0.226211</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>0.798554</td>\n",
       "      <td>0.805074</td>\n",
       "      <td>0.801674</td>\n",
       "      <td>0.804025</td>\n",
       "      <td>0.797907</td>\n",
       "      <td>0.806804</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>203.073417</td>\n",
       "      <td>25.312860</td>\n",
       "      <td>0.677408</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987628</td>\n",
       "      <td>0.988995</td>\n",
       "      <td>0.989606</td>\n",
       "      <td>0.988777</td>\n",
       "      <td>0.989180</td>\n",
       "      <td>0.988744</td>\n",
       "      <td>0.989257</td>\n",
       "      <td>0.988861</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>217.663624</td>\n",
       "      <td>223.572931</td>\n",
       "      <td>0.553119</td>\n",
       "      <td>0.219257</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984488</td>\n",
       "      <td>0.985504</td>\n",
       "      <td>0.986885</td>\n",
       "      <td>0.985129</td>\n",
       "      <td>0.985695</td>\n",
       "      <td>0.984936</td>\n",
       "      <td>0.986337</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>103.800450</td>\n",
       "      <td>5.746303</td>\n",
       "      <td>0.394553</td>\n",
       "      <td>0.301245</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959114</td>\n",
       "      <td>0.960575</td>\n",
       "      <td>0.963978</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.963111</td>\n",
       "      <td>0.959996</td>\n",
       "      <td>0.962418</td>\n",
       "      <td>0.961344</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>305.320971</td>\n",
       "      <td>59.342621</td>\n",
       "      <td>0.606575</td>\n",
       "      <td>0.120821</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985453</td>\n",
       "      <td>0.986445</td>\n",
       "      <td>0.987005</td>\n",
       "      <td>0.985547</td>\n",
       "      <td>0.986576</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.987112</td>\n",
       "      <td>0.986233</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>102.538558</td>\n",
       "      <td>3.363380</td>\n",
       "      <td>0.421863</td>\n",
       "      <td>0.036955</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982312</td>\n",
       "      <td>0.983491</td>\n",
       "      <td>0.984753</td>\n",
       "      <td>0.982607</td>\n",
       "      <td>0.983767</td>\n",
       "      <td>0.982724</td>\n",
       "      <td>0.984011</td>\n",
       "      <td>0.983344</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>173.911546</td>\n",
       "      <td>5.071884</td>\n",
       "      <td>0.338486</td>\n",
       "      <td>0.032476</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982008</td>\n",
       "      <td>0.983266</td>\n",
       "      <td>0.984789</td>\n",
       "      <td>0.982414</td>\n",
       "      <td>0.983546</td>\n",
       "      <td>0.982560</td>\n",
       "      <td>0.983857</td>\n",
       "      <td>0.983167</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     395.304133     25.412146         0.587299        0.052609   \n",
       "1     167.217239     11.165350         0.489047        0.155241   \n",
       "2     120.322799      8.478442         0.271042        0.108111   \n",
       "3      99.684576      5.295310         0.226211        0.090092   \n",
       "4     203.073417     25.312860         0.677408        0.173201   \n",
       "5     217.663624    223.572931         0.553119        0.219257   \n",
       "6     103.800450      5.746303         0.394553        0.301245   \n",
       "7     305.320971     59.342621         0.606575        0.120821   \n",
       "8     102.538558      3.363380         0.421863        0.036955   \n",
       "9     173.911546      5.071884         0.338486        0.032476   \n",
       "\n",
       "  param_subsample param_scale_pos_weight param_reg_lambda param_reg_alpha  \\\n",
       "0             0.5                      3                5               5   \n",
       "1             0.7                      1                7               7   \n",
       "2             0.1                      7                3               7   \n",
       "3             0.5                      7                1               5   \n",
       "4             0.5                      5                5               3   \n",
       "5             0.7                      3                1               7   \n",
       "6             0.1                      7                7               3   \n",
       "7             0.1                      3                3               0   \n",
       "8             0.5                      3                5               7   \n",
       "9             0.3                      5                7               5   \n",
       "\n",
       "  param_max_depth param_colsample_bytree  ... split3_test_score  \\\n",
       "0               9                    0.5  ...          0.985380   \n",
       "1              11                    0.7  ...          0.963229   \n",
       "2               2                    0.7  ...          0.961926   \n",
       "3               9                    0.7  ...          0.802181   \n",
       "4              13                    0.7  ...          0.987628   \n",
       "5               9                    0.7  ...          0.984488   \n",
       "6               3                    0.3  ...          0.959114   \n",
       "7              13                    0.5  ...          0.985453   \n",
       "8              11                    0.1  ...          0.982312   \n",
       "9               7                    0.3  ...          0.982008   \n",
       "\n",
       "  split4_test_score split5_test_score split6_test_score split7_test_score  \\\n",
       "0          0.986789          0.987938          0.986694          0.987347   \n",
       "1          0.964751          0.967276          0.963401          0.966066   \n",
       "2          0.962940          0.965645          0.961338          0.963113   \n",
       "3          0.798554          0.805074          0.801674          0.804025   \n",
       "4          0.988995          0.989606          0.988777          0.989180   \n",
       "5          0.985504          0.986885          0.985129          0.985695   \n",
       "6          0.960575          0.963978          0.959773          0.963111   \n",
       "7          0.986445          0.987005          0.985547          0.986576   \n",
       "8          0.983491          0.984753          0.982607          0.983767   \n",
       "9          0.983266          0.984789          0.982414          0.983546   \n",
       "\n",
       "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.986711           0.987547         0.986829        0.000743   \n",
       "1           0.964305           0.966658         0.965024        0.001343   \n",
       "2           0.962412           0.964037         0.963005        0.001308   \n",
       "3           0.797907           0.806804         0.801659        0.003228   \n",
       "4           0.988744           0.989257         0.988861        0.000556   \n",
       "5           0.984936           0.986337         0.985598        0.000679   \n",
       "6           0.959996           0.962418         0.961344        0.001475   \n",
       "7           0.985673           0.987112         0.986233        0.000623   \n",
       "8           0.982724           0.984011         0.983344        0.000777   \n",
       "9           0.982560           0.983857         0.983167        0.000871   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                7  \n",
       "2                8  \n",
       "3               10  \n",
       "4                1  \n",
       "5                4  \n",
       "6                9  \n",
       "7                3  \n",
       "8                5  \n",
       "9                6  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### testing manual tuning ######\n",
    "### manual xbgc tuning\n",
    "max_depth = [3,5,7,9,11,13,15]\n",
    "# max_depth = [1,3,5]\n",
    "list_time_elapsed = []\n",
    "list_roc_auc_score = []\n",
    "for val in max_depth:\n",
    "    model_xgbc = XGBClassifier(max_depth=val, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_xgbc.fit(mod.X_train_test, mod.y_train)\n",
    "    y_pred_xgbc = model_xgbc.predict(mod.X_test)\n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    \n",
    "    score_roc_auc = roc_auc_score(mod.y_test, y_pred_xgbc)\n",
    "    print(score_roc_auc) #delete\n",
    "    list_time_elapsed.append(elapsed_time)\n",
    "    list_roc_auc_score.append(score_roc_auc)\n",
    "    print('max depth: ', val)\n",
    "    print(confusion_matrix(mod.y_test, y_pred_xgbc))\n",
    "\n",
    "col_time_elapsed = pd.Series(list_time_elapsed)\n",
    "col_roc_score = pd.Series(list_roc_auc_score)\n",
    "col_max_depth = pd.Series(max_depth)\n",
    "df_results_xgbc = pd.concat([col_max_depth, col_roc_score,col_time_elapsed], \n",
    "                            keys=['max_depth', 'roc_auc_score', 'time_elap'], \n",
    "                            axis=1)\n",
    "print(df_results_xgbc)\n",
    "\n",
    "sns.lineplot(x='max_depth', y='roc_auc_score', data=df_results_xgbc)\n",
    "plt.title(\"XGBC manual tuning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Tuning RandomForestClassifier READY ####\n",
    "rfc = RandomForestClassifier(oob_score=False, n_jobs=1, random_state=42, verbose=1)\n",
    "\n",
    "n_estimators = [50,75,100,125,150,200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [3,5,7,9,11,13,15]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8,10]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_leaf_nodes = [2,3,5,7,9,None]\n",
    "min_impurity_decrease = [0,.1,.3,.5,.7,.9]\n",
    "\n",
    "# n_estimators = [50,75,100,125]\n",
    "# criterion = ['gini']\n",
    "# max_depth = [2,3,4,5,6,7,None]\n",
    "# min_samples_split = [6,7,8,9]\n",
    "# min_samples_leaf = [1,2]\n",
    "# min_weight_fraction_leaf = [0]\n",
    "# max_features = ['auto', 'sqrt', 'log2', None]\n",
    "# max_leaf_nodes = [None]\n",
    "# min_impurity_decrease = [0]\n",
    "\n",
    "hyperparameters = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split,\n",
    "                       min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, max_leaf_nodes=max_leaf_nodes,\n",
    "                       min_impurity_decrease=min_impurity_decrease\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(rfc, hyperparameters, random_state=42, cv=5, verbose=5, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best max_leaf_nodes:', best_model.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print('Best min_impurity_decrease:', best_model.best_estimator_.get_params()['min_impurity_decrease'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### testing manual tuning ######\n",
    "# ### manual lr tuning\n",
    "\n",
    "# penalty = ['l1', 'l2', 'elasticnet','none']\n",
    "\n",
    "# list_time_elapsed = []\n",
    "# list_roc_auc_score = []\n",
    "# for val in penalty:\n",
    "#     model = LogisticRegression(penalty=val, n_jobs=1, random_state=42)\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     model.fit(mod.X_train, mod.y_train)\n",
    "#     y_pred = model.predict(mod.X_test)\n",
    "#     elapsed_time = (time.time() - start_time) / 60\n",
    "    \n",
    "#     score_roc_auc = roc_auc_score(mod.y_test, y_pred)\n",
    "#     print(score_roc_auc) #delete\n",
    "#     list_time_elapsed.append(elapsed_time)\n",
    "#     list_roc_auc_score.append(score_roc_auc)\n",
    "#     print('penalty: ', val)\n",
    "#     print(confusion_matrix(mod.y_test, y_pred))\n",
    "\n",
    "# col_time_elapsed = pd.Series(list_time_elapsed)\n",
    "# col_roc_score = pd.Series(list_roc_auc_score)\n",
    "# col_penalty = pd.Series(penalty) ### UPDATE\n",
    "# df_results = pd.concat([col_max_depth, col_roc_score,col_time_elapsed], \n",
    "#                             keys=['penalty', 'roc_auc_score', 'time_elap'], \n",
    "#                             axis=1)\n",
    "# print(df_results)\n",
    "\n",
    "# sns.lineplot(x='penalty', y='roc_auc_score', data=df_results_xgbc)\n",
    "# plt.title(\"lr manual tuning\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### LR Tuning ####\n",
    "lr = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "\n",
    "penalty = ['l1', 'l2', 'elasticnet','none']\n",
    "tol = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "C = [1e-1,.2,.3,.5,.7,1]\n",
    "fit_intercept = [True,False]\n",
    "intercept_scaling = [1,.1,.01,.001]\n",
    "class_weight = ['balanced', None]\n",
    "solver = ['newton-cg', 'lbfgs', 'sag']#, 'liblinear','saga']\n",
    "max_iter = [50,75,100,150,200]\n",
    "multi_class = ['auto', 'ovr', 'multinomial']\n",
    "l1_ratio = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "\n",
    "\n",
    "hyperparameters = dict(penalty=penalty, \n",
    "#                        tol=tol, \n",
    "#                        C=C, \n",
    "#                        fit_intercept=fit_intercept,\n",
    "                       intercept_scaling=intercept_scaling, \n",
    "                       class_weight=class_weight,\n",
    "                       solver=solver, \n",
    "#                        max_iter=max_iter\n",
    "                       multi_class=multi_class, \n",
    "                       l1_ratio=l1_ratio\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(lr, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "# best_model = clf.fit(mod.X_features_test, mod.y_target_test) #testing\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best tol:', best_model.best_estimator_.get_params()['tol'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best fit_intercept:', best_model.best_estimator_.get_params()['fit_intercept'])\n",
    "print('Best intercept_scaling:', best_model.best_estimator_.get_params()['intercept_scaling'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best solver:', best_model.best_estimator_.get_params()['solver'])\n",
    "print('Best max_iter:', best_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best multi_class:', best_model.best_estimator_.get_params()['multi_class'])\n",
    "print('Best l1_ratio:', best_model.best_estimator_.get_params()['l1_ratio'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(mod.y_target[mod.y_target==0].isnull())\n",
    "# df_temp = pd.concat([mod.X_features, mod.y_target], keys=['features','target'],axis=1).sample(n=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod.X_features_test = df_temp.features\n",
    "# mod.y_target_test = df_temp.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Tuning DTC READY ####\n",
    "dt = DecisionTreeClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [3,5,7,9,11]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,3,5,7,9]\n",
    "min_weight_fraction_leaf = [0,.1,.2,.3,.4,.5]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "class_weight = ['balanced', None]\n",
    "\n",
    "hyperparameters = dict(criterion=criterion, splitter=splitter, max_depth=max_depth, \n",
    "                       min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                       min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       max_features=max_features, class_weight=class_weight\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(dt, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "# best_model = clf.fit(mod.X_features_test, mod.y_target_test) #testing\n",
    " \n",
    "# best hyper parameters\n",
    "print('Best criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Best splitter:', best_model.best_estimator_.get_params()['splitter'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_weight_fraction_leaf:', best_model.best_estimator_.get_params()['min_weight_fraction_leaf'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Best class_weight:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning CatBoost READY ###\n",
    "# Tune learning rate manually.\n",
    "cbc = CatBoostClassifier(random_state=42)\n",
    "\n",
    "max_depth = [2,3,5,7,9,11,13]\n",
    "learning_rate = [.1,.3,.5,.7,.9]\n",
    "# bagging_temperature = []\n",
    "subsample = [1,3,5,7]\n",
    "n_estimators = [50,75,100,150]\n",
    "depth = [2,4,6,8,10]\n",
    "grow_policy = ['SymmetricTree', 'Depthwise', 'Lossguide']\n",
    "\n",
    "\n",
    "hyperparameters = dict(max_depth=max_depth, \n",
    "#                        learning_rate=learning_rate, \n",
    "#                        n_estimators=n_estimators,\n",
    "                       subsample=subsample,\n",
    "#                        depth=depth,\n",
    "                       grow_policy=grow_policy\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(cbc, hyperparameters, random_state=42, cv=10, verbose=10, n_jobs=1, scoring='roc_auc')\n",
    "best_model = clf.fit(mod.X_features, mod.y_target)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best subsample:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print(clf.best_estimator_)\n",
    "pd.DataFrame(clf.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:\n",
      " XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
      "              colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
      "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
      "              silent=None, subsample=0.5, verbosity=1)\n",
      "       isFraud\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n",
      "...        ...\n",
      "59049        0\n",
      "59050        0\n",
      "59051        0\n",
      "59052        0\n",
      "59053        0\n",
      "\n",
      "[59054 rows x 1 columns]\n",
      "[0 0 0 ... 0 0 0]\n",
      "roc auc score: 0.8850176446948032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97     56945\n",
      "           1       0.34      0.83      0.48      2109\n",
      "\n",
      "    accuracy                           0.94     59054\n",
      "   macro avg       0.67      0.89      0.72     59054\n",
      "weighted avg       0.97      0.94      0.95     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn      fp  precision    recall  time_elapsed (min)  \\\n",
      "384          NaN  876.0  4959.0   0.199128  0.584637            0.129198   \n",
      "385          NaN  362.0  4608.0   0.274902  0.828355            3.408594   \n",
      "386  model score  357.0  4560.0   0.277567  0.830725            4.032026   \n",
      "387          NaN  359.0  3402.0   0.339674  0.829777            7.586321   \n",
      "0            NaN  359.0  3402.0   0.339674  0.829777            7.044470   \n",
      "\n",
      "         tn       tp  \n",
      "384  1233.0  51986.0  \n",
      "385  1747.0  52337.0  \n",
      "386  1752.0  52385.0  \n",
      "387  1750.0  53543.0  \n",
      "0    1750.0  53543.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAGECAYAAADX+oDHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5RdZX3/8fdHLiHcryIhaFSCihgCDIIgqEQLWhSsYoNYAW3j5dcqVRQsrhYv9Fcs2ta60MYKiPqLgSAB6wVilgEvIA4hJISb3DRcyiVRIdwDn98f+xk5GWaSM8mcOTM8n9daZ2WfZ9+++wx85jnP3rO3bBMREc9tz+t2ARER0XkJ+4iICiTsIyIqkLCPiKhAwj4iogIJ+4iICiTsIyIqkLCPMUnSHZIelbSy5TVhPbf5ekl3DleNbe7zHEmfH8l9DkbSqZK+3e06ojMS9jGWvdX25i2vu7tZjKQNu7n/9TGWa4/2JOzjOUfS/pJ+KekPkq6V9PqWecdLukHSQ5Juk/SB0r4Z8CNgQus3hf497/69//IN4yRJi4GHJW1Y1rtA0v2Sbpf0kTbrniTJpcZlkn4v6YOS9pW0uBzPV1qWP07SLyT9p6Q/SrpR0rSW+RMkXSxphaRbJP1Ny7xTJc2R9G1JDwIfBP4B+Mty7Neu6fNq/SwkfVzSfZLukXR8y/zxkr4o6belvp9LGr+2n1F0Rn6bx3OKpJ2BHwB/BfwYmAZcIOnltu8H7gMOB24DDgZ+JOnXthdKejPwbdsTW7bXzm6PBv4ceAB4Gvg+cFFpnwj8RNJNti9p8zD2AyaX+i4ux/FGYCPgGknn276sZdk5wPbAXwDfk/Ri2yuAWcBSYALwcmCepNtszy/rHgEcBbwXGFe2savt97TUMujnVea/ANgK2Bl4EzBH0lzbvwfOAF4JHAD8b6n16TZ+RtEB6dnHWDa39Az/IGluaXsP8EPbP7T9tO15QC/wFgDbP7B9qxuXAZcCB61nHV+2vcz2o8C+wA62P2v7Cdu3AV8Hpg9he5+z/ZjtS4GHgVm277N9F/AzYK+WZe8D/t32k7ZnAzcBfy5pF+C1wEllW4uA/6YJ2D5X2J5bPqdHByqkjc/rSeCzZf8/BFYCL5P0POB9wEdt32X7Kdu/tP04a/kZRWekZx9j2ZG2f9Kv7UXAUZLe2tK2EfBTgNJ7/ydgN5rOzqbAkvWsY1m//U+Q9IeWtg1oQrpd97ZMPzrA+81b3t/l1e9m+FuanvwEYIXth/rN6xmk7gG18Xktt72q5f0jpb7tgU2AWwfY7Bp/RtEZCft4rlkGfMv23/SfIWkccAHNsMVFtp8s3wj6xmoGugXswzQB1+cFAyzTut4y4Hbbk9el+HWwsyS1BP4LaYZ+7ga2lbRFS+C/ELirZd3+x7va+zY+rzV5AHgMeClwbb95g/6MonMyjBPPNd8G3irpUEkbSNqknEicCGxMMzZ9P7Cq9Fr/rGXde4HtJG3V0rYIeIukbSW9ADhhLfu/CniwnLQdX2rYQ9K+w3aEq3s+8BFJG0k6CngFzRDJMuCXwP8tn8EU4P3Ad9awrXuBSWUIBtb+eQ3K9tPAWcCXyoniDSS9pvwCWdPPKDokYR/PKSXkjqC5suR+ml7kJ4DnlR7uR4DzgN8D76bpBfeteyPNSc3bynmACcC3aHqmd9CMV89ey/6fAt4KTAVup+nh/jfNScxO+BXNydwHgNOAd9peXuYdDUyi6eVfCPxTGR8fzPnl3+WSFq7t82rDiTRDPr8GVgCn0/wcBv0ZDWHbMUTKw0sixiZJxwF/bfu13a4lRr/8Jo2IqEDCPiKiAhnGiYioQHr2EREVSNhHRFQgf1TVBdtvv70nTZrU7TIi4jnm6quvfsD2DgPNS9h3waRJk+jt7e12GRHxHCPpt4PNyzBOREQFcjVOF2y+5VbeY98Du11GRIxiV87/4ZDXkXS17Z6B5qVnHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgYR9IWmBpEP7tZ0g6UxJL5R0qaQbJF0vaVKZ/zNJi8rrbklzu1F7RMTa5EZoz5gFTAcuaWmbTvMg5HOB02zPk7Q58DSA7YP6FpR0AXDRyJUbEdG+9OyfMQc4XNI4gNJ7nwCsADa0PQ/A9krbj7SuKGkL4BAgPfuIGJUS9oXt5cBVwGGlaTowG5gM/EHS9yRdI+lfJW3Qb/W3A/NtPzjY9iXNkNQrqffJJ57oxCFERAwqYb+6vqEcyr+zaIa6DgJOBPYFXgIc12+9o8uyg7I903aP7Z6NNt54OGuOiFirhP3q5gLTJO0NjLe9ELgTuMb2bbZXlWX27ltB0nbAq4EfdKPgiIh2JOxb2F4JLADO4pme+q+BbST1PerrEOD6ltWOAv7H9mMjVWdExFAl7J9tFrAn8F0A20/RDOHMl7QEEPD1luX7hnsiIkatXHrZj+0LaQK9tW0eMGWQ5V8/AmVFRKyX9OwjIiqQsI+IqEDCPiKiAgn7iIgKJOwjIiqQsI+IqEDCPiKiArnOvgtevttkrpz/w26XEREVSc8+IqICCfuIiAok7CMiKpCwj4ioQMI+IqICCfuIiArk0ssuuPHWO3jt24/vdhkxRD+/8OxulxCxztKzj4ioQMI+IqICCfuIiAok7CMiKpCwj4ioQMI+IqICCfuIiAok7CMiKpCwj4ioQMfCXtJTkhZJuk7S+ZI2XY9tHSfpK+ux7oSW9xtJ+hdJvym1XSXpzWXeHZKWlNf1kj4vadwatj1J0qPlOK+XdK6kjdalzoiITupkz/5R21Nt7wE8AXywdaYaI/HN4jhgQsv7zwE7AXuU2t4KbNEy/w22XwW8GngJMHMt27/V9lTgVcBE4F3DVHdExLAZqWGcnwG7lp7wDZLOBBYCu0g6uvSkr5N0et8Kko6XdLOky4ADW9rPkfTOlvcrW6Y/WbZ1bem9vxPoAb5Tet+bAX8D/J3txwFs32v7vP4F215J8wvqSEnbru0AbT8FXAXsPNQPJyKi0zoe9pI2BN4MLClNLwPOtb0X8CRwOnAIMBXYV9KRknYCPkMT8m8Cdm9jP28GjgT2s70n8AXbc4Be4JjS+34p8DvbD7ZTe1nudmByG/vfBNgP+PEg82dI6pXUu+rxx9rZfUTEsOlk2I+XtIgmbH8HfKO0/9b2lWV6X2CB7fttrwK+AxxME5p97U8As9vY3xuBs20/AmB7xTAdh9Yy/6XlOJfT/CJZPNBCtmfa7rHds+G4TYaptIiI9nTyFsePlt70n0gCeLi1aQ3re5D2VZRfUmo2uHHLtgZbp88twAslbWH7obUsi6QtgEnAzWtY7FbbU8u3kQWS3mb74rVtOyJiJHX70stfAa+TtL2kDYCjgctK++slbVeubjmqZZ07gH3K9BFA39UvlwLv67vqp2Wc/SHKCdjS6/8G8GVJG5fldpL0nv6FSdocOBOYa/v3azsQ2/cAJwOfavPYIyJGTFfDvgTkp4CfAtcCC21fVNpPBa4AfkJzMrfP12l+QVxFM9zzcNnWj4GLgd4yrHJiWf4c4GvlBO144NPA/cD1kq4D5pb3fX5a2q+iGX76wBAOaS6wqaSDhrBORETHyV7byEcMt8232d5TX//WbpcRQ5QnVcVoJ+lq2z0Dzev2ME5ERIyAPIO2DZJeBXyrX/PjtvfrRj0REUOVsG+D7SU0fwcQETEmZRgnIqICCfuIiAok7CMiKpCwj4ioQE7QdsHLXzop12xHxIhKzz4iogIJ+4iICiTsIyIqkLCPiKhAwj4iogK5GqcLbrrjTl533EndLiOG6LJzTl/7QhGjVHr2EREVSNhHRFQgYR8RUYGEfUREBRL2EREVSNhHRFQgYR8RUYGEfUREBRL2EREVSNi3kLRA0qH92k6QdKakL0haKukGSV+WpDL/aElLJC2W9GNJ23en+oiIwSXsVzcLmN6vbTowGzgQmALsAewLvE7ShsB/AG+wPQVYDPztyJUbEdGehP3q5gCHSxoHIGkSMAF4AtgE2BgYB2wE3AuovDYrPf0tgbtHvOqIiLVI2LewvRy4CjisNE0HZtu+AvgpcE95XWL7BttPAh8CltCE/O7ANwbatqQZknol9T752KMdPpKIiNUl7J+tdShnOjBL0q7AK4CJwM7AIZIOlrQRTdjvRfMNYDHwqYE2anum7R7bPRttMr7TxxARsZqE/bPNBaZJ2hsYb3sh8HbgStsrba8EfgTsD0wFsH2rbQPnAQd0qe6IiEEl7PspYb4AOIumlw/wO8oJ2dKbfx1wA3AXsLukHcpybyrtERGjSh5eMrBZwPd4ZjhnDnAIzdi8gR/b/j6ApM8Al0t6EvgtcNyIVxsRsRYJ+wHYvpDmKpu+908BHxhk2a8BXxuh0iIi1kmGcSIiKpCwj4ioQMI+IqICCfuIiAok7CMiKpCwj4ioQMI+IqICuc6+C142aSKXnXN6t8uIiIqkZx8RUYGEfUREBRL2EREVSNhHRFQgYR8RUYGEfUREBXLpZRfcvOxepn3037pdxjqZ/x9/3+0SImIdpGcfEVGBhH1ERAUS9hERFUjYR0RUIGEfEVGBhH1ERAUS9hERFUjYR0RUoLqwl7RA0qH92k6QdLakqyUtkrRU0gdb5u8jaYmkWyR9WZJK+1Fl2acl9Yz0sUREtKu6sAdmAdP7tU0HzgEOsD0V2A84WdKEMv+rwAxgcnkdVtqvA/4CuLzDNUdErJcaw34OcLikcQCSJgETgMttP16WGUf5bCTtBGxp+wrbBs4FjgSwfYPtm0a2/IiIoasu7G0vB67imd75dGC2bUvaRdJiYBlwuu27gZ2BO1s2cWdpi4gYM6oL+6J1KGd6eY/tZbanALsCx0raEdAA63uoO5Q0Q1KvpN4nHn14HcuOiFg3tYb9XGCapL2B8bYXts4sPfqlwEE0PfmJLbMnAncPdYe2Z9rusd2z8fjN1r3yiIh1UGXY214JLADOovTqJU2UNL5MbwMcCNxk+x7gIUn7l6tw3gtc1JXCIyLWUZVhX8wC9gS+W96/AviVpGuBy4AzbC8p8z4E/DdwC3Ar8CMASW+XdCfwGuAHki4ZwfojItpW7cNLbF9Iy3i87XnAlEGW7QX2GGQbF3aqxoiI4VJzzz4iohoJ+4iICiTsIyIqkLCPiKhAwj4iogIJ+4iICiTsIyIqkLCPiKhAtX9U1U277bIj8//j77tdRkRUJD37iIgKJOwjIiqQsI+IqEDCPiKiAgn7iIgK5GqcLvjN3Ss49B+/0+0yhuySzx7T7RIiYh2lZx8RUYGEfUREBRL2EREVSNhHRFQgYR8RUYGEfUREBRL2EREVSNhHRFQgYR8RUYHqwl7SAkmH9ms7QdLZkq6WtEjSUkkfbJm/j6Qlkm6R9GVJKu3bSpon6Tfl321G+ngiItpRXdgDs4Dp/dqmA+cAB9ieCuwHnCxpQpn/VWAGMLm8DivtJwPzbU8G5pf3ERGjTo1hPwc4XNI4AEmTgAnA5bYfL8uMo3w2knYCtrR9hW0D5wJHluWOAL5Zpr/Z0h4RMapUF/a2lwNX8UzvfDow27Yl7SJpMbAMON323cDOwJ0tm7iztAHsaPuest17gOePxDFERAxVdWFftA7lTC/vsb3M9hRgV+BYSTsCGmB9D3WHkmZI6pXU+8QjD65j2RER66bWsJ8LTJO0NzDe9sLWmaVHvxQ4iKYnP7Fl9kTg7jJ9bxnm6RvuuW+wHdqeabvHds/Gm245fEcSEdGGKsPe9kpgAXAWpVcvaaKk8WV6G+BA4KYyPPOQpP3LVTjvBS4qm7oYOLZMH9vSHhExqtT88JJZwPd4ZjjnFcAXJZlm6OYM20vKvA/RXK0zHvhReQH8C3CepPcDvwOOGpnSIyKGptqwt30hLePxtucBUwZZthfYY4D25cC0TtUYETFcqhzGiYioTcI+IqICCfuIiAok7CMiKpCwj4ioQMI+IqICa7z0UtLH1jTf9peGt5yIiOiEtV1nv8WIVBERER2l5q69MZJ6enrc29vb7TIi4jlG0tW2ewaa19aYfblvzIWS7pN0r6QLJE1c+5oRETEatHuC9myam35NoLmX+/dLW0REjAHthv0Ots+2vaq8zgF26GBdERExjNoN+wckvUfSBuX1HmB5JwuLiIjh027Yvw94F/C/wD3AO4HjO1VUREQMr3Zvcfw54FjbvweQtC1wBs0vgRiiW+/9I+8443+6XcZaXXDi4d0uISKGSbs9+yl9QQ9gewWwV2dKioiI4dZu2D+vPKoP+FPPvtoHn0REjDXtBvYXgV9KmgOYZvz+tI5VFRERw6qtsLd9rqRe4BCaR/n9he3rO1pZREQMm7aHYkq4J+AjIsag3OI4IqICCfuIiAok7CMiKpCwj4ioQLVhL2mBpJ6W6ZskLSqv569hvR0k/UrSNZIOGrmKIyLWXRV/GCVpQ9ur1rLYMbbbeaLINOBG28cOQ2kRESNizIW9pPcCJ9L8cddi4Dzg08DGNHfiPMb2vZJOpbn//iSau3a+n+Ye/LsDNwDj12HfU4EvAOMlLQJeAxwEfAYYB9wKHG975XocYkTEsBtTYS/plcApwIG2Hyi3bTCwv21L+mvgk8DHyyr7AK+1/Wh5ePojtqdImgIs7Lf5syU9BVwAfN4DPK/R9iJJ/wj02P5bSdvT/KJ5o+2HJZ0EfAz47AC1zwBmAIzfOo8CiIiRNabCnuYveOfYfgCaG7JJehUwW9JONL3721uWv9j2o2X6YODLZb3Fkha3LHeM7bskbUET9n8FnNtGPfvTfFP4hSTK/q8YaEHbM4GZANvsMjkP/o2IETXWTtCKpiff6j+Br9h+FfABYJOWeQ/3W3bAkLV9V/n3IeD/Aa8eQj3zbE8tr91tv7/NdSMiRsxYC/v5wLskbQd/uvvmVsBdZf6aTppeDhxT1tsDmFKmNyzDMUjaCDgcuK7Neq4EDpS0a1l/U0m7DemIIiJGwJgaxrG9VNJpwGVlfP0a4FTgfEl30YTviwdZ/as04/KLgUXAVaV9HHBJCfoNgJ8AX2+znvslHQfMkjSuNH8auHmoxxYR0Uka4DxkdNg2u0z2IR/9t26XsVZ5UlXE2CLpats9A80ba8M4ERGxDsbUMM5IknQKcFS/5vNt56EtETHmJOwHUUI9wR4RzwkZxomIqEDCPiKiAgn7iIgKJOwjIiqQE7Rd8NIdt8o17BExotKzj4ioQMI+IqICCfuIiAok7CMiKpCwj4ioQMI+IqICufSyC357/0PM+K/53S5jNTM/MK3bJUREB6VnHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgWrDXtICST1lemNJMyXdLOlGSe9Yw3o7SPqVpGskHTRyFUdErLsqbpcgaUPbq9awyCnAfbZ3k/Q8YNs1LDsNuNH2scNaZEREB425sJf0XuBEwMBi4Dzg08DGwHLgGNv3SjoVmABMAh6Q9H7gbGB34AZgfMtm3we8HMD208ADg+x7KvAFYLykRcBrgIOAzwDjgFuB422vHL4jjohYf2NqGEfSK2l64YfY3hP4KPBzYH/bewHfBT7Zsso+wBG23w18CHjE9hTgtDIPSVuXZT8naaGk8yXtOND+bS8C/hGYbXsqsBnNL5o32t4b6AU+NkjtMyT1Sup9bOUf1uNTiIgYujEV9sAhwBzbDwDYXgFMBC6RtAT4BPDKluUvtv1omT4Y+HZZbzHNtwJovt1MBH5RAvsK4Iw269mf5pvCL0pP/1jgRQMtaHum7R7bPZtsvvVAi0REdMxYC3vRDN+0+k/gK7ZfBXwA2KRl3sP9lu2/LjRDP48AF5b35wN7D6Geebanltfutt/f5roRESNmrIX9fOBdkrYDkLQtsBVwV5m/ppOmlwPHlPX2AKYA2DbwfeD1ZblpwPVt1nMlcKCkXct2N5W0W7sHExExUsbUCVrbSyWdBlwm6SngGuBU4HxJd9GE74sHWf2rwNmSFgOLgKta5p0EfEvSvwP3A8e3Wc/9ko4DZkkaV5o/Ddw8pAOLiOgwNR3bGEk7vOhlfvs/nNntMlaTJ1VFjH2SrrbdM9C8sTaMExER62BMDeOMJEmnAEf1az7f9mndqCciYn0k7AdRQj3BHhHPCRnGiYioQMI+IqICCfuIiAok7CMiKpATtF3woh22yHXtETGi0rOPiKhAwj4iogIJ+4iICiTsIyIqkLCPiKhArsbpgrtWrOQfZv2y22UA8M9HH9DtEiJiBKRnHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgYR9C0kLJB3ar+0ESWeW6S0l3SXpK+X9FpIWtbwekPTv3ag9ImJNEvarmwVM79c2vbQDfA64rG+G7YdsT+17Ab8FvjcilUZEDEHCfnVzgMMljQOQNAmYAPxc0j7AjsClA60oaTLwfOBnI1JpRMQQJOxb2F4OXAUcVpqmA7MBAV8EPrGG1Y8GZtv2QDMlzZDUK6n3kYf+MIxVR0SsXcL+2VqHcvqGcD4M/ND2sjWs1zrc8yy2Z9rusd2z6RZbD1uxERHtyC2On20u8CVJewPjbS+U9HHgIEkfBjYHNpa00vbJAJL2BDa0fXX3yo6IGFzCvh/bKyUtAM6i9NRtH9M3X9JxQE9f0BdHs4ZefUREt2UYZ2CzgD2B77a5/LtI2EfEKJae/QBsX0hzUnageecA5/Rre0nnq4qIWHfp2UdEVCBhHxFRgYR9REQFEvYRERVI2EdEVCBhHxFRgYR9REQFcp19F+y87eb889EHdLuMiKhIevYRERVI2EdEVCBhHxFRgYR9REQFEvYRERVI2EdEVCCXXnbBvX98hC/+z8JulwHAxw/fu9slRMQISM8+IqICCfuIiAok7CMiKpCwj4ioQMI+IqICCfuIiAok7CMiKpCwj4ioQMK+DZIWSDq0X9sJks6UdLqk68rrL7tVY0TEmiTs2zMLmN6vbTpwL7A3MBXYD/iEpC1HuLaIiLVK2LdnDnC4pHEAkiYBE4BHgMtsr7L9MHAtcFi3ioyIGEzCvg22lwNX8UyQTwdm04T7myVtKml74A3ALt2pMiJicLkRWvv6hnIuKv++z/ZCSfsCvwTuB64AVg20sqQZwAyAbXZ4wYgUHBHRJz379s0FpknaGxhveyGA7dNsT7X9JkDAbwZa2fZM2z22ezbbapuRqzoigoR922yvBBYAZ9H08pG0gaTtyvQUYApwabdqjIgYTIZxhmYW8D2euTJnI+BnkgAeBN5je8BhnIiIbkrYD4HtC2mGavrePwbs3r2KIiLak2GciIgKJOwjIiqQsI+IqEDCPiKiAgn7iIgKJOwjIiqQsI+IqEDCPiKiAvmjqi7YcatN+fjhe3e7jIioSHr2EREVSNhHRFQgYR8RUYGEfUREBRL2EREVSNhHRFQgl152wfKVj3HO5Td0Zd/HHfyKruw3IrorPfuIiAok7CMiKpCwj4ioQMI+IqICCfuIiAok7CMiKpCwj4ioQMI+IqIC1YW9pAWSDu3XdoKksyVdLWmRpKWSPtgyfx9JSyTdIunLklTa/1XSjZIWS7pQ0tYjfTwREe2oLuyBWcD0fm3TgXOAA2xPBfYDTpY0ocz/KjADmFxeh5X2ecAetqcANwOf6mzpERHrpsawnwMcLmkcgKRJwATgctuPl2XGUT4bSTsBW9q+wraBc4EjAWxfantVWedKYOJIHURExFBUF/a2lwNX8UzvfDow27Yl7SJpMbAMON323cDOwJ0tm7iztPX3PuBHnas8ImLdVRf2RetQzvTyHtvLypDMrsCxknYENMD6bn0j6RRgFfCdwXYoaYakXkm9D/1hxTAcQkRE+2oN+7nANEl7A+NtL2ydWXr0S4GDaHryrcMzE4G7+95IOhY4HDimDPMMyPZM2z22e7bYetvhO5KIiDZUGfa2VwILgLMovXpJEyWNL9PbAAcCN9m+B3hI0v7lKpz3AheV5Q4DTgLeZvuRET+QiIg21Xw/+1nA93hmOOcVwBclmWbo5gzbS8q8D9FcrTOeZly+b2z+KzQnc+eVqzGvtP2nSzYjIkaLasPe9oW0jMfbngdMGWTZXmCPAdp37ViBERHDqMphnIiI2iTsIyIqkLCPiKhAwj4iogIJ+4iICiTsIyIqkLCPiKhAwj4iogLV/lFVN223+SYcd/Arul1GRFQkPfuIiAok7CMiKqA13JU3OkTSQ8BN3a6jDdsDD3S7iLUYCzXC2KhzLNQIY6PObtX4Its7DDQjY/bdcZPtnm4XsTaSekd7nWOhRhgbdY6FGmFs1Dkaa8wwTkREBRL2EREVSNh3x8xuF9CmsVDnWKgRxkadY6FGGBt1jroac4I2IqIC6dlHRFQgYT/MJB0m6SZJt0g6eYD54yTNLvN/JWlSy7xPlfabJB062mqU9CZJV0taUv49pFM1rk+dLfNfKGmlpBNHY42Spki6QtLS8pluMtrqlLSRpG+W+m6Q9Kku1niwpIWSVkl6Z795x0r6TXkd26ka16dOSVNbft6LJf1lJ+t8Ftt5DdML2AC4FXgJsDFwLbB7v2U+DHytTE8HZpfp3cvy44AXl+1sMMpq3AuYUKb3AO4ajZ9ly/wLgPOBE0dbjTSXPS8G9izvt+vEz3sY6nw38N0yvSlwBzCpSzVOonlO9LnAO1vatwVuK/9uU6a36eJnOViduwGTy/QE4B5g607UOdArPfvh9WrgFtu32X4C+C5wRL9ljgC+WabnANMkqbR/1/bjtm8HbinbGzU12r7G9t2lfSmwiaRxHahxveoEkHQkzf/0SztU3/rW+GfAYtvXAthebvupUVingc0kbQiMB54AHuxGjbbvsL0YeLrfuocC82yvsP17YB5wWAdqXK86bd9s+zdl+m7gPmDAP4DqhIT98NoZWNby/s7SNuAytlcBf6Tp1bWzbrdrbPUO4Brbj3egxvWqU9JmwEnAZzpU23rXSNPLs6RLylf+T47SOucAD9P0Qn8HnGF7RZdq7MS6QzUs+5L0appvBrcOU11rlb+gHV4aoK3/5U6DLdPOusNhfWpsZkqvBE6n6Z12ygTo7lUAAAQGSURBVPrU+Rng32yvLB39TlmfGjcEXgvsCzwCzJd0te35w1viGmtoZ5lXA0/RDDtsA/xM0k9s3za8Ja7Xf/8j9f/OsOxL0k7At4Bjbff/ltIx6dkPrzuBXVreTwTuHmyZ8tV4K2BFm+t2u0YkTQQuBN5ru5O9kvWpcz/gC5LuAE4A/kHS346yGu8ELrP9gO1HgB8Ce3egxvWt893Aj20/afs+4BdAJ24DsD7//Y/U/zvrvS9JWwI/AD5t+8phrm3NRurkQA0vmt7abTQnWPtO3ryy3zL/h9VPhJ1Xpl/J6idob6MzJ2jXp8aty/LvGM2fZb9lTqVzJ2jX57PcBlhIc9JzQ+AnwJ+PwjpPAs6m6dFuBlwPTOlGjS3LnsOzT9DeXj7Tbcr0tt36LNdQ58bAfOCETtS21tq7sdPn8gt4C3AzzVjcKaXts8DbyvQmNFeI3AJcBbykZd1Tyno3AW8ebTUCn6YZv13U8nr+aKuz3zZOpUNhPww/7/fQnEC+DvjCaPzvEti8tC+lCfpPdLHGfWl61g8Dy4GlLeu+r9R+C3B8lz/LAessP+8n+/3/M7WTtba+8he0EREVyJh9REQFEvYRERVI2EdEVCBhHxFRgYR9REQFEvYRERVI2EcMA0kfKbcA/s4Q15sk6d2dqqtlPwskjaoHYMfISthHDI8PA2+xfcwQ15tEc0uCtpRbGUQMWcI+Yj1J+hrN/c0vlnSKpLMk/VrSNZKOKMtMkvSzcofLhZIOKKv/C3CQpEWS/n6Q7R8n6XxJ3wculbS5pPllO0v67eMGSV8vD8i4VNL4ftt6XnkYyec79oHEqJS/oI0YBuWmaz3Ax4DrbX9b0tY0tx7Yi+bOiE/bfkzSZGCW7R5Jr6e5ncPha9j2ccDnae5Js6L07je1/aCk7YErgcnAi2huF9Bje5Gk84CLSy0LgJOBjwLX2T6tAx9DjGL5ShgxvP4MeJueeRTiJsALae6M+BVJU2luGbzbELc7z8/cR17AP0s6mOYBGTsDO5Z5t9teVKavphkm6vNfNDc4S9BXKGEfMbxEc1fQm1ZrlE4F7gX2pBk+fWyI2324ZfoYmicc7WP7yfKtou/5ta0Pk3mK5ulSfX4JvEHSF20Pdf8xxmXMPmJ4XQL8XcvjEfcq7VsB97h5WMVf0TzLFOAhYIsh7mMr4L4S9G+gGb5pxzdo7pt/fk701idhHzG8PgdsBCyWdF15D3AmcKykK2mGcPp66ouBVZKuHewE7QC+A/RI6qXp5d/YbnG2v0RzH/1vScr//xXJCdqIiArkN3tERAUybhcxSkg6lOZB7q1ut/32btQTzy0ZxomIqECGcSIiKpCwj4ioQMI+IqICCfuIiAok7CMiKvD/AWwRLaxvEdnBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           col  feat_rank\n",
      "0          V67   0.127891\n",
      "1  ProductCD_R   0.053158\n",
      "2          V88   0.053002\n",
      "3         V301   0.022626\n",
      "4         V300   0.021941\n",
      "5     card5_fe   0.020173\n",
      "6     card6_fe   0.018008\n",
      "7          V47   0.016993\n",
      "8           V9   0.016852\n",
      "9         V302   0.014930\n",
      "Fitting model:\n",
      " XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=0.3,\n",
      "              colsample_bynode=0.5, colsample_bytree=0.7, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=13,\n",
      "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=3, reg_lambda=5, scale_pos_weight=5, seed=None,\n",
      "              silent=None, subsample=0.5, verbosity=1)\n",
      "       isFraud\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n",
      "...        ...\n",
      "59049        0\n",
      "59050        0\n",
      "59051        0\n",
      "59052        0\n",
      "59053        0\n",
      "\n",
      "[59054 rows x 1 columns]\n",
      "[0 0 0 ... 0 0 0]\n",
      "roc auc score: 0.8850176446948032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97     56945\n",
      "           1       0.34      0.83      0.48      2109\n",
      "\n",
      "    accuracy                           0.94     59054\n",
      "   macro avg       0.67      0.89      0.72     59054\n",
      "weighted avg       0.97      0.94      0.95     59054\n",
      "\n",
      "\n",
      "Printing df_scores...\n",
      "\n",
      "      feat_tested     fn      fp  precision    recall  time_elapsed (min)  \\\n",
      "385          NaN  362.0  4608.0   0.274902  0.828355            3.408594   \n",
      "386  model score  357.0  4560.0   0.277567  0.830725            4.032026   \n",
      "387          NaN  359.0  3402.0   0.339674  0.829777            7.586321   \n",
      "388          NaN  359.0  3402.0   0.339674  0.829777            7.044470   \n",
      "0            NaN  359.0  3402.0   0.339674  0.829777            6.538398   \n",
      "\n",
      "         tn       tp  \n",
      "385  1747.0  52337.0  \n",
      "386  1752.0  52385.0  \n",
      "387  1750.0  53543.0  \n",
      "388  1750.0  53543.0  \n",
      "0    1750.0  53543.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           col  feat_rank\n",
      "0          V67   0.127891\n",
      "1  ProductCD_R   0.053158\n",
      "2          V88   0.053002\n",
      "3         V301   0.022626\n",
      "4         V300   0.021941\n",
      "5     card5_fe   0.020173\n",
      "6     card6_fe   0.018008\n",
      "7          V47   0.016993\n",
      "8           V9   0.016852\n",
      "9         V302   0.014930\n"
     ]
    }
   ],
   "source": [
    "bool_predict_proba = False\n",
    "# tuned model\n",
    "current_model = RandomForestClassifier(\n",
    "                                       max_depth=3, max_features='log2',\n",
    "                                       min_impurity_decrease=0.0, \n",
    "                                       min_samples_leaf=1, min_samples_split=7,\n",
    "                                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
    "                                       n_jobs=-1, oob_score=False, random_state=42,\n",
    "                                       verbose=0, warm_start=False)\n",
    "mod.create_df_score_model(model_current)\n",
    "\n",
    "# base model\n",
    "current_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "mod.create_df_score_model(model_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_read = pd.read_csv('/Users/krahman/work/fraud_detection/saved_files/df_scores.csv')\n",
    "df_temp_read[len(df_temp_read)-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it reads the csv, creates a dataframe, then appends the results, then saves over the old version and keeps\n",
    "# # a record of all columns in the tested dataframe.\n",
    "\n",
    "# X = df_features.drop(col_target, axis=1)\n",
    "# X = X.drop(col_id, axis=1)\n",
    "# y = df_features[col_target]\n",
    "\n",
    "# # we want to test a feature for feature engineering... we must \n",
    "\n",
    "# for col_original, col_new in zip(list_col, fe.list_new_feat):\n",
    "#     print(col_original, col_new)\n",
    "#     X[col_new] = fe.df_feat[col_new]\n",
    "#     X = X.drop(col_original, axis=1)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     sm = SMOTE(random_state=42, ratio=1.0, n_jobs=-1) # SMOTE\n",
    "#     X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "#     model_lr_pca_sm = LogisticRegression(random_state=42, n_jobs=-1) # logistic regression\n",
    "#     model_lr_pca_sm.fit(X_train_res, y_train_res)\n",
    "    \n",
    "#     y_pred = model_lr_pca_sm.predict(X_test)     # predict\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print('\\nTime elapsed:', elapsed_time / 60)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "# #     X = X.drop(col, axis=1)\n",
    "#     print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fe.df_feat['time_delta'] = df_temp['time_delta']\n",
    "# fe.df_feat['time_delta_week'] = df_temp['time_delta']/7\n",
    "# fe.df_feat['time_delta_month'] = df_temp['time_delta']/30\n",
    "# fe.df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##### implement into feature engineering class. days lapsed\n",
    "# df_temp = fe.df_feat[['TransactionDT']]\n",
    "# df_temp['time_delta'] = 0\n",
    "# len_df_temp = df_temp.shape[0]\n",
    "# for i in range(1,len(df_temp['TransactionDT'][0:len_df_temp])):\n",
    "#     val_time_1 = df_temp.loc[i - 1, 'TransactionDT']\n",
    "#     val_time_2 = df_temp.loc[i, 'TransactionDT']\n",
    "#     val_time_delta = val_time_2 - val_time_1\n",
    "#     df_temp.loc[i, 'time_delta'] = val_time_delta\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP\n",
    "# class Results():\n",
    "#     def __init__(self):\n",
    "#         self.model_lr_results = pd.DataFrame()\n",
    "#         self.model_recall = []\n",
    "#         self.model_precision = []\n",
    "# #         self.model_auc_score = []\n",
    "        \n",
    "#     def _score(self, y_true, y_pred):\n",
    "#         self.model_recall.append(recall_score(y_true, y_pred))\n",
    "#         self.model_precision.append(precision_score(y_true, y_pred))\n",
    "#         self._create_series()\n",
    "# #         self.model_auc_score.append(roc_auc_score(y_true, y_pred[:,1]))\n",
    "\n",
    "#     def _create_series(self):\n",
    "#         model_recall = pd.Series(self.model_recall, name='recall')\n",
    "#         model_precision = pd.Series(self.model_precision, name='precision')\n",
    "# #         model_auc_score = pd.Series(self.model_auc_score, name='auc_score')\n",
    "#         model_results_final = pd.concat([model_recall, model_precision],axis=1)\n",
    "#         return model_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes, do we need to visualize our results?? We need to look at our confusion matrix\n",
    "# and decide how to improve our results from here... Test and see what happens if we \n",
    "# increase our principal components... test removing columns, adding columns, imputing\n",
    "# certain columns all together. \n",
    "\n",
    "# test imputing 500 or less for ohe. Then test dropping card1 due to its number\n",
    "# of unique values that would make our data very high dimensional. We can try only ohe for\n",
    "# the entire dataset to see how our model performs over all... Though.. it will likely run \n",
    "# out of memory and crash. \n",
    "\n",
    "# ALSO test probabilities on logisticregression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "# plt.hist(y_pred_prob[:,1], bins=8)\n",
    "# plt.xlim(0,1)\n",
    "# plt.title(\"Histogram of Probability of Fraud\")\n",
    "# plt.xlabel(\"Predicted probability of Fraud\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "\n",
    "# y_pred_prob = model_lr_pca.predict_proba(X_pca)\n",
    "e\n",
    "\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.title(\"ROC curve for fraud detection classifier\")\n",
    "# plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "# plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_threshold(threshold):\n",
    "#     print(\"Sensitivity:\", tpr[thresholds > threshold][-1])\n",
    "#     print(\"Specificity:\", 1 - fpr[thresholds > threshold][-1],'\\n')\n",
    "    \n",
    "# evaluate_threshold(.5)\n",
    "# evaluate_threshold(.2)\n",
    "# evaluate_threshold(.1)\n",
    "\n",
    "# print(roc_auc_score(y, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_test2) # actual prediction test data set\n",
    "# print('y_pred_actual on test set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_actual))\n",
    "# print(classification_report(y_test2, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_test2)\n",
    "# y_pred_class = binarize(y_pred_proba, 0.5)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y_test2, y_pred_class))\n",
    "# print(classification_report(y_test2, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = model_lr_pca.predict(X_pca) # actual full data set\n",
    "# print('Logistic Regression')\n",
    "# print('y_pred_actual full data set\\n')\n",
    "# print(y_pred_actual[0:10])\n",
    "# print(confusion_matrix(y, y_pred_actual))\n",
    "# print(classification_report(y, y_pred_actual))\n",
    "\n",
    "# print('y_pred_proba full data set\\n')\n",
    "# y_pred_proba = model_lr_pca.predict_proba(X_pca)#[:,1]#[0:10]\n",
    "# y_pred_class = binarize(y_pred_proba, 0.2)[:,1]\n",
    "# print(y_pred_class[0:10])\n",
    "# print(confusion_matrix(y, y_pred_class))\n",
    "# print(classification_report(y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='TransactionDT', y='TransactionDT', hue='isFraud', data=df_features)\n",
    "# plt.title(\"Transaction Date Versus Fraud\")\n",
    "# plt.show()\n",
    "\n",
    "# we want to figure out how to create more features from TransactionDT.. \n",
    "# are certain transactions more likely. in general, to be fraudualant around a certain day? \n",
    "# we have transactionID yet we dont have the specific card of who it belongs to.. \n",
    "# if card1 is the unique identifier... and we did a groupby on fraud.. \n",
    "# we have average spent per day as an option... \n",
    "# create a feature that is average spent per day for non fraud versus average spent per day for fraud.. \n",
    "# what would the describe method reveal for us? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
